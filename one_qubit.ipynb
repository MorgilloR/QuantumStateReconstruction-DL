{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a895083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import qiskit as qk\n",
    "import qiskit.visualization\n",
    "\n",
    "from qiskit import Aer\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.quantum_info import Statevector\n",
    "\n",
    "from qiskit.providers.aer import AerSimulator\n",
    "from qiskit.providers.aer.noise import QuantumError, ReadoutError\n",
    "from qiskit import transpile\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "from tensorflow.python.framework.ops import convert_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4714753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure reproducibility\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce61c96",
   "metadata": {},
   "source": [
    "## Data Generation + (In)Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bfc12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of a random unitary transformation\n",
    "def random_unitary(N):\n",
    "    Z=np.random.randn(N,N) + 1.0j * np.random.randn(N,N)\n",
    "    [Q,R]=sp.linalg.qr(Z)\n",
    "    D=np.diag(np.diagonal(R)/np.abs(np.diagonal(R)))\n",
    "    return np.dot(Q,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6922ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which generates the density matrix given the state vector\n",
    "def get_density_matrix(state_vector):\n",
    "    density_matrix = np.outer(state_vector, np.conjugate(state_vector))\n",
    "    return density_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "785177be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which computes the components of the Bloch vector, given the density matrix \n",
    "\n",
    "#Here we define the identity matrix and the Pauli matrices for dimension 2 (one qubit)\n",
    "I = np.array([[1, 0],[0, 1]])\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "Y = np.array([[0, -1j], [1j, 0]])\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "\n",
    "def Bloch_vector(rho):\n",
    "    ax = np.trace(np.dot(rho, X)).real\n",
    "    ay = np.trace(np.dot(rho, Y)).real\n",
    "    az = np.trace(np.dot(rho, Z)).real\n",
    "    pnt = [ax, ay, az]\n",
    "    return np.array(pnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1d2c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_matrix_from_bloch_vector(bloch_vector):\n",
    "   rho = 0.5 * (I+ bloch_vector[0]*X + bloch_vector[1]*Y + bloch_vector[2]*Z)\n",
    "   return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "405a6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_function(a,b):\n",
    "    fid = tf.linalg.trace(a @ b)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "975d0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_tf = tf.constant([1.0, 0.0,0.0,1.0],shape=(2,2), dtype = tf.complex64)\n",
    "X_tf = tf.constant([0.0, 1.0, 1.0, 0.0],shape=(2,2), dtype = tf.complex64)\n",
    "Y_tf = tf.constant([0.0+0j, 0.0-1j ,0.0+1j,0.0+0j],shape=(2,2), dtype = tf.complex64)\n",
    "Z_tf = tf.constant([1.0, 0.0,0.0,-1.0],shape=(2,2), dtype = tf.complex64)\n",
    "A = tf.stack([X_tf,Y_tf,Z_tf]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c76a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def infidelity(a,b):\n",
    "   a = tf.cast(a, tf.complex64)\n",
    "   b = tf.cast(b, tf.complex64)\n",
    "   el_a = tf.einsum('ijk,mi->mjk',A,a) \n",
    "   el_b = tf.einsum('ijk,mi->mjk',A,b) \n",
    "   rho_a = 0.5 *(el_a + I_tf)\n",
    "   rho_b = 0.5 * (el_b +I_tf)\n",
    "   fidelity = tf.linalg.trace(rho_a @ rho_b) \n",
    "   infidelity = 1 - fidelity\n",
    "   return infidelity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf06bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to represent the data on the Bloch sphere\n",
    "\n",
    "def Bloch_sphere(data):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    qk.visualization.plot_bloch_vector([0, 0, 0], title='Bloch Sphere',ax=ax)\n",
    "    for (x, y, z) in data:\n",
    "        ax.scatter3D(y, -x, z, c='b') #here x and y axis are inverted in order to match qiskit and matplotlib axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b17acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_bknd=Aer.get_backend('aer_simulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f9cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Haar_data(num_qubits, samples=1000):\n",
    "    data = []\n",
    "    for i in range(samples):\n",
    "        qc = qk.QuantumCircuit(num_qubits) #creates a quantum circuit with \"num_qubits\" qubits\n",
    "        u = random_unitary(2**num_qubits)\n",
    "        qc.unitary(u, qubits=range(num_qubits)) #applies the random unitary transformation to the circuit\n",
    "        qc = qk.transpile(qc, backend=sim_bknd) #it's used to optimize the circuit\n",
    "        qc.save_statevector() #it's the instruction to save the state vector obtained by the simulation\n",
    "\n",
    "        state = sim_bknd.run(qc).result().get_statevector(qc) #does the simulation and gets the state vector\n",
    "        state = np.asarray(state)\n",
    "        data.append(state) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd81fa",
   "metadata": {},
   "source": [
    "## Noise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95961f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SINGLE ELEMENT OF THE OPERATOR-SUM REPRESENTATION\n",
    "\n",
    "def sum_element(rho,operator):\n",
    "    element = np.dot(np.dot(operator,rho),operator.conj().T)\n",
    "    return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de29c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIT FLIP, PHASE FLIP AND BIT-PHASE FLIP ERROR\n",
    "\n",
    "def flip_error(num_qubits, rho, error_type, p):\n",
    "\n",
    "    E_0 = np.sqrt(1-p)*I\n",
    "    if error_type == 'bit':\n",
    "        E_1 = np.sqrt(p)*X\n",
    "    if error_type == 'phase':\n",
    "        E_1 = np.sqrt(p)*Z\n",
    "    if error_type == 'bp':\n",
    "        E_1 = np.sqrt(p)*Y\n",
    "        \n",
    "    rho_with_flip_error = sum_element(rho, E_0)+sum_element(rho, E_1)\n",
    "    \n",
    "    return rho_with_flip_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeeb3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL PAULI ERROR (generalizes and allows to combine the flip errors)\n",
    "\n",
    "def g_pauli_error(num_qubits, rho, p_0, p_1, p_2, p_3):\n",
    "    \n",
    "    E_0 = np.sqrt(p_0)*I\n",
    "    E_1 = np.sqrt(p_1)*X\n",
    "    E_2 = np.sqrt(p_2)*Y\n",
    "    E_3 = np.sqrt(p_3)*Z\n",
    "    \n",
    "    rho_with_gpauli_error = sum_element(rho, E_0)+sum_element(rho, E_1)+sum_element(rho, E_2)+sum_element(rho, E_3)\n",
    "    \n",
    "    return rho_with_gpauli_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa22893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPOLARIZING ERROR\n",
    "\n",
    "def depolar_error(num_qubits, rho, p):\n",
    "    \n",
    "    rho_with_dep_error = p*I/2 + (1-p)*rho\n",
    "\n",
    "    return rho_with_dep_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ed1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL AMPLITUDE DAMPING ERROR\n",
    "\n",
    "def ampl_damp_error(num_qubits, rho, p, a):\n",
    "  \n",
    "    E_0 = np.sqrt(p)*np.array([[1, 0], [0, np.sqrt(1-a)]])\n",
    "    E_1 = np.sqrt(p)*np.array([[0, np.sqrt(a)], [0, 0]])\n",
    "    E_2 = np.sqrt(1-p)*np.array([[np.sqrt(1-a), 0], [0, 1]])\n",
    "    E_3 = np.sqrt(1-p)*np.array([[0, 0], [np.sqrt(a), 0]])\n",
    "    \n",
    "    rho_with_ad_error = sum_element(rho, E_0)+sum_element(rho, E_1)+sum_element(rho, E_2)+sum_element(rho, E_3)\n",
    "\n",
    "    return rho_with_ad_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e4ab0",
   "metadata": {},
   "source": [
    "## Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cfb8bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density matrix noise free type: complex128\n",
      "Bloch vector noise free type: float64\n"
     ]
    }
   ],
   "source": [
    "# GENERATE DATA\n",
    "data = generate_Haar_data(1, 100)\n",
    "#COMPUTE NOISE FREE DENSITY MATRIX\n",
    "density_matrix_noise_free = [*map(get_density_matrix, data)]\n",
    "#COMPUTE BLOCH VECTOR NOISE FREE\n",
    "bloch_vectors_noise_free = [*map(Bloch_vector, density_matrix_noise_free)]\n",
    "\n",
    "#PRINT THE TYPE OF THE SINGLE DENSITY MATRIX IN THE LISTS OF THE DENSITY MATRICES NOISE FREE\n",
    "print(\"Density matrix noise free type:\", density_matrix_noise_free[0].dtype)\n",
    "#PRINT THE TYPE OF THE BLOCH VECTOR IN THE LISTS OF THE BLOCH VECTORS NOISE FREE\n",
    "print(\"Bloch vector noise free type:\", bloch_vectors_noise_free[0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d6c04",
   "metadata": {},
   "source": [
    "## Phase Flip Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8651eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density matrix with noise type: complex128\n",
      "Bloch vector with noise type: float64\n"
     ]
    }
   ],
   "source": [
    "#APPLY ERROR (in this case phase error with p=0.2)\n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = flip_error(1, density_matrix_noise_free[i], 'phase', 0.2)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "\n",
    "#PRINT THE TYPE OF THE SINGLE DENSITY MATRIX IN THE LISTS OF THE DENSITY MATRICES WITH NOISE\n",
    "print(\"Density matrix with noise type:\", density_matrix_with_noise[0].dtype)\n",
    "\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]\n",
    "print(\"Bloch vector with noise type:\", bloch_vectors_with_noise[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccce50fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: <dtype: 'float64'>\n",
      "Output data type: <dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "print(\"Input data type:\", x_train.dtype)\n",
    "print(\"Output data type:\", y_train.dtype)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5eb39b",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ebcd919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3106abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 94ms/step - loss: 0.3024 - val_loss: 0.2616\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2572 - val_loss: 0.2206\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2155 - val_loss: 0.1825\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1782 - val_loss: 0.1483\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1436 - val_loss: 0.1173\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1122 - val_loss: 0.0897\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0850 - val_loss: 0.0664\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0604 - val_loss: 0.0469\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0410 - val_loss: 0.0313\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0253 - val_loss: 0.0192\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3769e-04 - val_loss: 9.5093e-04\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8575e-04 - val_loss: 8.8661e-04\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9317e-04 - val_loss: 8.7123e-04\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1406e-04 - val_loss: 8.4122e-04\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7122e-04 - val_loss: 8.0179e-04\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5278e-04 - val_loss: 7.4764e-04\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.1402e-04 - val_loss: 7.4343e-04\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7324e-04 - val_loss: 6.8413e-04\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.3989e-04 - val_loss: 6.3404e-04\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2246e-04 - val_loss: 6.1738e-04\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0380e-04 - val_loss: 6.0223e-04\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8219e-04 - val_loss: 5.7284e-04\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.6399e-04 - val_loss: 5.3436e-04\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.5586e-04 - val_loss: 5.2889e-04\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.4024e-04 - val_loss: 5.4073e-04\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1973e-04 - val_loss: 5.3464e-04\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1274e-04 - val_loss: 5.1346e-04\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0266e-04 - val_loss: 4.8693e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.8858e-04 - val_loss: 4.8563e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8363e-04 - val_loss: 4.8911e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7382e-04 - val_loss: 4.8631e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6776e-04 - val_loss: 4.7372e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5944e-04 - val_loss: 4.5881e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5190e-04 - val_loss: 4.4870e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4796e-04 - val_loss: 4.5039e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3951e-04 - val_loss: 4.4059e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3638e-04 - val_loss: 4.4839e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2734e-04 - val_loss: 4.3471e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2203e-04 - val_loss: 4.3459e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1972e-04 - val_loss: 4.3334e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1298e-04 - val_loss: 4.2100e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0900e-04 - val_loss: 4.1790e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0948e-04 - val_loss: 4.2000e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0576e-04 - val_loss: 4.1173e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.9415e-05 - val_loss: 4.1167e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.7103e-05 - val_loss: 4.0253e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.4333e-05 - val_loss: 4.0616e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2266e-05 - val_loss: 4.0121e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8995e-05 - val_loss: 3.9763e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5439e-05 - val_loss: 3.9186e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3044e-05 - val_loss: 3.9212e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9349e-05 - val_loss: 3.9354e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.8822e-05 - val_loss: 3.8583e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.5283e-05 - val_loss: 3.8577e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4353e-05 - val_loss: 3.8806e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3070e-05 - val_loss: 3.8055e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3364e-05 - val_loss: 3.8087e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9437e-05 - val_loss: 3.7922e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7695e-05 - val_loss: 3.8224e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7052e-05 - val_loss: 3.7318e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.5772e-05 - val_loss: 3.7990e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2462e-05 - val_loss: 3.6905e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9821e-05 - val_loss: 3.6275e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9087e-05 - val_loss: 3.6384e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9395e-05 - val_loss: 3.7023e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.7310e-05 - val_loss: 3.6116e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.5621e-05 - val_loss: 3.6340e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3702e-05 - val_loss: 3.6745e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.3698e-05 - val_loss: 3.5814e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.3486e-05 - val_loss: 3.5230e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.1328e-05 - val_loss: 3.6075e-04\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0489e-05 - val_loss: 3.5868e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8426e-05 - val_loss: 3.5407e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9086e-05 - val_loss: 3.5923e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.6254e-05 - val_loss: 3.5754e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5949e-05 - val_loss: 3.4923e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4547e-05 - val_loss: 3.5257e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4451e-05 - val_loss: 3.5292e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2161e-05 - val_loss: 3.4672e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1474e-05 - val_loss: 3.4770e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.1551e-05 - val_loss: 3.5195e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9956e-05 - val_loss: 3.4809e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9975e-05 - val_loss: 3.4870e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7935e-05 - val_loss: 3.4402e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7689e-05 - val_loss: 3.4536e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7096e-05 - val_loss: 3.4688e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5817e-05 - val_loss: 3.4278e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5672e-05 - val_loss: 3.4398e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5024e-05 - val_loss: 3.4118e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3765e-05 - val_loss: 3.4282e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4088e-05 - val_loss: 3.3740e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3403e-05 - val_loss: 3.4227e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.2116e-05 - val_loss: 3.4026e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.2686e-05 - val_loss: 3.3221e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1528e-05 - val_loss: 3.3820e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9893e-05 - val_loss: 3.3658e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.0603e-05 - val_loss: 3.3014e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.8410e-05 - val_loss: 3.3930e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9490e-05 - val_loss: 3.3316e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7615e-05 - val_loss: 3.3136e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9595e-05 - val_loss: 3.3330e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8864e-05 - val_loss: 3.3186e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7216e-05 - val_loss: 3.3761e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7376e-05 - val_loss: 3.2656e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6850e-05 - val_loss: 3.3347e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.6734e-05 - val_loss: 3.2744e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4578e-05 - val_loss: 3.2432e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.5038e-05 - val_loss: 3.2595e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.4330e-05 - val_loss: 3.2925e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3899e-05 - val_loss: 3.2631e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.2999e-05 - val_loss: 3.2231e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3716e-05 - val_loss: 3.2038e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1628e-05 - val_loss: 3.1921e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2405e-05 - val_loss: 3.2384e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1739e-05 - val_loss: 3.2177e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1575e-05 - val_loss: 3.1909e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1201e-05 - val_loss: 3.1807e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0335e-05 - val_loss: 3.1506e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9918e-05 - val_loss: 3.2176e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0293e-05 - val_loss: 3.1722e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9518e-05 - val_loss: 3.1594e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9884e-05 - val_loss: 3.1983e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8950e-05 - val_loss: 3.1430e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8603e-05 - val_loss: 3.1790e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8326e-05 - val_loss: 3.1304e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6899e-05 - val_loss: 3.0857e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7191e-05 - val_loss: 3.1194e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6986e-05 - val_loss: 3.1731e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7528e-05 - val_loss: 3.0951e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6028e-05 - val_loss: 3.1373e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6211e-05 - val_loss: 3.1111e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5455e-05 - val_loss: 3.0645e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6215e-05 - val_loss: 3.1486e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5022e-05 - val_loss: 3.0905e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4732e-05 - val_loss: 3.0954e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4478e-05 - val_loss: 3.1152e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6078e-05 - val_loss: 3.0385e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5955e-05 - val_loss: 3.0702e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4467e-05 - val_loss: 3.2002e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5091e-05 - val_loss: 3.0549e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.3590e-05 - val_loss: 3.0953e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3224e-05 - val_loss: 3.0530e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2715e-05 - val_loss: 3.0627e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2923e-05 - val_loss: 3.0427e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2896e-05 - val_loss: 3.0863e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2090e-05 - val_loss: 3.0022e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2497e-05 - val_loss: 3.0476e-04\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2132e-05 - val_loss: 3.0771e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2069e-05 - val_loss: 2.9673e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1574e-05 - val_loss: 3.0372e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1574e-05 - val_loss: 3.0327e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1545e-05 - val_loss: 3.0014e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0540e-05 - val_loss: 3.0418e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1249e-05 - val_loss: 2.9981e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0853e-05 - val_loss: 3.0023e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0687e-05 - val_loss: 3.0020e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0336e-05 - val_loss: 3.0245e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0123e-05 - val_loss: 3.0341e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4692e-06 - val_loss: 2.9896e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6628e-06 - val_loss: 3.0447e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0778e-05 - val_loss: 2.9895e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.4782e-06 - val_loss: 2.9112e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1167e-06 - val_loss: 2.9979e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.6538e-06 - val_loss: 2.9793e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1957e-06 - val_loss: 3.0000e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.9131e-06 - val_loss: 2.9857e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1791e-06 - val_loss: 2.9500e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3098e-06 - val_loss: 2.9345e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2078e-06 - val_loss: 2.9863e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9990e-06 - val_loss: 2.9435e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2380e-06 - val_loss: 2.9710e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.0444e-06 - val_loss: 2.9736e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8753e-06 - val_loss: 2.9194e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4611e-06 - val_loss: 2.9772e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4707e-06 - val_loss: 2.9437e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9852e-06 - val_loss: 2.9131e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0072e-06 - val_loss: 2.9657e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8445e-06 - val_loss: 2.9445e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6442e-06 - val_loss: 2.9474e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9898e-06 - val_loss: 2.9111e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3092e-06 - val_loss: 2.9422e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5711e-06 - val_loss: 2.9339e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9015e-06 - val_loss: 2.9639e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4640e-06 - val_loss: 2.9280e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3192e-06 - val_loss: 2.9318e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1963e-06 - val_loss: 2.9403e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9087e-06 - val_loss: 2.9130e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6776e-06 - val_loss: 2.9224e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8260e-06 - val_loss: 2.9500e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5969e-06 - val_loss: 2.9205e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5518e-06 - val_loss: 2.9349e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4171e-06 - val_loss: 2.9299e-04\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=loss_fn)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9e085ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.3648e-04 - 40ms/epoch - 40ms/step\n",
      "tf.Tensor((0.997434203101137+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dca919",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60867fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39448463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 82ms/step - loss: 0.4958 - val_loss: 0.5261\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4729 - val_loss: 0.5108\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4543 - val_loss: 0.4955\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4376 - val_loss: 0.4810\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4220 - val_loss: 0.4672\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4084 - val_loss: 0.4525\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3941 - val_loss: 0.4374\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3785 - val_loss: 0.4211\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.3630 - val_loss: 0.4028\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3449 - val_loss: 0.3824\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3255 - val_loss: 0.3588\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3011 - val_loss: 0.3326\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2768 - val_loss: 0.3014\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2484 - val_loss: 0.2657\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2213 - val_loss: 0.2253\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1890 - val_loss: 0.1907\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1619 - val_loss: 0.1647\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1447 - val_loss: 0.1434\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1280 - val_loss: 0.1270\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1136 - val_loss: 0.1143\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1016 - val_loss: 0.1033\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0901 - val_loss: 0.0940\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0804 - val_loss: 0.0860\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0708 - val_loss: 0.0792\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0631 - val_loss: 0.0731\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0557 - val_loss: 0.0679\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0496 - val_loss: 0.0633\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0435 - val_loss: 0.0593\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0391 - val_loss: 0.0553\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0342 - val_loss: 0.0519\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0309 - val_loss: 0.0487\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0274 - val_loss: 0.0460\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0244 - val_loss: 0.0436\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0220 - val_loss: 0.0413\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0199 - val_loss: 0.0391\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0182 - val_loss: 0.0371\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0169 - val_loss: 0.0353\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0155 - val_loss: 0.0337\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.0322\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 0.0308\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0126 - val_loss: 0.0294\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0119 - val_loss: 0.0282\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.0270\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0107 - val_loss: 0.0258\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0248\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0238\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0229\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0221\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.0214\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0081 - val_loss: 0.0206\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0198\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0074 - val_loss: 0.0191\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0072 - val_loss: 0.0184\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.0177\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0172\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0063 - val_loss: 0.0167\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0062 - val_loss: 0.0161\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0156\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0152\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 0.0147\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.0143\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0138\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0135\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0131\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0127\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0045 - val_loss: 0.0123\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.0121\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0042 - val_loss: 0.0117\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0115\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0112\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0109\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0107\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0104\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0102\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0100\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0098\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0032 - val_loss: 0.0096\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0093\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0092\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0029 - val_loss: 0.0090\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0029 - val_loss: 0.0088\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0028 - val_loss: 0.0087\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0027 - val_loss: 0.0083\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0026 - val_loss: 0.0082\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0080\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0079\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0024 - val_loss: 0.0077\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0076\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0075\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0073\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.0072\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0021 - val_loss: 0.0071\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0070\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0050\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0047\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8850e-04 - val_loss: 0.0046\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8183e-04 - val_loss: 0.0046\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5704e-04 - val_loss: 0.0045\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.3846e-04 - val_loss: 0.0045\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2128e-04 - val_loss: 0.0044\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.1224e-04 - val_loss: 0.0044\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.9145e-04 - val_loss: 0.0043\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7892e-04 - val_loss: 0.0043\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6349e-04 - val_loss: 0.0043\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4929e-04 - val_loss: 0.0042\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3658e-04 - val_loss: 0.0042\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2269e-04 - val_loss: 0.0042\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.0797e-04 - val_loss: 0.0042\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.9816e-04 - val_loss: 0.0041\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7941e-04 - val_loss: 0.0041\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7359e-04 - val_loss: 0.0041\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5992e-04 - val_loss: 0.0040\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.5067e-04 - val_loss: 0.0040\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3445e-04 - val_loss: 0.0040\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.2657e-04 - val_loss: 0.0040\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1258e-04 - val_loss: 0.0039\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9937e-04 - val_loss: 0.0039\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8821e-04 - val_loss: 0.0039\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8062e-04 - val_loss: 0.0038\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7071e-04 - val_loss: 0.0038\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6056e-04 - val_loss: 0.0038\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5126e-04 - val_loss: 0.0038\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4112e-04 - val_loss: 0.0037\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2953e-04 - val_loss: 0.0037\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2070e-04 - val_loss: 0.0037\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1259e-04 - val_loss: 0.0037\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0474e-04 - val_loss: 0.0036\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9693e-04 - val_loss: 0.0036\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8449e-04 - val_loss: 0.0036\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7936e-04 - val_loss: 0.0036\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7085e-04 - val_loss: 0.0036\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 5.6502e-04 - val_loss: 0.0036\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.5381e-04 - val_loss: 0.0035\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.4603e-04 - val_loss: 0.0035\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4022e-04 - val_loss: 0.0035\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3346e-04 - val_loss: 0.0035\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.2555e-04 - val_loss: 0.0034\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.1841e-04 - val_loss: 0.0034\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1237e-04 - val_loss: 0.0034\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0580e-04 - val_loss: 0.0034\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9862e-04 - val_loss: 0.0034\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.9165e-04 - val_loss: 0.0034\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8528e-04 - val_loss: 0.0033\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8088e-04 - val_loss: 0.0033\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7389e-04 - val_loss: 0.0033\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.6595e-04 - val_loss: 0.0033\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6184e-04 - val_loss: 0.0033\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5796e-04 - val_loss: 0.0033\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5284e-04 - val_loss: 0.0032\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4696e-04 - val_loss: 0.0032\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3796e-04 - val_loss: 0.0032\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3319e-04 - val_loss: 0.0032\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.2943e-04 - val_loss: 0.0032\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2287e-04 - val_loss: 0.0032\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.1782e-04 - val_loss: 0.0032\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1261e-04 - val_loss: 0.0032\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.0895e-04 - val_loss: 0.0031\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0352e-04 - val_loss: 0.0031\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9849e-04 - val_loss: 0.0031\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9486e-04 - val_loss: 0.0031\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9168e-04 - val_loss: 0.0031\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.8532e-04 - val_loss: 0.0031\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8280e-04 - val_loss: 0.0031\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7641e-04 - val_loss: 0.0030\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7259e-04 - val_loss: 0.0030\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.6812e-04 - val_loss: 0.0030\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.6294e-04 - val_loss: 0.0030\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5874e-04 - val_loss: 0.0030\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.5742e-04 - val_loss: 0.0030\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5171e-04 - val_loss: 0.0030\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4996e-04 - val_loss: 0.0030\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.4414e-04 - val_loss: 0.0030\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3959e-04 - val_loss: 0.0030\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3599e-04 - val_loss: 0.0029\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3280e-04 - val_loss: 0.0029\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3240e-04 - val_loss: 0.0029\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2583e-04 - val_loss: 0.0029\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2120e-04 - val_loss: 0.0029\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2034e-04 - val_loss: 0.0029\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.1566e-04 - val_loss: 0.0029\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.1572e-04 - val_loss: 0.0029\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1099e-04 - val_loss: 0.0028\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.0561e-04 - val_loss: 0.0028\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0257e-04 - val_loss: 0.0028\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.0147e-04 - val_loss: 0.0028\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9854e-04 - val_loss: 0.0028\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9429e-04 - val_loss: 0.0028\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9103e-04 - val_loss: 0.0028\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8986e-04 - val_loss: 0.0028\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8603e-04 - val_loss: 0.0028\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8283e-04 - val_loss: 0.0028\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7999e-04 - val_loss: 0.0028\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.7726e-04 - val_loss: 0.0028\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7461e-04 - val_loss: 0.0028\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.7283e-04 - val_loss: 0.0028\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.7009e-04 - val_loss: 0.0027\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6739e-04 - val_loss: 0.0027\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.6396e-04 - val_loss: 0.0027\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6193e-04 - val_loss: 0.0027\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.5937e-04 - val_loss: 0.0027\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5703e-04 - val_loss: 0.0027\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5398e-04 - val_loss: 0.0027\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5198e-04 - val_loss: 0.0027\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5009e-04 - val_loss: 0.0027\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4806e-04 - val_loss: 0.0027\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4567e-04 - val_loss: 0.0027\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4342e-04 - val_loss: 0.0027\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.4165e-04 - val_loss: 0.0027\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3884e-04 - val_loss: 0.0026\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.3609e-04 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.3648e-04 - val_loss: 0.0026\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.3299e-04 - val_loss: 0.0026\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3172e-04 - val_loss: 0.0026\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2963e-04 - val_loss: 0.0026\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2595e-04 - val_loss: 0.0026\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2759e-04 - val_loss: 0.0026\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2378e-04 - val_loss: 0.0026\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2026e-04 - val_loss: 0.0026\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1962e-04 - val_loss: 0.0026\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1801e-04 - val_loss: 0.0026\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1475e-04 - val_loss: 0.0026\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1422e-04 - val_loss: 0.0026\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.1425e-04 - val_loss: 0.0026\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1151e-04 - val_loss: 0.0026\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.0900e-04 - val_loss: 0.0026\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0729e-04 - val_loss: 0.0026\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0535e-04 - val_loss: 0.0026\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0319e-04 - val_loss: 0.0026\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0152e-04 - val_loss: 0.0025\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0097e-04 - val_loss: 0.0025\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9853e-04 - val_loss: 0.0025\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9834e-04 - val_loss: 0.0025\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.9559e-04 - val_loss: 0.0025\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9352e-04 - val_loss: 0.0025\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9253e-04 - val_loss: 0.0025\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9186e-04 - val_loss: 0.0025\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9073e-04 - val_loss: 0.0025\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8849e-04 - val_loss: 0.0025\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8665e-04 - val_loss: 0.0025\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8616e-04 - val_loss: 0.0025\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8452e-04 - val_loss: 0.0025\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8319e-04 - val_loss: 0.0025\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8234e-04 - val_loss: 0.0025\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8032e-04 - val_loss: 0.0025\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.7914e-04 - val_loss: 0.0025\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7816e-04 - val_loss: 0.0025\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7673e-04 - val_loss: 0.0025\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7698e-04 - val_loss: 0.0024\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7477e-04 - val_loss: 0.0024\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7340e-04 - val_loss: 0.0024\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7164e-04 - val_loss: 0.0024\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7034e-04 - val_loss: 0.0024\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7003e-04 - val_loss: 0.0024\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7016e-04 - val_loss: 0.0024\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6775e-04 - val_loss: 0.0024\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6784e-04 - val_loss: 0.0024\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6499e-04 - val_loss: 0.0024\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6511e-04 - val_loss: 0.0024\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6252e-04 - val_loss: 0.0024\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6251e-04 - val_loss: 0.0024\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6062e-04 - val_loss: 0.0024\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5937e-04 - val_loss: 0.0024\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5838e-04 - val_loss: 0.0024\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5705e-04 - val_loss: 0.0024\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5682e-04 - val_loss: 0.0024\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5537e-04 - val_loss: 0.0024\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5608e-04 - val_loss: 0.0024\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5304e-04 - val_loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "adam_opt = tf.optimizers.Adam(0.0001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "498f3b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0022 - 202ms/epoch - 202ms/step\n",
      "tf.Tensor((0.9977837759336639+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b2b35",
   "metadata": {},
   "source": [
    "## Bit Flip Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "464ed279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density matrix with noise type: complex128\n",
      "Bloch vector with noise type: float64\n"
     ]
    }
   ],
   "source": [
    "#APPLY ERROR (in this case phase error with p=0.2)\n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = flip_error(1, density_matrix_noise_free[i], 'bit', 0.2)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "\n",
    "#PRINT THE TYPE OF THE SINGLE DENSITY MATRIX IN THE LISTS OF THE DENSITY MATRICES WITH NOISE\n",
    "print(\"Density matrix with noise type:\", density_matrix_with_noise[0].dtype)\n",
    "\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]\n",
    "print(\"Bloch vector with noise type:\", bloch_vectors_with_noise[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e871b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: <dtype: 'float64'>\n",
      "Output data type: <dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "print(\"Input data type:\", x_train.dtype)\n",
    "print(\"Output data type:\", y_train.dtype)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8caf87",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7180656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5fe47bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 69ms/step - loss: 0.3429 - val_loss: 0.3086\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.2874 - val_loss: 0.2668\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2430 - val_loss: 0.2285\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2053 - val_loss: 0.1948\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1718 - val_loss: 0.1638\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1409 - val_loss: 0.1345\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1134 - val_loss: 0.1085\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0882 - val_loss: 0.0847\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0662 - val_loss: 0.0646\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0493 - val_loss: 0.0469\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0337 - val_loss: 0.0330\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.0974e-04 - val_loss: 0.0011\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0703e-04 - val_loss: 0.0010\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6204e-04 - val_loss: 9.4163e-04\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5861e-04 - val_loss: 8.5224e-04\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7109e-04 - val_loss: 7.9247e-04\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9506e-04 - val_loss: 7.3913e-04\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4464e-04 - val_loss: 6.9955e-04\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.0504e-04 - val_loss: 6.8550e-04\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6589e-04 - val_loss: 6.5601e-04\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4812e-04 - val_loss: 6.3186e-04\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.2101e-04 - val_loss: 6.0557e-04\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9945e-04 - val_loss: 5.8612e-04\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.7996e-04 - val_loss: 5.7843e-04\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6528e-04 - val_loss: 5.7598e-04\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4455e-04 - val_loss: 5.4181e-04\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3502e-04 - val_loss: 5.1568e-04\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1968e-04 - val_loss: 4.9772e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0715e-04 - val_loss: 5.0281e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9694e-04 - val_loss: 4.8940e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8461e-04 - val_loss: 4.7165e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7773e-04 - val_loss: 4.5669e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7136e-04 - val_loss: 4.4794e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6052e-04 - val_loss: 4.2348e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5089e-04 - val_loss: 4.1651e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4279e-04 - val_loss: 4.1078e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3747e-04 - val_loss: 4.0603e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2997e-04 - val_loss: 3.9523e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3063e-04 - val_loss: 3.8223e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2205e-04 - val_loss: 3.7904e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1596e-04 - val_loss: 3.6882e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1193e-04 - val_loss: 3.5680e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0637e-04 - val_loss: 3.5520e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0399e-04 - val_loss: 3.4758e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0019e-04 - val_loss: 3.4084e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.5846e-05 - val_loss: 3.3160e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.2758e-05 - val_loss: 3.3666e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0867e-05 - val_loss: 3.2993e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6636e-05 - val_loss: 3.1688e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4077e-05 - val_loss: 3.1378e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9534e-05 - val_loss: 3.0720e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9788e-05 - val_loss: 3.0745e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7593e-05 - val_loss: 2.9909e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2672e-05 - val_loss: 2.9486e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0295e-05 - val_loss: 2.9351e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9047e-05 - val_loss: 2.9167e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7859e-05 - val_loss: 2.8543e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5201e-05 - val_loss: 2.8839e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3517e-05 - val_loss: 2.8507e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.2059e-05 - val_loss: 2.7291e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1203e-05 - val_loss: 2.7715e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9958e-05 - val_loss: 2.7768e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.6162e-05 - val_loss: 2.6766e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.5578e-05 - val_loss: 2.6596e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3146e-05 - val_loss: 2.6372e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2439e-05 - val_loss: 2.6245e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0798e-05 - val_loss: 2.6098e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0113e-05 - val_loss: 2.6046e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9263e-05 - val_loss: 2.5744e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7444e-05 - val_loss: 2.4871e-04\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5879e-05 - val_loss: 2.5397e-04\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4824e-05 - val_loss: 2.5865e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3545e-05 - val_loss: 2.5134e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.2035e-05 - val_loss: 2.4456e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1042e-05 - val_loss: 2.4881e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.9897e-05 - val_loss: 2.4450e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.9623e-05 - val_loss: 2.4317e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.8890e-05 - val_loss: 2.4626e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7944e-05 - val_loss: 2.4501e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6534e-05 - val_loss: 2.3834e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.7141e-05 - val_loss: 2.4167e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4320e-05 - val_loss: 2.4068e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.4577e-05 - val_loss: 2.3664e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2515e-05 - val_loss: 2.3975e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2564e-05 - val_loss: 2.4297e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1337e-05 - val_loss: 2.3181e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.0623e-05 - val_loss: 2.3487e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.0860e-05 - val_loss: 2.3020e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9214e-05 - val_loss: 2.2948e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.9224e-05 - val_loss: 2.3525e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.8757e-05 - val_loss: 2.3124e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.8389e-05 - val_loss: 2.3411e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.7094e-05 - val_loss: 2.2649e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6806e-05 - val_loss: 2.2353e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.6254e-05 - val_loss: 2.3577e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.6106e-05 - val_loss: 2.3135e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5146e-05 - val_loss: 2.2295e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4643e-05 - val_loss: 2.2419e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3326e-05 - val_loss: 2.2525e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.3458e-05 - val_loss: 2.2715e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.2130e-05 - val_loss: 2.2495e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2200e-05 - val_loss: 2.2355e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1807e-05 - val_loss: 2.2737e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.0974e-05 - val_loss: 2.2465e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0765e-05 - val_loss: 2.2193e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0481e-05 - val_loss: 2.2405e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.0861e-05 - val_loss: 2.2633e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9691e-05 - val_loss: 2.2424e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9667e-05 - val_loss: 2.2752e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8500e-05 - val_loss: 2.2060e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9037e-05 - val_loss: 2.2085e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0454e-05 - val_loss: 2.2955e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9192e-05 - val_loss: 2.2167e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8783e-05 - val_loss: 2.2648e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7949e-05 - val_loss: 2.2541e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7166e-05 - val_loss: 2.2363e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7167e-05 - val_loss: 2.2551e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7429e-05 - val_loss: 2.2449e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6244e-05 - val_loss: 2.2459e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6505e-05 - val_loss: 2.2858e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5898e-05 - val_loss: 2.2024e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5534e-05 - val_loss: 2.2266e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5305e-05 - val_loss: 2.2706e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5008e-05 - val_loss: 2.2341e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5277e-05 - val_loss: 2.2349e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4801e-05 - val_loss: 2.2806e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4116e-05 - val_loss: 2.2164e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4353e-05 - val_loss: 2.2210e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4328e-05 - val_loss: 2.2319e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3674e-05 - val_loss: 2.2326e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3894e-05 - val_loss: 2.2287e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3839e-05 - val_loss: 2.2405e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2980e-05 - val_loss: 2.2390e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3086e-05 - val_loss: 2.2428e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3171e-05 - val_loss: 2.2509e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2585e-05 - val_loss: 2.2091e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3023e-05 - val_loss: 2.2313e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3378e-05 - val_loss: 2.2952e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3044e-05 - val_loss: 2.1925e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1978e-05 - val_loss: 2.2188e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2537e-05 - val_loss: 2.2241e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1551e-05 - val_loss: 2.2316e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1790e-05 - val_loss: 2.2120e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1332e-05 - val_loss: 2.1926e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1504e-05 - val_loss: 2.2561e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0989e-05 - val_loss: 2.2144e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1087e-05 - val_loss: 2.2054e-04\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0583e-05 - val_loss: 2.2267e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0647e-05 - val_loss: 2.2062e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0645e-05 - val_loss: 2.1751e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0363e-05 - val_loss: 2.2352e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0463e-05 - val_loss: 2.2234e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0147e-05 - val_loss: 2.2303e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7906e-06 - val_loss: 2.2045e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0918e-05 - val_loss: 2.1741e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1833e-05 - val_loss: 2.2641e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0124e-05 - val_loss: 2.2202e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1353e-05 - val_loss: 2.1638e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.8515e-06 - val_loss: 2.2378e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0194e-05 - val_loss: 2.1887e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.8074e-06 - val_loss: 2.1981e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.0169e-06 - val_loss: 2.1815e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7928e-06 - val_loss: 2.2084e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9554e-06 - val_loss: 2.2259e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1804e-06 - val_loss: 2.1512e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2634e-06 - val_loss: 2.2269e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5427e-06 - val_loss: 2.1395e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7633e-06 - val_loss: 2.2059e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8369e-06 - val_loss: 2.1680e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.4145e-06 - val_loss: 2.2295e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2283e-06 - val_loss: 2.1648e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.1477e-06 - val_loss: 2.1437e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.5052e-06 - val_loss: 2.2095e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.0270e-06 - val_loss: 2.1650e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.1586e-06 - val_loss: 2.2094e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.8344e-06 - val_loss: 2.1489e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9242e-06 - val_loss: 2.1731e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3544e-06 - val_loss: 2.1823e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4449e-06 - val_loss: 2.1621e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0452e-06 - val_loss: 2.1690e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3022e-06 - val_loss: 2.2076e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5844e-06 - val_loss: 2.1666e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4951e-06 - val_loss: 2.1760e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2591e-06 - val_loss: 2.1485e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2129e-06 - val_loss: 2.2379e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6200e-06 - val_loss: 2.1606e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7492e-06 - val_loss: 2.1873e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.8432e-06 - val_loss: 2.1760e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5008e-06 - val_loss: 2.1768e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.2066e-06 - val_loss: 2.1565e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4231e-06 - val_loss: 2.1505e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7182e-06 - val_loss: 2.1693e-04\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=loss_fn)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9f87e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 3.8901e-05 - 153ms/epoch - 153ms/step\n",
      "tf.Tensor((1.0004115316502333+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca31ac8d",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "432e70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b43683d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 66ms/step - loss: 0.5121 - val_loss: 0.4123\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3544 - val_loss: 0.3150\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2476 - val_loss: 0.2123\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1494 - val_loss: 0.1351\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0905 - val_loss: 0.0915\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0599 - val_loss: 0.0604\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0377 - val_loss: 0.0392\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0237 - val_loss: 0.0255\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0173\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0097\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.2988e-04 - val_loss: 0.0019\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3033e-04 - val_loss: 0.0018\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4769e-04 - val_loss: 0.0017\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8858e-04 - val_loss: 0.0016\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0476e-04 - val_loss: 0.0015\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3492e-04 - val_loss: 0.0015\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.8565e-04 - val_loss: 0.0014\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3568e-04 - val_loss: 0.0013\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.9683e-04 - val_loss: 0.0012\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.6714e-04 - val_loss: 0.0012\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.2706e-04 - val_loss: 0.0011\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9251e-04 - val_loss: 0.0011\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7329e-04 - val_loss: 0.0011\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4908e-04 - val_loss: 0.0010\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3337e-04 - val_loss: 0.0010\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1956e-04 - val_loss: 9.7339e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0589e-04 - val_loss: 9.4341e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8876e-04 - val_loss: 9.2402e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7663e-04 - val_loss: 8.9440e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7162e-04 - val_loss: 8.7474e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5807e-04 - val_loss: 8.5544e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4412e-04 - val_loss: 8.5012e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4311e-04 - val_loss: 8.4849e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3619e-04 - val_loss: 8.2009e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2838e-04 - val_loss: 7.9260e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2135e-04 - val_loss: 7.7941e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1580e-04 - val_loss: 7.6035e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0832e-04 - val_loss: 7.5903e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0228e-04 - val_loss: 7.5046e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9151e-05 - val_loss: 7.4550e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4328e-05 - val_loss: 7.3336e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.9581e-05 - val_loss: 7.1641e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.8030e-05 - val_loss: 7.0573e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3416e-05 - val_loss: 6.9814e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9919e-05 - val_loss: 6.9266e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.5614e-05 - val_loss: 6.7866e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4623e-05 - val_loss: 6.6844e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1352e-05 - val_loss: 6.6818e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8909e-05 - val_loss: 6.6709e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5362e-05 - val_loss: 6.6181e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.2921e-05 - val_loss: 6.4432e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3900e-05 - val_loss: 6.3737e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8341e-05 - val_loss: 6.3587e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6719e-05 - val_loss: 6.3566e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5534e-05 - val_loss: 6.2595e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3102e-05 - val_loss: 6.2083e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2036e-05 - val_loss: 6.1332e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0240e-05 - val_loss: 6.1336e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9028e-05 - val_loss: 6.1295e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6788e-05 - val_loss: 6.0372e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.6024e-05 - val_loss: 5.9565e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.4379e-05 - val_loss: 5.9602e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3219e-05 - val_loss: 5.8740e-04\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.1881e-05 - val_loss: 5.8942e-04\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 4.0755e-05 - val_loss: 5.8287e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9818e-05 - val_loss: 5.7980e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8283e-05 - val_loss: 5.7962e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7174e-05 - val_loss: 5.7567e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6293e-05 - val_loss: 5.7654e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6297e-05 - val_loss: 5.7184e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3991e-05 - val_loss: 5.7062e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4351e-05 - val_loss: 5.6340e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2569e-05 - val_loss: 5.5516e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1892e-05 - val_loss: 5.5771e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.1056e-05 - val_loss: 5.5853e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1549e-05 - val_loss: 5.4602e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9116e-05 - val_loss: 5.5052e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.9182e-05 - val_loss: 5.5882e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8355e-05 - val_loss: 5.5109e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7239e-05 - val_loss: 5.4258e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.6571e-05 - val_loss: 5.4347e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6397e-05 - val_loss: 5.4460e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5793e-05 - val_loss: 5.3930e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5061e-05 - val_loss: 5.3823e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4046e-05 - val_loss: 5.3262e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.3521e-05 - val_loss: 5.3028e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.3551e-05 - val_loss: 5.3087e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.3192e-05 - val_loss: 5.3273e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2260e-05 - val_loss: 5.3170e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1430e-05 - val_loss: 5.2761e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.1689e-05 - val_loss: 5.2080e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1070e-05 - val_loss: 5.2331e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0508e-05 - val_loss: 5.2652e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0267e-05 - val_loss: 5.2027e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8886e-05 - val_loss: 5.1783e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9041e-05 - val_loss: 5.1670e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8783e-05 - val_loss: 5.1624e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7682e-05 - val_loss: 5.1634e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7653e-05 - val_loss: 5.1446e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7515e-05 - val_loss: 5.1158e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7726e-05 - val_loss: 5.0718e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6797e-05 - val_loss: 5.0851e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6474e-05 - val_loss: 5.0462e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6273e-05 - val_loss: 5.0150e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6243e-05 - val_loss: 5.0276e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4616e-05 - val_loss: 5.0222e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5019e-05 - val_loss: 4.9985e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.4298e-05 - val_loss: 4.9883e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4284e-05 - val_loss: 4.9642e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3838e-05 - val_loss: 4.9544e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3909e-05 - val_loss: 4.9630e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4260e-05 - val_loss: 4.9172e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3099e-05 - val_loss: 4.9534e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3086e-05 - val_loss: 4.9300e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2497e-05 - val_loss: 4.9117e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2333e-05 - val_loss: 4.9276e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2785e-05 - val_loss: 4.8919e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2120e-05 - val_loss: 4.8950e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2136e-05 - val_loss: 4.8882e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1885e-05 - val_loss: 4.8724e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1661e-05 - val_loss: 4.8724e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1657e-05 - val_loss: 4.8569e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0952e-05 - val_loss: 4.8341e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1048e-05 - val_loss: 4.8427e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1024e-05 - val_loss: 4.8370e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1724e-05 - val_loss: 4.8228e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0321e-05 - val_loss: 4.7609e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0928e-05 - val_loss: 4.8262e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0455e-05 - val_loss: 4.8516e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1153e-05 - val_loss: 4.8242e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0166e-05 - val_loss: 4.7909e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0871e-05 - val_loss: 4.7128e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0012e-05 - val_loss: 4.8073e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0217e-05 - val_loss: 4.7796e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5916e-06 - val_loss: 4.7325e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.3937e-06 - val_loss: 4.7891e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.2161e-06 - val_loss: 4.7660e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.0647e-06 - val_loss: 4.7177e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7750e-06 - val_loss: 4.7160e-04\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.6844e-06 - val_loss: 4.7142e-04\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7953e-06 - val_loss: 4.7150e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7190e-06 - val_loss: 4.7143e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1040e-06 - val_loss: 4.6678e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1267e-06 - val_loss: 4.7064e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.2123e-06 - val_loss: 4.7285e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.1086e-06 - val_loss: 4.6868e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.4603e-06 - val_loss: 4.6540e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3995e-06 - val_loss: 4.6745e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3232e-06 - val_loss: 4.6865e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9954e-06 - val_loss: 4.6335e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.6629e-06 - val_loss: 4.6437e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.1038e-06 - val_loss: 4.6629e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.6532e-06 - val_loss: 4.6228e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6476e-06 - val_loss: 4.6664e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3659e-06 - val_loss: 4.6620e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3613e-06 - val_loss: 4.5746e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4518e-06 - val_loss: 4.6117e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6413e-06 - val_loss: 4.6235e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7546e-06 - val_loss: 4.6057e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0274e-06 - val_loss: 4.6093e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.0739e-06 - val_loss: 4.6095e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.1609e-06 - val_loss: 4.6000e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6590e-06 - val_loss: 4.5876e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1692e-06 - val_loss: 4.5583e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7317e-06 - val_loss: 4.5936e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.4029e-06 - val_loss: 4.5691e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3598e-06 - val_loss: 4.5415e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7806e-06 - val_loss: 4.5850e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.2668e-06 - val_loss: 4.5790e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1750e-06 - val_loss: 4.5218e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4850e-06 - val_loss: 4.5125e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8818e-06 - val_loss: 4.5626e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8746e-06 - val_loss: 4.5373e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8925e-06 - val_loss: 4.5501e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8007e-06 - val_loss: 4.5137e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1655e-06 - val_loss: 4.4913e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7425e-06 - val_loss: 4.4988e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4063e-06 - val_loss: 4.5183e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8782e-06 - val_loss: 4.4856e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2251e-06 - val_loss: 4.5827e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9630e-06 - val_loss: 4.4667e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7902e-06 - val_loss: 4.4436e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3837e-06 - val_loss: 4.5316e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6338e-06 - val_loss: 4.4268e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.9688e-06 - val_loss: 4.4807e-04\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a2c50f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 5.2003e-04 - 176ms/epoch - 176ms/step\n",
      "tf.Tensor((0.9994799637530694+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5b5d7",
   "metadata": {},
   "source": [
    "## Bit-Phase Flip Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "412717a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density matrix with noise type: complex128\n",
      "Bloch vector with noise type: float64\n"
     ]
    }
   ],
   "source": [
    "#APPLY ERROR (in this case phase error with p=0.2)\n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = flip_error(1, density_matrix_noise_free[i], 'bp', 0.2)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "\n",
    "#PRINT THE TYPE OF THE SINGLE DENSITY MATRIX IN THE LISTS OF THE DENSITY MATRICES WITH NOISE\n",
    "print(\"Density matrix with noise type:\", density_matrix_with_noise[0].dtype)\n",
    "\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]\n",
    "print(\"Bloch vector with noise type:\", bloch_vectors_with_noise[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f945c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: <dtype: 'float64'>\n",
      "Output data type: <dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "print(\"Input data type:\", x_train.dtype)\n",
    "print(\"Output data type:\", y_train.dtype)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd48c99",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2de0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12296a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 71ms/step - loss: 0.3324 - val_loss: 0.3043\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2832 - val_loss: 0.2675\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2407 - val_loss: 0.2322\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2026 - val_loss: 0.2000\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1681 - val_loss: 0.1689\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1348 - val_loss: 0.1394\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1054 - val_loss: 0.1126\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0799 - val_loss: 0.0886\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0589 - val_loss: 0.0687\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0436 - val_loss: 0.0524\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0319 - val_loss: 0.0393\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0230 - val_loss: 0.0286\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0113 - val_loss: 0.0138\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0083 - val_loss: 0.0095\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4135e-04 - val_loss: 0.0017\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3874e-04 - val_loss: 0.0016\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8060e-04 - val_loss: 0.0015\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2022e-04 - val_loss: 0.0014\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6116e-04 - val_loss: 0.0013\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1469e-04 - val_loss: 0.0013\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6898e-04 - val_loss: 0.0012\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2941e-04 - val_loss: 0.0012\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0195e-04 - val_loss: 0.0011\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7166e-04 - val_loss: 0.0011\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.3850e-04 - val_loss: 0.0011\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1616e-04 - val_loss: 0.0011\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9235e-04 - val_loss: 0.0010\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.7985e-04 - val_loss: 0.0010\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5642e-04 - val_loss: 9.5768e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3433e-04 - val_loss: 9.4138e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.2144e-04 - val_loss: 9.7975e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0266e-04 - val_loss: 9.1912e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8595e-04 - val_loss: 9.1549e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7360e-04 - val_loss: 8.9841e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.5751e-04 - val_loss: 8.7979e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.4774e-04 - val_loss: 8.4569e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3691e-04 - val_loss: 8.5083e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.1999e-04 - val_loss: 8.3846e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.1643e-04 - val_loss: 8.2599e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0445e-04 - val_loss: 7.8232e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9623e-04 - val_loss: 7.8828e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8694e-04 - val_loss: 7.8038e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7891e-04 - val_loss: 7.6704e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.7265e-04 - val_loss: 7.6362e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7087e-04 - val_loss: 7.4721e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5947e-04 - val_loss: 7.2297e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4937e-04 - val_loss: 7.3145e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.4697e-04 - val_loss: 7.2399e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4228e-04 - val_loss: 6.9619e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3468e-04 - val_loss: 7.0153e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3102e-04 - val_loss: 7.0520e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2682e-04 - val_loss: 6.6983e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2195e-04 - val_loss: 6.7752e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1561e-04 - val_loss: 6.7817e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1674e-04 - val_loss: 6.8068e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0962e-04 - val_loss: 6.2939e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0843e-04 - val_loss: 6.4624e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0267e-04 - val_loss: 6.4621e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9243e-05 - val_loss: 6.3371e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6490e-05 - val_loss: 6.3421e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1527e-05 - val_loss: 6.2241e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.2387e-05 - val_loss: 6.0057e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6456e-05 - val_loss: 6.2790e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6179e-05 - val_loss: 6.0814e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.1462e-05 - val_loss: 5.7711e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1111e-05 - val_loss: 5.9521e-04\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6643e-05 - val_loss: 5.9995e-04\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3626e-05 - val_loss: 5.8636e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1559e-05 - val_loss: 5.8307e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0361e-05 - val_loss: 5.6688e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0003e-05 - val_loss: 5.8226e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.6749e-05 - val_loss: 5.6230e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4787e-05 - val_loss: 5.7038e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3812e-05 - val_loss: 5.5774e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1495e-05 - val_loss: 5.5682e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2282e-05 - val_loss: 5.5375e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8969e-05 - val_loss: 5.5814e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6557e-05 - val_loss: 5.4372e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5413e-05 - val_loss: 5.4775e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4658e-05 - val_loss: 5.4297e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3344e-05 - val_loss: 5.4015e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.0420e-05 - val_loss: 5.2576e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0220e-05 - val_loss: 5.3593e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.9507e-05 - val_loss: 5.2621e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7244e-05 - val_loss: 5.2321e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6801e-05 - val_loss: 5.1906e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6459e-05 - val_loss: 5.2316e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5393e-05 - val_loss: 5.2655e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6007e-05 - val_loss: 5.1043e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3799e-05 - val_loss: 5.1507e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.1378e-05 - val_loss: 5.2660e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0774e-05 - val_loss: 5.0555e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.1104e-05 - val_loss: 4.9357e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9567e-05 - val_loss: 5.2218e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8511e-05 - val_loss: 4.9446e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8376e-05 - val_loss: 4.9712e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8496e-05 - val_loss: 5.1759e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7138e-05 - val_loss: 4.8730e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.6206e-05 - val_loss: 5.0507e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4146e-05 - val_loss: 4.9235e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3114e-05 - val_loss: 4.8985e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4101e-05 - val_loss: 4.9398e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4205e-05 - val_loss: 4.7312e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1569e-05 - val_loss: 4.9816e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.2589e-05 - val_loss: 4.9273e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.2344e-05 - val_loss: 4.5617e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9645e-05 - val_loss: 4.9659e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1966e-05 - val_loss: 4.8576e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.9496e-05 - val_loss: 4.5695e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8963e-05 - val_loss: 4.7992e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8259e-05 - val_loss: 4.7696e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.6274e-05 - val_loss: 4.6068e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.5914e-05 - val_loss: 4.6302e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6060e-05 - val_loss: 4.7456e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.5499e-05 - val_loss: 4.7141e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.4173e-05 - val_loss: 4.5263e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.3908e-05 - val_loss: 4.6645e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.3116e-05 - val_loss: 4.6769e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.2762e-05 - val_loss: 4.5362e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.3710e-05 - val_loss: 4.5789e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.1714e-05 - val_loss: 4.4667e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1148e-05 - val_loss: 4.6028e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1268e-05 - val_loss: 4.6004e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.0583e-05 - val_loss: 4.5223e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1674e-05 - val_loss: 4.4822e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9244e-05 - val_loss: 4.5679e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0570e-05 - val_loss: 4.4720e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9468e-05 - val_loss: 4.4040e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8153e-05 - val_loss: 4.5167e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8358e-05 - val_loss: 4.4578e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8106e-05 - val_loss: 4.3689e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7510e-05 - val_loss: 4.4603e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.7176e-05 - val_loss: 4.3754e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.7619e-05 - val_loss: 4.3523e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6675e-05 - val_loss: 4.4410e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6981e-05 - val_loss: 4.3929e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.7067e-05 - val_loss: 4.2942e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5314e-05 - val_loss: 4.3615e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5860e-05 - val_loss: 4.3071e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5259e-05 - val_loss: 4.3724e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4556e-05 - val_loss: 4.2637e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.4657e-05 - val_loss: 4.3193e-04\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4497e-05 - val_loss: 4.2914e-04\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4238e-05 - val_loss: 4.2389e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3733e-05 - val_loss: 4.3267e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3725e-05 - val_loss: 4.2517e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3328e-05 - val_loss: 4.2492e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2849e-05 - val_loss: 4.2711e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2883e-05 - val_loss: 4.1447e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2700e-05 - val_loss: 4.1938e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.2690e-05 - val_loss: 4.2068e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2360e-05 - val_loss: 4.1997e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2814e-05 - val_loss: 4.2268e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2940e-05 - val_loss: 4.0618e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1727e-05 - val_loss: 4.2638e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1646e-05 - val_loss: 4.1030e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2204e-05 - val_loss: 4.0891e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1272e-05 - val_loss: 4.2183e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2620e-05 - val_loss: 4.1064e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1340e-05 - val_loss: 4.1689e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2140e-05 - val_loss: 4.0669e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.1645e-05 - val_loss: 4.0764e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0808e-05 - val_loss: 4.1627e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0347e-05 - val_loss: 4.0356e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0050e-05 - val_loss: 4.1004e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.7559e-06 - val_loss: 4.0705e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.3537e-06 - val_loss: 4.0138e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4758e-06 - val_loss: 4.0349e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.9474e-06 - val_loss: 4.0193e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.8571e-06 - val_loss: 4.0293e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6008e-06 - val_loss: 4.0401e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7490e-06 - val_loss: 4.0395e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5169e-06 - val_loss: 3.9926e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7818e-06 - val_loss: 4.0240e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4849e-06 - val_loss: 3.9113e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.3106e-06 - val_loss: 4.0639e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.4106e-06 - val_loss: 3.9620e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.3752e-06 - val_loss: 3.9297e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.1290e-06 - val_loss: 4.0097e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4464e-06 - val_loss: 3.9116e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.5443e-06 - val_loss: 4.0009e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2643e-06 - val_loss: 3.9551e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8849e-06 - val_loss: 3.9416e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.8651e-06 - val_loss: 3.8699e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8560e-06 - val_loss: 3.9518e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8669e-06 - val_loss: 3.8512e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0093e-06 - val_loss: 3.9482e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9504e-06 - val_loss: 3.9234e-04\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=loss_fn)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10022767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 6.8123e-05 - 167ms/epoch - 167ms/step\n",
      "tf.Tensor((1.0020681254800978+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df919f",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77ca4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "860b6274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 91ms/step - loss: 0.4027 - val_loss: 0.2550\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1404 - val_loss: 0.0674\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0442 - val_loss: 0.0509\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0286 - val_loss: 0.0317\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5329e-04 - val_loss: 0.0033\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5766e-04 - val_loss: 0.0032\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.9206e-04 - val_loss: 0.0031\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3219e-04 - val_loss: 0.0030\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7296e-04 - val_loss: 0.0029\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3086e-04 - val_loss: 0.0028\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9199e-04 - val_loss: 0.0028\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4374e-04 - val_loss: 0.0027\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9793e-04 - val_loss: 0.0027\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6774e-04 - val_loss: 0.0026\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4133e-04 - val_loss: 0.0026\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.2764e-04 - val_loss: 0.0025\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9003e-04 - val_loss: 0.0025\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.7360e-04 - val_loss: 0.0025\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5080e-04 - val_loss: 0.0024\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.3230e-04 - val_loss: 0.0023\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.2129e-04 - val_loss: 0.0023\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.0817e-04 - val_loss: 0.0024\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8951e-04 - val_loss: 0.0023\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.7863e-04 - val_loss: 0.0022\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.6181e-04 - val_loss: 0.0022\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5490e-04 - val_loss: 0.0022\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4315e-04 - val_loss: 0.0022\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3829e-04 - val_loss: 0.0023\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.2910e-04 - val_loss: 0.0021\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.1820e-04 - val_loss: 0.0021\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0515e-04 - val_loss: 0.0021\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9730e-04 - val_loss: 0.0021\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9120e-04 - val_loss: 0.0021\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.8561e-04 - val_loss: 0.0021\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8094e-04 - val_loss: 0.0020\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7068e-04 - val_loss: 0.0020\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6907e-04 - val_loss: 0.0020\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6360e-04 - val_loss: 0.0020\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5602e-04 - val_loss: 0.0020\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4771e-04 - val_loss: 0.0020\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4817e-04 - val_loss: 0.0020\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.3738e-04 - val_loss: 0.0020\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.3567e-04 - val_loss: 0.0019\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3182e-04 - val_loss: 0.0019\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2606e-04 - val_loss: 0.0019\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2593e-04 - val_loss: 0.0019\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1997e-04 - val_loss: 0.0019\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.1755e-04 - val_loss: 0.0019\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1490e-04 - val_loss: 0.0018\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0918e-04 - val_loss: 0.0018\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0548e-04 - val_loss: 0.0019\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0648e-04 - val_loss: 0.0019\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.8288e-05 - val_loss: 0.0018\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0731e-04 - val_loss: 0.0017\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3857e-05 - val_loss: 0.0018\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.1436e-05 - val_loss: 0.0018\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1859e-05 - val_loss: 0.0018\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6111e-05 - val_loss: 0.0017\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5886e-05 - val_loss: 0.0018\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3532e-05 - val_loss: 0.0018\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8310e-05 - val_loss: 0.0017\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.8864e-05 - val_loss: 0.0017\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3404e-05 - val_loss: 0.0017\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4108e-05 - val_loss: 0.0017\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1161e-05 - val_loss: 0.0017\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.7466e-05 - val_loss: 0.0017\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7337e-05 - val_loss: 0.0017\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6553e-05 - val_loss: 0.0017\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0916e-05 - val_loss: 0.0017\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2581e-05 - val_loss: 0.0017\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5714e-05 - val_loss: 0.0017\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8045e-05 - val_loss: 0.0016\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4549e-05 - val_loss: 0.0017\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3746e-05 - val_loss: 0.0016\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0371e-05 - val_loss: 0.0016\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9696e-05 - val_loss: 0.0016\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7004e-05 - val_loss: 0.0017\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6179e-05 - val_loss: 0.0016\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.3951e-05 - val_loss: 0.0016\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4838e-05 - val_loss: 0.0016\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1713e-05 - val_loss: 0.0016\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1331e-05 - val_loss: 0.0016\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0826e-05 - val_loss: 0.0016\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8875e-05 - val_loss: 0.0016\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8333e-05 - val_loss: 0.0016\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.7981e-05 - val_loss: 0.0016\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.6443e-05 - val_loss: 0.0016\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5228e-05 - val_loss: 0.0016\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.5204e-05 - val_loss: 0.0016\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4583e-05 - val_loss: 0.0016\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3933e-05 - val_loss: 0.0016\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.1781e-05 - val_loss: 0.0016\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.1649e-05 - val_loss: 0.0016\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.0757e-05 - val_loss: 0.0016\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.1241e-05 - val_loss: 0.0015\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8726e-05 - val_loss: 0.0016\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8627e-05 - val_loss: 0.0016\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7755e-05 - val_loss: 0.0016\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.7837e-05 - val_loss: 0.0016\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7608e-05 - val_loss: 0.0015\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4915e-05 - val_loss: 0.0016\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.4714e-05 - val_loss: 0.0016\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4447e-05 - val_loss: 0.0015\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.4801e-05 - val_loss: 0.0015\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.2994e-05 - val_loss: 0.0015\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.4493e-05 - val_loss: 0.0015\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.2724e-05 - val_loss: 0.0016\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2833e-05 - val_loss: 0.0016\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1698e-05 - val_loss: 0.0015\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.1882e-05 - val_loss: 0.0015\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0435e-05 - val_loss: 0.0015\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9969e-05 - val_loss: 0.0015\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8778e-05 - val_loss: 0.0015\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9078e-05 - val_loss: 0.0015\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7939e-05 - val_loss: 0.0015\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7146e-05 - val_loss: 0.0015\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7227e-05 - val_loss: 0.0015\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6123e-05 - val_loss: 0.0015\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5699e-05 - val_loss: 0.0016\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5492e-05 - val_loss: 0.0015\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6260e-05 - val_loss: 0.0015\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4302e-05 - val_loss: 0.0015\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.4398e-05 - val_loss: 0.0015\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4054e-05 - val_loss: 0.0015\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4141e-05 - val_loss: 0.0015\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3379e-05 - val_loss: 0.0015\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2918e-05 - val_loss: 0.0015\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.3113e-05 - val_loss: 0.0015\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3715e-05 - val_loss: 0.0015\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2517e-05 - val_loss: 0.0015\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2108e-05 - val_loss: 0.0015\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1501e-05 - val_loss: 0.0015\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1295e-05 - val_loss: 0.0015\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0700e-05 - val_loss: 0.0015\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0741e-05 - val_loss: 0.0015\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0439e-05 - val_loss: 0.0015\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0006e-05 - val_loss: 0.0015\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0223e-05 - val_loss: 0.0015\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7285e-06 - val_loss: 0.0015\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9286e-06 - val_loss: 0.0015\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8654e-06 - val_loss: 0.0015\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0989e-06 - val_loss: 0.0015\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3469e-06 - val_loss: 0.0015\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6699e-06 - val_loss: 0.0015\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2885e-06 - val_loss: 0.0015\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1681e-06 - val_loss: 0.0015\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6459e-06 - val_loss: 0.0015\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9821e-06 - val_loss: 0.0015\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6495e-06 - val_loss: 0.0015\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2048e-06 - val_loss: 0.0015\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8949e-06 - val_loss: 0.0015\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2716e-06 - val_loss: 0.0015\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0892e-06 - val_loss: 0.0015\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4884e-06 - val_loss: 0.0015\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7578e-06 - val_loss: 0.0015\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5015e-06 - val_loss: 0.0014\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0211e-06 - val_loss: 0.0014\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2226e-06 - val_loss: 0.0014\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6301e-06 - val_loss: 0.0015\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4358e-06 - val_loss: 0.0015\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4763e-06 - val_loss: 0.0014\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3595e-06 - val_loss: 0.0015\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3929e-06 - val_loss: 0.0014\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3821e-06 - val_loss: 0.0014\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1234e-06 - val_loss: 0.0014\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0162e-06 - val_loss: 0.0014\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2832e-06 - val_loss: 0.0015\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8981e-06 - val_loss: 0.0014\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8481e-06 - val_loss: 0.0014\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.7587e-06 - val_loss: 0.0014\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.5894e-06 - val_loss: 0.0014\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4523e-06 - val_loss: 0.0014\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4082e-06 - val_loss: 0.0014\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3808e-06 - val_loss: 0.0014\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3009e-06 - val_loss: 0.0014\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2365e-06 - val_loss: 0.0014\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2306e-06 - val_loss: 0.0014\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.0947e-06 - val_loss: 0.0014\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.0410e-06 - val_loss: 0.0014\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0839e-06 - val_loss: 0.0014\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.0851e-06 - val_loss: 0.0014\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.9147e-06 - val_loss: 0.0014\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7716e-06 - val_loss: 0.0014\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.0255e-06 - val_loss: 0.0014\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7072e-06 - val_loss: 0.0014\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8074e-06 - val_loss: 0.0014\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7263e-06 - val_loss: 0.0014\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.6858e-06 - val_loss: 0.0014\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.5606e-06 - val_loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0215ec12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 3.4182e-04 - 234ms/epoch - 234ms/step\n",
      "tf.Tensor((0.9996581697266729+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518daec7",
   "metadata": {},
   "source": [
    "## General Pauli Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89886c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY ERROR \n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = g_pauli_error(1, density_matrix_noise_free[i], 0.7, 0.1, 0.1, 0.1)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a030dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08407175",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68c10b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2e16e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 65ms/step - loss: 0.2920 - val_loss: 0.2692\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2480 - val_loss: 0.2328\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2087 - val_loss: 0.1983\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1736 - val_loss: 0.1672\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1420 - val_loss: 0.1387\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1132 - val_loss: 0.1117\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0871 - val_loss: 0.0876\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0641 - val_loss: 0.0656\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0450 - val_loss: 0.0472\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0294 - val_loss: 0.0323\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0183 - val_loss: 0.0212\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0072 - val_loss: 0.0088\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7690e-04 - val_loss: 0.0017\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5259e-04 - val_loss: 0.0016\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0636e-04 - val_loss: 0.0015\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3135e-04 - val_loss: 0.0014\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.6841e-04 - val_loss: 0.0013\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2780e-04 - val_loss: 0.0012\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7890e-04 - val_loss: 0.0011\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4208e-04 - val_loss: 0.0011\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0885e-04 - val_loss: 0.0010\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.8294e-04 - val_loss: 9.8468e-04\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5595e-04 - val_loss: 9.4387e-04\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.3870e-04 - val_loss: 9.0450e-04\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.1094e-04 - val_loss: 8.8963e-04\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.9386e-04 - val_loss: 8.5697e-04\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.7898e-04 - val_loss: 8.3069e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.6866e-04 - val_loss: 8.1087e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4749e-04 - val_loss: 7.7693e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.3584e-04 - val_loss: 7.5442e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2926e-04 - val_loss: 7.4164e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1342e-04 - val_loss: 7.3111e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0201e-04 - val_loss: 7.0278e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9483e-04 - val_loss: 6.8804e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8693e-04 - val_loss: 6.7465e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7773e-04 - val_loss: 6.7127e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7073e-04 - val_loss: 6.5554e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6360e-04 - val_loss: 6.4168e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5746e-04 - val_loss: 6.3529e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5012e-04 - val_loss: 6.2096e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4865e-04 - val_loss: 6.0356e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3833e-04 - val_loss: 5.9851e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3371e-04 - val_loss: 5.8561e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2728e-04 - val_loss: 5.7528e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2286e-04 - val_loss: 5.5878e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1682e-04 - val_loss: 5.6109e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1404e-04 - val_loss: 5.5780e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0813e-04 - val_loss: 5.4493e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0483e-04 - val_loss: 5.3688e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9977e-05 - val_loss: 5.2833e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.9178e-05 - val_loss: 5.2289e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4645e-05 - val_loss: 5.0768e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1132e-05 - val_loss: 5.0333e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.0266e-05 - val_loss: 5.0804e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7159e-05 - val_loss: 4.9822e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5890e-05 - val_loss: 4.8746e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0163e-05 - val_loss: 4.8657e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9512e-05 - val_loss: 4.9112e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5347e-05 - val_loss: 4.7243e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4682e-05 - val_loss: 4.6717e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1971e-05 - val_loss: 4.6455e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0464e-05 - val_loss: 4.6336e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7468e-05 - val_loss: 4.5129e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7725e-05 - val_loss: 4.5509e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2502e-05 - val_loss: 4.4650e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1340e-05 - val_loss: 4.4817e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9240e-05 - val_loss: 4.5073e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8247e-05 - val_loss: 4.4594e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7447e-05 - val_loss: 4.2446e-04\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5657e-05 - val_loss: 4.2755e-04\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2683e-05 - val_loss: 4.3725e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2619e-05 - val_loss: 4.3304e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9871e-05 - val_loss: 4.2194e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9994e-05 - val_loss: 4.2576e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9861e-05 - val_loss: 4.2525e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7065e-05 - val_loss: 4.2031e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5870e-05 - val_loss: 4.1836e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.4520e-05 - val_loss: 4.1260e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2078e-05 - val_loss: 4.1472e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.4027e-05 - val_loss: 4.1462e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1903e-05 - val_loss: 4.1481e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1264e-05 - val_loss: 4.0434e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8557e-05 - val_loss: 4.0374e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.7671e-05 - val_loss: 4.0140e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.7178e-05 - val_loss: 3.9385e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6114e-05 - val_loss: 3.9525e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4849e-05 - val_loss: 3.9906e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4382e-05 - val_loss: 3.9537e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.3761e-05 - val_loss: 3.8834e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.2547e-05 - val_loss: 3.8837e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3195e-05 - val_loss: 3.8540e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3966e-05 - val_loss: 3.9057e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0881e-05 - val_loss: 3.8264e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1464e-05 - val_loss: 3.7841e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1334e-05 - val_loss: 3.8774e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.9666e-05 - val_loss: 3.7270e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.8263e-05 - val_loss: 3.8258e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7076e-05 - val_loss: 3.7810e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.6373e-05 - val_loss: 3.7405e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.5776e-05 - val_loss: 3.7764e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.6161e-05 - val_loss: 3.7210e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4955e-05 - val_loss: 3.6990e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4668e-05 - val_loss: 3.7208e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3813e-05 - val_loss: 3.7079e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.3645e-05 - val_loss: 3.7215e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.3066e-05 - val_loss: 3.6251e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1986e-05 - val_loss: 3.6359e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2103e-05 - val_loss: 3.7113e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1509e-05 - val_loss: 3.6161e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0719e-05 - val_loss: 3.6326e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1075e-05 - val_loss: 3.6442e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9783e-05 - val_loss: 3.5943e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.9890e-05 - val_loss: 3.5849e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9531e-05 - val_loss: 3.6441e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8703e-05 - val_loss: 3.6054e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8518e-05 - val_loss: 3.5178e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8380e-05 - val_loss: 3.5838e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7505e-05 - val_loss: 3.5578e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7132e-05 - val_loss: 3.5656e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6870e-05 - val_loss: 3.5511e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7090e-05 - val_loss: 3.5135e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6214e-05 - val_loss: 3.5752e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.6023e-05 - val_loss: 3.5255e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6197e-05 - val_loss: 3.4470e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5159e-05 - val_loss: 3.5188e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5798e-05 - val_loss: 3.4910e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4460e-05 - val_loss: 3.4629e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4327e-05 - val_loss: 3.5218e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4236e-05 - val_loss: 3.5015e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4351e-05 - val_loss: 3.4543e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3737e-05 - val_loss: 3.5079e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3580e-05 - val_loss: 3.4729e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2773e-05 - val_loss: 3.4672e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3232e-05 - val_loss: 3.4766e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2796e-05 - val_loss: 3.4295e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2144e-05 - val_loss: 3.4886e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2898e-05 - val_loss: 3.4700e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1686e-05 - val_loss: 3.4477e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1643e-05 - val_loss: 3.4592e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1255e-05 - val_loss: 3.4232e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1206e-05 - val_loss: 3.4375e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1223e-05 - val_loss: 3.4188e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0651e-05 - val_loss: 3.4236e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0633e-05 - val_loss: 3.4208e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0830e-05 - val_loss: 3.4327e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0814e-05 - val_loss: 3.3775e-04\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0196e-05 - val_loss: 3.3704e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.8121e-06 - val_loss: 3.4127e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0068e-05 - val_loss: 3.3964e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4875e-06 - val_loss: 3.3762e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.5047e-06 - val_loss: 3.3687e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5284e-06 - val_loss: 3.4051e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5228e-06 - val_loss: 3.3764e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6555e-06 - val_loss: 3.3281e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3798e-06 - val_loss: 3.3367e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.8044e-06 - val_loss: 3.3769e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5127e-06 - val_loss: 3.3886e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6832e-06 - val_loss: 3.3493e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4921e-06 - val_loss: 3.3089e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5976e-06 - val_loss: 3.3420e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0634e-06 - val_loss: 3.3168e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0607e-06 - val_loss: 3.3278e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3962e-06 - val_loss: 3.3246e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1132e-06 - val_loss: 3.3361e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.1148e-06 - val_loss: 3.2855e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3733e-06 - val_loss: 3.2906e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.5076e-06 - val_loss: 3.2905e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6973e-06 - val_loss: 3.2855e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.7730e-06 - val_loss: 3.2761e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5031e-06 - val_loss: 3.2885e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2324e-06 - val_loss: 3.3356e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2824e-06 - val_loss: 3.2359e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9275e-06 - val_loss: 3.2333e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6782e-06 - val_loss: 3.2561e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6031e-06 - val_loss: 3.2803e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9201e-06 - val_loss: 3.2559e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3533e-06 - val_loss: 3.2480e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4106e-06 - val_loss: 3.2366e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7131e-06 - val_loss: 3.2352e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4756e-06 - val_loss: 3.2533e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8135e-06 - val_loss: 3.2229e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3752e-06 - val_loss: 3.1789e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1574e-06 - val_loss: 3.2577e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2823e-06 - val_loss: 3.2317e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9762e-06 - val_loss: 3.2103e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0291e-06 - val_loss: 3.2442e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0013e-06 - val_loss: 3.1825e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9980e-06 - val_loss: 3.1911e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1082e-06 - val_loss: 3.2108e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.6495e-06 - val_loss: 3.1774e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6457e-06 - val_loss: 3.1712e-04\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=loss_fn)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac450e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 8.2074e-05 - 217ms/epoch - 217ms/step\n",
      "tf.Tensor((1.000344825592792+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf29531",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d84e2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d345af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 90ms/step - loss: 0.4356 - val_loss: 0.3076\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2349 - val_loss: 0.1562\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1357 - val_loss: 0.0740\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0605 - val_loss: 0.0442\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0329 - val_loss: 0.0299\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0182 - val_loss: 0.0183\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0125\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0057 - val_loss: 0.0100\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0048 - val_loss: 0.0085\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0026 - val_loss: 0.0054\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0013 - val_loss: 0.0042\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5222e-04 - val_loss: 0.0036\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5416e-04 - val_loss: 0.0034\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8917e-04 - val_loss: 0.0032\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1248e-04 - val_loss: 0.0031\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.5714e-04 - val_loss: 0.0030\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0855e-04 - val_loss: 0.0029\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5318e-04 - val_loss: 0.0028\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1457e-04 - val_loss: 0.0028\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.8519e-04 - val_loss: 0.0026\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.5224e-04 - val_loss: 0.0026\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1632e-04 - val_loss: 0.0025\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8547e-04 - val_loss: 0.0024\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6140e-04 - val_loss: 0.0024\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3521e-04 - val_loss: 0.0023\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1809e-04 - val_loss: 0.0023\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.9774e-04 - val_loss: 0.0023\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.7656e-04 - val_loss: 0.0022\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.6423e-04 - val_loss: 0.0022\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.4657e-04 - val_loss: 0.0022\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2931e-04 - val_loss: 0.0021\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.2015e-04 - val_loss: 0.0021\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.1419e-04 - val_loss: 0.0021\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0232e-04 - val_loss: 0.0020\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.8665e-04 - val_loss: 0.0020\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7937e-04 - val_loss: 0.0020\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7398e-04 - val_loss: 0.0020\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6077e-04 - val_loss: 0.0019\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5568e-04 - val_loss: 0.0019\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.4723e-04 - val_loss: 0.0019\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4505e-04 - val_loss: 0.0019\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3673e-04 - val_loss: 0.0019\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2919e-04 - val_loss: 0.0018\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2572e-04 - val_loss: 0.0018\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1990e-04 - val_loss: 0.0018\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1220e-04 - val_loss: 0.0018\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0824e-04 - val_loss: 0.0018\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0668e-04 - val_loss: 0.0018\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9931e-05 - val_loss: 0.0018\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7494e-05 - val_loss: 0.0017\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1726e-05 - val_loss: 0.0017\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8320e-05 - val_loss: 0.0017\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.4432e-05 - val_loss: 0.0017\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2068e-05 - val_loss: 0.0017\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6258e-05 - val_loss: 0.0017\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3681e-05 - val_loss: 0.0017\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0295e-05 - val_loss: 0.0017\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7482e-05 - val_loss: 0.0016\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5434e-05 - val_loss: 0.0016\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3313e-05 - val_loss: 0.0016\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9669e-05 - val_loss: 0.0016\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7213e-05 - val_loss: 0.0016\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5082e-05 - val_loss: 0.0016\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2351e-05 - val_loss: 0.0016\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0716e-05 - val_loss: 0.0016\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8525e-05 - val_loss: 0.0016\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.7950e-05 - val_loss: 0.0015\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5049e-05 - val_loss: 0.0015\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3714e-05 - val_loss: 0.0015\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2051e-05 - val_loss: 0.0015\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9976e-05 - val_loss: 0.0015\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8234e-05 - val_loss: 0.0015\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7237e-05 - val_loss: 0.0015\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 18ms/step - loss: 3.5725e-05 - val_loss: 0.0015\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4993e-05 - val_loss: 0.0015\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3394e-05 - val_loss: 0.0015\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.2647e-05 - val_loss: 0.0015\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.0310e-05 - val_loss: 0.0015\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.9756e-05 - val_loss: 0.0014\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8397e-05 - val_loss: 0.0014\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7786e-05 - val_loss: 0.0014\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7164e-05 - val_loss: 0.0014\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5543e-05 - val_loss: 0.0014\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7114e-05 - val_loss: 0.0014\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.3541e-05 - val_loss: 0.0014\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4776e-05 - val_loss: 0.0014\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2417e-05 - val_loss: 0.0014\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1503e-05 - val_loss: 0.0014\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1414e-05 - val_loss: 0.0014\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0558e-05 - val_loss: 0.0014\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9784e-05 - val_loss: 0.0014\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.9350e-05 - val_loss: 0.0014\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8749e-05 - val_loss: 0.0014\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8456e-05 - val_loss: 0.0014\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8206e-05 - val_loss: 0.0014\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6549e-05 - val_loss: 0.0013\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.6414e-05 - val_loss: 0.0013\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5966e-05 - val_loss: 0.0013\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5937e-05 - val_loss: 0.0013\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5097e-05 - val_loss: 0.0013\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4533e-05 - val_loss: 0.0013\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5228e-05 - val_loss: 0.0013\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4201e-05 - val_loss: 0.0013\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.4517e-05 - val_loss: 0.0013\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3255e-05 - val_loss: 0.0013\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2879e-05 - val_loss: 0.0013\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2659e-05 - val_loss: 0.0013\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2689e-05 - val_loss: 0.0013\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1933e-05 - val_loss: 0.0013\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1557e-05 - val_loss: 0.0013\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1466e-05 - val_loss: 0.0013\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1227e-05 - val_loss: 0.0013\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1240e-05 - val_loss: 0.0013\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0664e-05 - val_loss: 0.0013\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0246e-05 - val_loss: 0.0013\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0109e-05 - val_loss: 0.0013\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0085e-05 - val_loss: 0.0013\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.7811e-06 - val_loss: 0.0013\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6142e-06 - val_loss: 0.0013\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5701e-06 - val_loss: 0.0013\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3067e-06 - val_loss: 0.0013\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9455e-06 - val_loss: 0.0013\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7023e-06 - val_loss: 0.0013\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5938e-06 - val_loss: 0.0013\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6915e-06 - val_loss: 0.0013\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1873e-06 - val_loss: 0.0013\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1909e-06 - val_loss: 0.0013\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9703e-06 - val_loss: 0.0012\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8809e-06 - val_loss: 0.0013\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6771e-06 - val_loss: 0.0013\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4089e-06 - val_loss: 0.0013\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3874e-06 - val_loss: 0.0012\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1573e-06 - val_loss: 0.0012\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9928e-06 - val_loss: 0.0012\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6960e-06 - val_loss: 0.0012\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8188e-06 - val_loss: 0.0012\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.5804e-06 - val_loss: 0.0012\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.5124e-06 - val_loss: 0.0012\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4969e-06 - val_loss: 0.0012\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3300e-06 - val_loss: 0.0012\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0403e-06 - val_loss: 0.0012\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0916e-06 - val_loss: 0.0012\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9772e-06 - val_loss: 0.0012\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2156e-06 - val_loss: 0.0012\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7673e-06 - val_loss: 0.0012\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6922e-06 - val_loss: 0.0012\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7364e-06 - val_loss: 0.0012\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5850e-06 - val_loss: 0.0012\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4574e-06 - val_loss: 0.0012\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3442e-06 - val_loss: 0.0012\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3585e-06 - val_loss: 0.0012\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3358e-06 - val_loss: 0.0012\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0747e-06 - val_loss: 0.0012\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9222e-06 - val_loss: 0.0012\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0664e-06 - val_loss: 0.0012\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7147e-06 - val_loss: 0.0012\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8423e-06 - val_loss: 0.0012\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6718e-06 - val_loss: 0.0012\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4513e-06 - val_loss: 0.0012\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4036e-06 - val_loss: 0.0012\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6921e-06 - val_loss: 0.0012\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6706e-06 - val_loss: 0.0012\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3559e-06 - val_loss: 0.0012\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1854e-06 - val_loss: 0.0012\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4274e-06 - val_loss: 0.0012\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6945e-06 - val_loss: 0.0012\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3130e-06 - val_loss: 0.0012\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1902e-06 - val_loss: 0.0012\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.6931e-06 - val_loss: 0.0012\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8838e-06 - val_loss: 0.0012\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7694e-06 - val_loss: 0.0012\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7086e-06 - val_loss: 0.0012\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6240e-06 - val_loss: 0.0012\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4893e-06 - val_loss: 0.0012\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.4368e-06 - val_loss: 0.0012\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4595e-06 - val_loss: 0.0012\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4702e-06 - val_loss: 0.0012\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3951e-06 - val_loss: 0.0012\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.3987e-06 - val_loss: 0.0012\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2830e-06 - val_loss: 0.0012\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.2079e-06 - val_loss: 0.0012\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.3247e-06 - val_loss: 0.0012\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1173e-06 - val_loss: 0.0012\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.2890e-06 - val_loss: 0.0012\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1269e-06 - val_loss: 0.0012\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9743e-06 - val_loss: 0.0012\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8646e-06 - val_loss: 0.0012\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9612e-06 - val_loss: 0.0012\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1197e-06 - val_loss: 0.0012\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.9778e-06 - val_loss: 0.0012\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.8789e-06 - val_loss: 0.0012\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6691e-06 - val_loss: 0.0012\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7156e-06 - val_loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8560eef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 6.9703e-04 - 211ms/epoch - 211ms/step\n",
      "tf.Tensor((0.999302975409275+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd9fe3d",
   "metadata": {},
   "source": [
    "## Amplitude Damping Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c070bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY ERROR \n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = ampl_damp_error(1, density_matrix_noise_free[i], 0.5, 0.3)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a256f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d260780",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25843bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),  \n",
    "  tf.keras.layers.Dense(64, activation='relu'),                                  \n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d76149b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt,\n",
    "              loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "504e2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 71ms/step - loss: 0.3493 - val_loss: 0.3187\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2968 - val_loss: 0.2771\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2507 - val_loss: 0.2377\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2114 - val_loss: 0.2016\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1755 - val_loss: 0.1674\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1417 - val_loss: 0.1347\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1101 - val_loss: 0.1055\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0822 - val_loss: 0.0787\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0579 - val_loss: 0.0558\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0376 - val_loss: 0.0368\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0226 - val_loss: 0.0224\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.2554e-04 - val_loss: 0.0014\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4101e-04 - val_loss: 0.0013\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9825e-04 - val_loss: 0.0011\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0207e-04 - val_loss: 0.0010\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5609e-04 - val_loss: 9.1161e-04\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0106e-04 - val_loss: 8.7236e-04\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.6382e-04 - val_loss: 8.1921e-04\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.2841e-04 - val_loss: 7.8248e-04\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.0611e-04 - val_loss: 7.3888e-04\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8875e-04 - val_loss: 7.1297e-04\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.6789e-04 - val_loss: 6.7338e-04\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5537e-04 - val_loss: 6.4789e-04\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.4080e-04 - val_loss: 6.3402e-04\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.2822e-04 - val_loss: 6.1699e-04\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1695e-04 - val_loss: 6.0150e-04\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.0845e-04 - val_loss: 5.8686e-04\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9970e-04 - val_loss: 5.5631e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8841e-04 - val_loss: 5.4812e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8086e-04 - val_loss: 5.3418e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7284e-04 - val_loss: 5.2768e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.6550e-04 - val_loss: 5.1494e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5896e-04 - val_loss: 4.9853e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5059e-04 - val_loss: 4.8681e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.4854e-04 - val_loss: 4.7518e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4433e-04 - val_loss: 4.6255e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4081e-04 - val_loss: 4.8145e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3338e-04 - val_loss: 4.5125e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2566e-04 - val_loss: 4.3414e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2077e-04 - val_loss: 4.3205e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1695e-04 - val_loss: 4.2471e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1294e-04 - val_loss: 4.1451e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0984e-04 - val_loss: 4.1569e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.0754e-04 - val_loss: 3.9532e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0321e-04 - val_loss: 3.9831e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9100e-05 - val_loss: 3.8956e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.6282e-05 - val_loss: 3.8133e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4009e-05 - val_loss: 3.7892e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1247e-05 - val_loss: 3.7628e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7947e-05 - val_loss: 3.6733e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4487e-05 - val_loss: 3.6371e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3926e-05 - val_loss: 3.5533e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0285e-05 - val_loss: 3.5246e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9508e-05 - val_loss: 3.4968e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6646e-05 - val_loss: 3.4945e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5681e-05 - val_loss: 3.3678e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3118e-05 - val_loss: 3.3225e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2060e-05 - val_loss: 3.3718e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2943e-05 - val_loss: 3.4092e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7524e-05 - val_loss: 3.1583e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7328e-05 - val_loss: 3.1744e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.5342e-05 - val_loss: 3.2450e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2987e-05 - val_loss: 3.1777e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2146e-05 - val_loss: 3.0378e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1412e-05 - val_loss: 3.0565e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.8422e-05 - val_loss: 3.0420e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.8536e-05 - val_loss: 3.0487e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5771e-05 - val_loss: 3.0025e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4309e-05 - val_loss: 2.9276e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3692e-05 - val_loss: 2.8578e-04\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1336e-05 - val_loss: 2.9165e-04\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9946e-05 - val_loss: 2.9169e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9049e-05 - val_loss: 2.8468e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8213e-05 - val_loss: 2.7634e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6480e-05 - val_loss: 2.7761e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5884e-05 - val_loss: 2.7751e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5283e-05 - val_loss: 2.6918e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.4221e-05 - val_loss: 2.7396e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2847e-05 - val_loss: 2.7050e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1863e-05 - val_loss: 2.6731e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1447e-05 - val_loss: 2.6097e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0164e-05 - val_loss: 2.6361e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9135e-05 - val_loss: 2.6059e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8198e-05 - val_loss: 2.5735e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.7357e-05 - val_loss: 2.5474e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.7794e-05 - val_loss: 2.5275e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5192e-05 - val_loss: 2.5295e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.6919e-05 - val_loss: 2.5466e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.3911e-05 - val_loss: 2.4877e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3718e-05 - val_loss: 2.4492e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2404e-05 - val_loss: 2.4634e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2257e-05 - val_loss: 2.4571e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.3431e-05 - val_loss: 2.4304e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.0736e-05 - val_loss: 2.3949e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.0599e-05 - val_loss: 2.3611e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.9903e-05 - val_loss: 2.4463e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.9313e-05 - val_loss: 2.3423e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8392e-05 - val_loss: 2.3105e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7549e-05 - val_loss: 2.3193e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7239e-05 - val_loss: 2.3366e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7446e-05 - val_loss: 2.3554e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.6914e-05 - val_loss: 2.2370e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.5464e-05 - val_loss: 2.2629e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4479e-05 - val_loss: 2.2864e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.3867e-05 - val_loss: 2.2389e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3789e-05 - val_loss: 2.2484e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2939e-05 - val_loss: 2.2153e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2294e-05 - val_loss: 2.2280e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.2409e-05 - val_loss: 2.2234e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2202e-05 - val_loss: 2.1752e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.1254e-05 - val_loss: 2.1828e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1756e-05 - val_loss: 2.1737e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1440e-05 - val_loss: 2.2101e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1147e-05 - val_loss: 2.1485e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0434e-05 - val_loss: 2.1643e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9318e-05 - val_loss: 2.1389e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0062e-05 - val_loss: 2.0882e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.0457e-05 - val_loss: 2.1513e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8448e-05 - val_loss: 2.1163e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9896e-05 - val_loss: 2.0644e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.8833e-05 - val_loss: 2.1535e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7524e-05 - val_loss: 2.0860e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7175e-05 - val_loss: 2.0412e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6886e-05 - val_loss: 2.0727e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6741e-05 - val_loss: 2.0490e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5980e-05 - val_loss: 2.0354e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6001e-05 - val_loss: 2.0853e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5663e-05 - val_loss: 2.0407e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6614e-05 - val_loss: 1.9912e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5400e-05 - val_loss: 2.0679e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5024e-05 - val_loss: 2.0401e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5065e-05 - val_loss: 2.0004e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4256e-05 - val_loss: 1.9911e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4344e-05 - val_loss: 2.0065e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3970e-05 - val_loss: 1.9730e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3849e-05 - val_loss: 1.9794e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3645e-05 - val_loss: 2.0101e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3889e-05 - val_loss: 1.9591e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2900e-05 - val_loss: 1.9878e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2885e-05 - val_loss: 1.9672e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3062e-05 - val_loss: 1.9521e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2416e-05 - val_loss: 1.9747e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2483e-05 - val_loss: 1.9343e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2246e-05 - val_loss: 1.9314e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2042e-05 - val_loss: 1.9523e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2244e-05 - val_loss: 1.9421e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1496e-05 - val_loss: 1.9202e-04\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1750e-05 - val_loss: 1.9320e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1982e-05 - val_loss: 1.9312e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1043e-05 - val_loss: 1.9113e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1252e-05 - val_loss: 1.9303e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0928e-05 - val_loss: 1.8852e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0656e-05 - val_loss: 1.9042e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0477e-05 - val_loss: 1.9006e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0622e-05 - val_loss: 1.8886e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0675e-05 - val_loss: 1.8906e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0415e-05 - val_loss: 1.9016e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0871e-05 - val_loss: 1.8762e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0190e-05 - val_loss: 1.9056e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6563e-06 - val_loss: 1.8691e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4890e-06 - val_loss: 1.8637e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.5570e-06 - val_loss: 1.8928e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.7343e-06 - val_loss: 1.8932e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3656e-06 - val_loss: 1.8317e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4804e-06 - val_loss: 1.8861e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9728e-06 - val_loss: 1.8656e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1327e-06 - val_loss: 1.8555e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1245e-06 - val_loss: 1.8608e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7709e-06 - val_loss: 1.8827e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6426e-06 - val_loss: 1.8496e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4434e-06 - val_loss: 1.8294e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.2336e-06 - val_loss: 1.8656e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.3481e-06 - val_loss: 1.8448e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.2690e-06 - val_loss: 1.8597e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4160e-06 - val_loss: 1.8373e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1338e-06 - val_loss: 1.8593e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.2694e-06 - val_loss: 1.8176e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.3224e-06 - val_loss: 1.8305e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7250e-06 - val_loss: 1.8257e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7292e-06 - val_loss: 1.8410e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5249e-06 - val_loss: 1.8065e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6898e-06 - val_loss: 1.8291e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1253e-06 - val_loss: 1.8215e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6629e-06 - val_loss: 1.8184e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4461e-06 - val_loss: 1.8385e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0113e-06 - val_loss: 1.8002e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7958e-06 - val_loss: 1.8135e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2830e-06 - val_loss: 1.8086e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2276e-06 - val_loss: 1.8096e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2848e-06 - val_loss: 1.8095e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0443e-06 - val_loss: 1.7955e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8040e-06 - val_loss: 1.7905e-04\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val,y_val),batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afe3f6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.1119e-04 - 193ms/epoch - 193ms/step\n",
      "tf.Tensor((1.0007760737674012+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0892acf",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3fc40870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64909bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 3s 507ms/step - loss: 0.4524 - val_loss: 0.3607\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.2728 - val_loss: 0.2178\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1452 - val_loss: 0.0937\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0483 - val_loss: 0.0411\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0219 - val_loss: 0.0255\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0072 - val_loss: 0.0092\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0041 - val_loss: 0.0077\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0034 - val_loss: 0.0070\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.0040e-04 - val_loss: 0.0025\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.0342e-04 - val_loss: 0.0023\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3532e-04 - val_loss: 0.0022\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6131e-04 - val_loss: 0.0021\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1993e-04 - val_loss: 0.0020\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6400e-04 - val_loss: 0.0019\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2593e-04 - val_loss: 0.0018\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.8580e-04 - val_loss: 0.0017\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5691e-04 - val_loss: 0.0016\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3034e-04 - val_loss: 0.0016\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0489e-04 - val_loss: 0.0015\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8258e-04 - val_loss: 0.0015\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.6425e-04 - val_loss: 0.0014\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4567e-04 - val_loss: 0.0014\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3268e-04 - val_loss: 0.0013\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1377e-04 - val_loss: 0.0013\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.0381e-04 - val_loss: 0.0013\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9156e-04 - val_loss: 0.0013\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7563e-04 - val_loss: 0.0012\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.6384e-04 - val_loss: 0.0012\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.5353e-04 - val_loss: 0.0012\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.4371e-04 - val_loss: 0.0012\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3673e-04 - val_loss: 0.0012\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.3093e-04 - val_loss: 0.0011\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.2066e-04 - val_loss: 0.0011\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.1152e-04 - val_loss: 0.0011\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.0077e-04 - val_loss: 0.0011\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9255e-04 - val_loss: 0.0011\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8542e-04 - val_loss: 0.0011\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8120e-04 - val_loss: 0.0011\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7104e-04 - val_loss: 0.0011\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6625e-04 - val_loss: 0.0010\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5805e-04 - val_loss: 0.0010\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5578e-04 - val_loss: 0.0010\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4771e-04 - val_loss: 0.0010\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4175e-04 - val_loss: 0.0010\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3953e-04 - val_loss: 0.0010\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3276e-04 - val_loss: 0.0010\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3067e-04 - val_loss: 0.0010\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2175e-04 - val_loss: 9.9829e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1810e-04 - val_loss: 9.9480e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1577e-04 - val_loss: 9.8718e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1094e-04 - val_loss: 9.8838e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0957e-04 - val_loss: 9.7895e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0411e-04 - val_loss: 9.7522e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0466e-04 - val_loss: 9.7996e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6908e-05 - val_loss: 9.8222e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3514e-05 - val_loss: 9.8130e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1118e-05 - val_loss: 9.7717e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0526e-05 - val_loss: 9.7574e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4990e-05 - val_loss: 9.7946e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2353e-05 - val_loss: 9.7717e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0174e-05 - val_loss: 9.7461e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.7292e-05 - val_loss: 9.7146e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6919e-05 - val_loss: 9.7287e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3998e-05 - val_loss: 9.6512e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0908e-05 - val_loss: 9.6599e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9405e-05 - val_loss: 9.6948e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8583e-05 - val_loss: 9.7478e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7203e-05 - val_loss: 9.6450e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4195e-05 - val_loss: 9.6882e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2723e-05 - val_loss: 9.6957e-04\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0670e-05 - val_loss: 9.6634e-04\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8907e-05 - val_loss: 9.6912e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7330e-05 - val_loss: 9.6952e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7207e-05 - val_loss: 9.7364e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4011e-05 - val_loss: 9.7062e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4836e-05 - val_loss: 9.6599e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1913e-05 - val_loss: 9.6678e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2291e-05 - val_loss: 9.6951e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8949e-05 - val_loss: 9.6598e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9653e-05 - val_loss: 9.6772e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6850e-05 - val_loss: 9.6342e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.4807e-05 - val_loss: 9.6751e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4497e-05 - val_loss: 9.7058e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3226e-05 - val_loss: 9.6957e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1547e-05 - val_loss: 9.6259e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.0429e-05 - val_loss: 9.6367e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9120e-05 - val_loss: 9.6363e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.9922e-05 - val_loss: 9.6958e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8024e-05 - val_loss: 9.7042e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.7597e-05 - val_loss: 9.6790e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5203e-05 - val_loss: 9.6322e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4016e-05 - val_loss: 9.6182e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4258e-05 - val_loss: 9.6033e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.2938e-05 - val_loss: 9.6585e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.1319e-05 - val_loss: 9.6245e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0488e-05 - val_loss: 9.6406e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9415e-05 - val_loss: 9.6615e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8471e-05 - val_loss: 9.6090e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8040e-05 - val_loss: 9.5253e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.6952e-05 - val_loss: 9.4788e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7672e-05 - val_loss: 9.5657e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5808e-05 - val_loss: 9.5187e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6017e-05 - val_loss: 9.5182e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.5498e-05 - val_loss: 9.5184e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.4322e-05 - val_loss: 9.4904e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5157e-05 - val_loss: 9.5046e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.4784e-05 - val_loss: 9.5070e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.3553e-05 - val_loss: 9.5511e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3636e-05 - val_loss: 9.5258e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2531e-05 - val_loss: 9.4841e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.1197e-05 - val_loss: 9.5089e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2155e-05 - val_loss: 9.4767e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.0165e-05 - val_loss: 9.4773e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.9805e-05 - val_loss: 9.4747e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9941e-05 - val_loss: 9.4515e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9525e-05 - val_loss: 9.4200e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9110e-05 - val_loss: 9.4301e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.9119e-05 - val_loss: 9.4977e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8140e-05 - val_loss: 9.4455e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8352e-05 - val_loss: 9.3619e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7480e-05 - val_loss: 9.4011e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7071e-05 - val_loss: 9.4281e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7165e-05 - val_loss: 9.4191e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6553e-05 - val_loss: 9.3706e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5936e-05 - val_loss: 9.3554e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5695e-05 - val_loss: 9.4293e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5324e-05 - val_loss: 9.4131e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6563e-05 - val_loss: 9.3900e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5738e-05 - val_loss: 9.3765e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4504e-05 - val_loss: 9.3447e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4359e-05 - val_loss: 9.3580e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4089e-05 - val_loss: 9.3942e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4234e-05 - val_loss: 9.3741e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.4007e-05 - val_loss: 9.3532e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3765e-05 - val_loss: 9.3448e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4046e-05 - val_loss: 9.3167e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3740e-05 - val_loss: 9.4101e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3490e-05 - val_loss: 9.4038e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3407e-05 - val_loss: 9.3568e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.3028e-05 - val_loss: 9.2752e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3120e-05 - val_loss: 9.3325e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1957e-05 - val_loss: 9.3674e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.2144e-05 - val_loss: 9.3649e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2318e-05 - val_loss: 9.3066e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1767e-05 - val_loss: 9.2551e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1413e-05 - val_loss: 9.3641e-04\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1548e-05 - val_loss: 9.3614e-04\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 25ms/step - loss: 1.1979e-05 - val_loss: 9.3094e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1077e-05 - val_loss: 9.3179e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1387e-05 - val_loss: 9.3566e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0880e-05 - val_loss: 9.3050e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0738e-05 - val_loss: 9.2606e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0124e-05 - val_loss: 9.3340e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0490e-05 - val_loss: 9.3353e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0055e-05 - val_loss: 9.3516e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0580e-05 - val_loss: 9.3542e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0358e-05 - val_loss: 9.2891e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0285e-05 - val_loss: 9.2791e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.4974e-06 - val_loss: 9.2586e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3794e-06 - val_loss: 9.2836e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.9848e-06 - val_loss: 9.3264e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.3520e-06 - val_loss: 9.3583e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1434e-06 - val_loss: 9.3168e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.3293e-06 - val_loss: 9.2639e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4996e-06 - val_loss: 9.2825e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6296e-06 - val_loss: 9.2822e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4352e-06 - val_loss: 9.2576e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.7595e-06 - val_loss: 9.3144e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8011e-06 - val_loss: 9.3166e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0478e-06 - val_loss: 9.3196e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1420e-06 - val_loss: 9.3295e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1670e-06 - val_loss: 9.3156e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5495e-06 - val_loss: 9.2790e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6222e-06 - val_loss: 9.2865e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8952e-06 - val_loss: 9.2962e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4422e-06 - val_loss: 9.2962e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5483e-06 - val_loss: 9.3040e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3850e-06 - val_loss: 9.2889e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8653e-06 - val_loss: 9.2952e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7699e-06 - val_loss: 9.3158e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5744e-06 - val_loss: 9.3038e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8617e-06 - val_loss: 9.2802e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.8176e-06 - val_loss: 9.2387e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8128e-06 - val_loss: 9.3173e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2692e-06 - val_loss: 9.3566e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3360e-06 - val_loss: 9.3090e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4826e-06 - val_loss: 9.2641e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6054e-06 - val_loss: 9.2876e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0976e-06 - val_loss: 9.2832e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1560e-06 - val_loss: 9.2911e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9998e-06 - val_loss: 9.3374e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9617e-06 - val_loss: 9.3268e-04\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fafad0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 3.9188e-04 - 216ms/epoch - 216ms/step\n",
      "tf.Tensor((0.9996081326010282+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7cfbb2",
   "metadata": {},
   "source": [
    "## Depolarizing Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b5d706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY ERROR \n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = depolar_error(1, density_matrix_noise_free[i], 0.3)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4fdd5c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958506a",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e22cec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),  \n",
    "  tf.keras.layers.Dense(64, activation='relu'),                                  \n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "096a3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt,\n",
    "              loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "113abe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 94ms/step - loss: 0.3360 - val_loss: 0.3226\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2966 - val_loss: 0.2889\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2611 - val_loss: 0.2561\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2275 - val_loss: 0.2259\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1958 - val_loss: 0.1968\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1650 - val_loss: 0.1680\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1361 - val_loss: 0.1404\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1085 - val_loss: 0.1139\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0838 - val_loss: 0.0897\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0629 - val_loss: 0.0680\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0449 - val_loss: 0.0496\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0303 - val_loss: 0.0347\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0201 - val_loss: 0.0230\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.1279e-04 - val_loss: 0.0016\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5034e-04 - val_loss: 0.0014\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.4543e-04 - val_loss: 0.0013\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5526e-04 - val_loss: 0.0012\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9085e-04 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4052e-04 - val_loss: 0.0011\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.0420e-04 - val_loss: 0.0010\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.7677e-04 - val_loss: 9.3702e-04\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.5338e-04 - val_loss: 8.6733e-04\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3083e-04 - val_loss: 8.1828e-04\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.1243e-04 - val_loss: 7.9483e-04\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0124e-04 - val_loss: 7.9160e-04\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8384e-04 - val_loss: 7.6024e-04\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.7583e-04 - val_loss: 7.3119e-04\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.6040e-04 - val_loss: 6.9802e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.5472e-04 - val_loss: 6.8867e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4345e-04 - val_loss: 6.7634e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4156e-04 - val_loss: 6.8870e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3190e-04 - val_loss: 6.5844e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.1986e-04 - val_loss: 6.2522e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1682e-04 - val_loss: 6.0975e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.1655e-04 - val_loss: 6.0543e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 2.0166e-04 - val_loss: 5.9763e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.9853e-04 - val_loss: 6.0254e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.8807e-04 - val_loss: 5.8025e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8645e-04 - val_loss: 5.7102e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.8060e-04 - val_loss: 5.6170e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.7318e-04 - val_loss: 5.3691e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6820e-04 - val_loss: 5.3740e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6374e-04 - val_loss: 5.3380e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5987e-04 - val_loss: 5.1852e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5202e-04 - val_loss: 5.1172e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5113e-04 - val_loss: 4.9604e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4338e-04 - val_loss: 4.9165e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4386e-04 - val_loss: 4.8742e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3878e-04 - val_loss: 4.8148e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.3420e-04 - val_loss: 4.8070e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2820e-04 - val_loss: 4.8155e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2597e-04 - val_loss: 4.6953e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2207e-04 - val_loss: 4.5156e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1983e-04 - val_loss: 4.4714e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1490e-04 - val_loss: 4.5370e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1677e-04 - val_loss: 4.5329e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1002e-04 - val_loss: 4.4424e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0940e-04 - val_loss: 4.3347e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.0619e-04 - val_loss: 4.4482e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0502e-04 - val_loss: 4.2707e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0114e-04 - val_loss: 4.3149e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7269e-05 - val_loss: 4.1855e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3085e-05 - val_loss: 4.0870e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1202e-05 - val_loss: 4.0951e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1220e-05 - val_loss: 4.1190e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9188e-05 - val_loss: 4.0779e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6310e-05 - val_loss: 4.0573e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3451e-05 - val_loss: 3.9938e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2421e-05 - val_loss: 3.9416e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9837e-05 - val_loss: 3.9553e-04\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9886e-05 - val_loss: 3.9657e-04\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5292e-05 - val_loss: 3.9726e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3439e-05 - val_loss: 3.8682e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8119e-05 - val_loss: 3.8630e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0523e-05 - val_loss: 3.7909e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1819e-05 - val_loss: 3.7230e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6960e-05 - val_loss: 3.8375e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8418e-05 - val_loss: 3.8432e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4600e-05 - val_loss: 3.7259e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.5682e-05 - val_loss: 3.6815e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2776e-05 - val_loss: 3.6031e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1331e-05 - val_loss: 3.6650e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9308e-05 - val_loss: 3.7717e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8328e-05 - val_loss: 3.6787e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8075e-05 - val_loss: 3.5413e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4479e-05 - val_loss: 3.5331e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3151e-05 - val_loss: 3.5692e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.3377e-05 - val_loss: 3.5979e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2763e-05 - val_loss: 3.5104e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0578e-05 - val_loss: 3.5068e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0089e-05 - val_loss: 3.5008e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9805e-05 - val_loss: 3.4581e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7142e-05 - val_loss: 3.5053e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7370e-05 - val_loss: 3.4398e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.7519e-05 - val_loss: 3.3421e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.7843e-05 - val_loss: 3.4760e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.3955e-05 - val_loss: 3.3684e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.3246e-05 - val_loss: 3.3378e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.1650e-05 - val_loss: 3.3681e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1161e-05 - val_loss: 3.3312e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1635e-05 - val_loss: 3.4088e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.9356e-05 - val_loss: 3.2733e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9003e-05 - val_loss: 3.2985e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9270e-05 - val_loss: 3.2363e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9970e-05 - val_loss: 3.3719e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8320e-05 - val_loss: 3.2239e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6219e-05 - val_loss: 3.2228e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.6124e-05 - val_loss: 3.2551e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7323e-05 - val_loss: 3.2519e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3525e-05 - val_loss: 3.2791e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5418e-05 - val_loss: 3.1959e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2113e-05 - val_loss: 3.1630e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.1952e-05 - val_loss: 3.1525e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.0400e-05 - val_loss: 3.1928e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.0884e-05 - val_loss: 3.1658e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.1003e-05 - val_loss: 3.1608e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8736e-05 - val_loss: 3.1006e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8981e-05 - val_loss: 3.0802e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.9079e-05 - val_loss: 3.1154e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8780e-05 - val_loss: 3.0585e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8195e-05 - val_loss: 3.1236e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.6203e-05 - val_loss: 3.1044e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.6372e-05 - val_loss: 3.0506e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5887e-05 - val_loss: 3.1053e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.6127e-05 - val_loss: 3.0100e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5326e-05 - val_loss: 3.0195e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.4175e-05 - val_loss: 3.0150e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.4890e-05 - val_loss: 3.0839e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3421e-05 - val_loss: 2.9751e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.2994e-05 - val_loss: 2.9925e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2419e-05 - val_loss: 3.0214e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3228e-05 - val_loss: 2.9493e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3723e-05 - val_loss: 3.0597e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1437e-05 - val_loss: 2.9870e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2462e-05 - val_loss: 2.9436e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0829e-05 - val_loss: 2.9874e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.0362e-05 - val_loss: 2.9905e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.0217e-05 - val_loss: 2.8898e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0345e-05 - val_loss: 2.9449e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.8781e-05 - val_loss: 2.9393e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9672e-05 - val_loss: 2.9026e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8281e-05 - val_loss: 2.9195e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7909e-05 - val_loss: 2.8999e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8730e-05 - val_loss: 2.9603e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7225e-05 - val_loss: 2.8495e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7818e-05 - val_loss: 2.8864e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 25ms/step - loss: 1.7648e-05 - val_loss: 2.9212e-04\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6622e-05 - val_loss: 2.8925e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6592e-05 - val_loss: 2.8710e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5987e-05 - val_loss: 2.8645e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6566e-05 - val_loss: 2.8221e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5919e-05 - val_loss: 2.8709e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5465e-05 - val_loss: 2.8691e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4815e-05 - val_loss: 2.8204e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5202e-05 - val_loss: 2.7938e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5574e-05 - val_loss: 2.8868e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5194e-05 - val_loss: 2.7979e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4508e-05 - val_loss: 2.8111e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4549e-05 - val_loss: 2.8029e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4484e-05 - val_loss: 2.8080e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4642e-05 - val_loss: 2.7804e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3196e-05 - val_loss: 2.7614e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3341e-05 - val_loss: 2.7794e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2874e-05 - val_loss: 2.7454e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3051e-05 - val_loss: 2.7387e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3243e-05 - val_loss: 2.7150e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3031e-05 - val_loss: 2.8034e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2162e-05 - val_loss: 2.7038e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2733e-05 - val_loss: 2.7840e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1977e-05 - val_loss: 2.7411e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1559e-05 - val_loss: 2.6903e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1475e-05 - val_loss: 2.6914e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1486e-05 - val_loss: 2.7121e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0923e-05 - val_loss: 2.7534e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1039e-05 - val_loss: 2.7335e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1222e-05 - val_loss: 2.6841e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1949e-05 - val_loss: 2.6454e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1947e-05 - val_loss: 2.7212e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1639e-05 - val_loss: 2.6703e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0361e-05 - val_loss: 2.6650e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0500e-05 - val_loss: 2.6522e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0143e-05 - val_loss: 2.6929e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0458e-05 - val_loss: 2.6751e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1553e-05 - val_loss: 2.6839e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0638e-05 - val_loss: 2.6394e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0355e-05 - val_loss: 2.6604e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8594e-06 - val_loss: 2.6095e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0226e-05 - val_loss: 2.6445e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6562e-06 - val_loss: 2.6443e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.5801e-06 - val_loss: 2.6975e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.0088e-06 - val_loss: 2.5726e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9459e-06 - val_loss: 2.5984e-04\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val,y_val),batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6467df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.5879e-04 - 242ms/epoch - 242ms/step\n",
      "tf.Tensor((0.9984214997982033+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e90fb",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "643b49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f404622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 141ms/step - loss: 0.5151 - val_loss: 0.3175\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3054 - val_loss: 0.1790\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.1316 - val_loss: 0.0697\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0409 - val_loss: 0.0326\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0276 - val_loss: 0.0268\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0199 - val_loss: 0.0190\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0041 - val_loss: 0.0068\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - val_loss: 0.0033\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6682e-04 - val_loss: 0.0030\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.7002e-04 - val_loss: 0.0028\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9086e-04 - val_loss: 0.0027\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4511e-04 - val_loss: 0.0025\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9197e-04 - val_loss: 0.0024\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4776e-04 - val_loss: 0.0023\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1475e-04 - val_loss: 0.0022\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7290e-04 - val_loss: 0.0022\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4234e-04 - val_loss: 0.0021\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.1351e-04 - val_loss: 0.0021\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9170e-04 - val_loss: 0.0020\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.6441e-04 - val_loss: 0.0020\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4436e-04 - val_loss: 0.0019\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.2624e-04 - val_loss: 0.0019\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.0825e-04 - val_loss: 0.0018\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.9056e-04 - val_loss: 0.0018\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.7845e-04 - val_loss: 0.0018\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.6640e-04 - val_loss: 0.0017\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5005e-04 - val_loss: 0.0017\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.4147e-04 - val_loss: 0.0017\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.2923e-04 - val_loss: 0.0016\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2036e-04 - val_loss: 0.0016\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0763e-04 - val_loss: 0.0016\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9778e-04 - val_loss: 0.0016\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8732e-04 - val_loss: 0.0016\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8032e-04 - val_loss: 0.0016\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7341e-04 - val_loss: 0.0015\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6664e-04 - val_loss: 0.0015\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6027e-04 - val_loss: 0.0015\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5269e-04 - val_loss: 0.0015\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.4316e-04 - val_loss: 0.0015\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3679e-04 - val_loss: 0.0014\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3119e-04 - val_loss: 0.0014\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2796e-04 - val_loss: 0.0014\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2131e-04 - val_loss: 0.0014\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1831e-04 - val_loss: 0.0014\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1245e-04 - val_loss: 0.0014\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0942e-04 - val_loss: 0.0013\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0374e-04 - val_loss: 0.0013\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.8712e-05 - val_loss: 0.0013\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6325e-05 - val_loss: 0.0013\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.3011e-05 - val_loss: 0.0013\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8652e-05 - val_loss: 0.0013\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5341e-05 - val_loss: 0.0013\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2572e-05 - val_loss: 0.0013\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9323e-05 - val_loss: 0.0013\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5908e-05 - val_loss: 0.0012\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.4623e-05 - val_loss: 0.0012\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.1428e-05 - val_loss: 0.0012\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8380e-05 - val_loss: 0.0012\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6345e-05 - val_loss: 0.0012\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4753e-05 - val_loss: 0.0012\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4007e-05 - val_loss: 0.0012\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0110e-05 - val_loss: 0.0012\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8033e-05 - val_loss: 0.0012\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6109e-05 - val_loss: 0.0012\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5404e-05 - val_loss: 0.0012\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1069e-05 - val_loss: 0.0012\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.9731e-05 - val_loss: 0.0012\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.8853e-05 - val_loss: 0.0012\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.7138e-05 - val_loss: 0.0011\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 4.5451e-05 - val_loss: 0.0011\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.4307e-05 - val_loss: 0.0011\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2186e-05 - val_loss: 0.0011\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2164e-05 - val_loss: 0.0011\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3.9818e-05 - val_loss: 0.0011\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3.8642e-05 - val_loss: 0.0011\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.9561e-05 - val_loss: 0.0011\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.7347e-05 - val_loss: 0.0011\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.6267e-05 - val_loss: 0.0011\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.4982e-05 - val_loss: 0.0011\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.5005e-05 - val_loss: 0.0011\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 3.3480e-05 - val_loss: 0.0011\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3.2406e-05 - val_loss: 0.0011\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.0382e-05 - val_loss: 0.0011\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.9833e-05 - val_loss: 0.0011\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.8205e-05 - val_loss: 0.0011\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7429e-05 - val_loss: 0.0011\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.6686e-05 - val_loss: 0.0011\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.5880e-05 - val_loss: 0.0011\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.5055e-05 - val_loss: 0.0011\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.5443e-05 - val_loss: 0.0011\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 2.4290e-05 - val_loss: 0.0011\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 2.2937e-05 - val_loss: 0.0011\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 2.3142e-05 - val_loss: 0.0011\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 2.1722e-05 - val_loss: 0.0011\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.1304e-05 - val_loss: 0.0011\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 2.1412e-05 - val_loss: 0.0011\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0249e-05 - val_loss: 0.0011\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9583e-05 - val_loss: 0.0011\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.9726e-05 - val_loss: 0.0011\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.8362e-05 - val_loss: 0.0010\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.7983e-05 - val_loss: 0.0010\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.7387e-05 - val_loss: 0.0010\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.7191e-05 - val_loss: 0.0010\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.6605e-05 - val_loss: 0.0010\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6280e-05 - val_loss: 0.0010\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5786e-05 - val_loss: 0.0010\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5205e-05 - val_loss: 0.0010\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.4845e-05 - val_loss: 0.0010\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4491e-05 - val_loss: 0.0010\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4129e-05 - val_loss: 0.0010\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3698e-05 - val_loss: 0.0010\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3354e-05 - val_loss: 0.0010\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3210e-05 - val_loss: 0.0010\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2971e-05 - val_loss: 0.0010\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2351e-05 - val_loss: 0.0010\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2220e-05 - val_loss: 0.0010\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2336e-05 - val_loss: 0.0010\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1487e-05 - val_loss: 0.0010\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1672e-05 - val_loss: 0.0010\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1098e-05 - val_loss: 0.0010\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1134e-05 - val_loss: 0.0010\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0644e-05 - val_loss: 0.0010\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0232e-05 - val_loss: 0.0010\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.0301e-05 - val_loss: 0.0010\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.7811e-06 - val_loss: 0.0010\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.8133e-06 - val_loss: 0.0010\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3865e-06 - val_loss: 0.0010\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5165e-06 - val_loss: 0.0010\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.1124e-06 - val_loss: 0.0010\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9991e-06 - val_loss: 0.0010\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9824e-06 - val_loss: 0.0010\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.6164e-06 - val_loss: 0.0010\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.6677e-06 - val_loss: 0.0010\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.2362e-06 - val_loss: 0.0010\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.5044e-06 - val_loss: 0.0010\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.9715e-06 - val_loss: 0.0010\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.9191e-06 - val_loss: 0.0010\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.0979e-06 - val_loss: 0.0010\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 7.6699e-06 - val_loss: 9.9863e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.6377e-06 - val_loss: 0.0010\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 7.2551e-06 - val_loss: 0.0010\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.7818e-06 - val_loss: 0.0010\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.7806e-06 - val_loss: 9.9861e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.5923e-06 - val_loss: 0.0010\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.5839e-06 - val_loss: 0.0010\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.3193e-06 - val_loss: 0.0010\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.2454e-06 - val_loss: 0.0010\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.5339e-06 - val_loss: 0.0010\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.2871e-06 - val_loss: 9.9859e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.2227e-06 - val_loss: 9.9784e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.7817e-06 - val_loss: 9.9972e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7113e-06 - val_loss: 0.0010\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7292e-06 - val_loss: 9.9865e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6696e-06 - val_loss: 9.9899e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5742e-06 - val_loss: 9.9546e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5325e-06 - val_loss: 9.9333e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3728e-06 - val_loss: 9.9920e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3978e-06 - val_loss: 9.9756e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1129e-06 - val_loss: 9.9641e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2154e-06 - val_loss: 9.9447e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1403e-06 - val_loss: 9.9617e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1749e-06 - val_loss: 9.9410e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8053e-06 - val_loss: 9.9457e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8113e-06 - val_loss: 9.9909e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0366e-06 - val_loss: 9.9754e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.5872e-06 - val_loss: 9.9519e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7278e-06 - val_loss: 9.9896e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5002e-06 - val_loss: 9.9969e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4322e-06 - val_loss: 9.9440e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4513e-06 - val_loss: 9.9339e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2534e-06 - val_loss: 9.9330e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3201e-06 - val_loss: 9.9851e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4286e-06 - val_loss: 9.9313e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2009e-06 - val_loss: 9.9433e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0901e-06 - val_loss: 9.9287e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9530e-06 - val_loss: 9.9221e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1926e-06 - val_loss: 9.8893e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3082e-06 - val_loss: 9.9682e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9113e-06 - val_loss: 9.9568e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.8183e-06 - val_loss: 9.9171e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.7491e-06 - val_loss: 9.9346e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.6240e-06 - val_loss: 9.9023e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7110e-06 - val_loss: 9.8998e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4726e-06 - val_loss: 9.9166e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5918e-06 - val_loss: 9.9375e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.6252e-06 - val_loss: 9.8905e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5918e-06 - val_loss: 9.9329e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5119e-06 - val_loss: 9.9240e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3796e-06 - val_loss: 9.9095e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.2902e-06 - val_loss: 9.8984e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.1960e-06 - val_loss: 9.9039e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.1638e-06 - val_loss: 9.8834e-04\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9728f362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 2.2932e-04 - 273ms/epoch - 273ms/step\n",
      "tf.Tensor((0.9997706817103381+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
