{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab555793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import qiskit as qk\n",
    "import qiskit.visualization\n",
    "\n",
    "from qiskit import Aer\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.quantum_info import Statevector\n",
    "\n",
    "from qiskit.providers.aer import AerSimulator\n",
    "from qiskit.providers.aer.noise import QuantumError, ReadoutError\n",
    "from qiskit import transpile\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "from tensorflow.python.framework.ops import convert_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8f1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure reproducibility\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e113b1",
   "metadata": {},
   "source": [
    "## Data Generation + (In)Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44873593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of a random unitary transformation\n",
    "def random_unitary(N):\n",
    "    Z=np.random.randn(N,N) + 1.0j * np.random.randn(N,N)\n",
    "    [Q,R]=sp.linalg.qr(Z)\n",
    "    D=np.diag(np.diagonal(R)/np.abs(np.diagonal(R)))\n",
    "    return np.dot(Q,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead9c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which generates the density matrix given the state vector\n",
    "def get_density_matrix(state_vector):\n",
    "    density_matrix = np.outer(state_vector, np.conjugate(state_vector))\n",
    "    return density_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf90b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which computes the components of the Bloch vector, given the density matrix \n",
    "\n",
    "#Here we define the identity matrix and the Pauli matrices for dimension 2 (one qubit)\n",
    "I = np.array([[1, 0],[0, 1]])\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "Y = np.array([[0, -1j], [1j, 0]])\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "\n",
    "def Bloch_vector(rho):\n",
    "    ax = np.trace(np.dot(rho, X)).real\n",
    "    ay = np.trace(np.dot(rho, Y)).real\n",
    "    az = np.trace(np.dot(rho, Z)).real\n",
    "    pnt = [ax, ay, az]\n",
    "    return np.array(pnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594b8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_matrix_from_bloch_vector(bloch_vector):\n",
    "   rho = 0.5 * (I+ bloch_vector[0]*X + bloch_vector[1]*Y + bloch_vector[2]*Z)\n",
    "   return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc6e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_function(a,b):\n",
    "    fid = tf.linalg.trace(a @ b)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64513f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_tf = tf.constant([1.0, 0.0,0.0,1.0],shape=(2,2), dtype = tf.complex64)\n",
    "X_tf = tf.constant([0.0, 1.0, 1.0, 0.0],shape=(2,2), dtype = tf.complex64)\n",
    "Y_tf = tf.constant([0.0+0j, 0.0-1j ,0.0+1j,0.0+0j],shape=(2,2), dtype = tf.complex64)\n",
    "Z_tf = tf.constant([1.0, 0.0,0.0,-1.0],shape=(2,2), dtype = tf.complex64)\n",
    "A = tf.stack([X_tf,Y_tf,Z_tf]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "077c8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def infidelity(a,b):\n",
    "   a = tf.cast(a, tf.complex64)\n",
    "   b = tf.cast(b, tf.complex64)\n",
    "   el_a = tf.einsum('ijk,mi->mjk',A,a) \n",
    "   el_b = tf.einsum('ijk,mi->mjk',A,b) \n",
    "   rho_a = 0.5 *(el_a + I_tf)\n",
    "   rho_b = 0.5 * (el_b +I_tf)\n",
    "   fidelity = tf.linalg.trace(rho_a @ rho_b) \n",
    "   infidelity = 1 - fidelity\n",
    "   return infidelity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e60e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to represent the data on the Bloch sphere\n",
    "\n",
    "def Bloch_sphere(data):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    qk.visualization.plot_bloch_vector([0, 0, 0], title='Bloch Sphere',ax=ax)\n",
    "    for (x, y, z) in data:\n",
    "        ax.scatter3D(y, -x, z, c='b') #here x and y axis are inverted in order to match qiskit and matplotlib axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c232191",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_bknd=Aer.get_backend('aer_simulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12ac1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Haar_data(num_qubits, samples=1000):\n",
    "    data = []\n",
    "    for i in range(samples):\n",
    "        qc = qk.QuantumCircuit(num_qubits) #creates a quantum circuit with \"num_qubits\" qubits\n",
    "        u = random_unitary(2**num_qubits)\n",
    "        qc.unitary(u, qubits=range(num_qubits)) #applies the random unitary transformation to the circuit\n",
    "        qc = qk.transpile(qc, backend=sim_bknd) #it's used to optimize the circuit\n",
    "        qc.save_statevector() #it's the instruction to save the state vector obtained by the simulation\n",
    "\n",
    "        state = sim_bknd.run(qc).result().get_statevector(qc) #does the simulation and gets the state vector\n",
    "        state = np.asarray(state)\n",
    "        data.append(state) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a6c3a",
   "metadata": {},
   "source": [
    "## Noise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f2e1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SINGLE ELEMENT OF THE OPERATOR-SUM REPRESENTATION\n",
    "\n",
    "def sum_element(rho,operator):\n",
    "    element = np.dot(np.dot(operator,rho),operator.conj().T)\n",
    "    return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895143aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIT FLIP, PHASE FLIP AND BIT-PHASE FLIP ERROR\n",
    "\n",
    "def flip_error(num_qubits, rho, error_type, p):\n",
    "\n",
    "    E_0 = np.sqrt(1-p)*I\n",
    "    if error_type == 'bit':\n",
    "        E_1 = np.sqrt(p)*X\n",
    "    if error_type == 'phase':\n",
    "        E_1 = np.sqrt(p)*Z\n",
    "    if error_type == 'bp':\n",
    "        E_1 = np.sqrt(p)*Y\n",
    "        \n",
    "    rho_with_flip_error = sum_element(rho, E_0)+sum_element(rho, E_1)\n",
    "    \n",
    "    return rho_with_flip_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3759710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL PAULI ERROR (generalizes and allows to combine the flip errors)\n",
    "\n",
    "def g_pauli_error(num_qubits, rho, p_0, p_1, p_2, p_3):\n",
    "    \n",
    "    E_0 = np.sqrt(p_0)*I\n",
    "    E_1 = np.sqrt(p_1)*X\n",
    "    E_2 = np.sqrt(p_2)*Y\n",
    "    E_3 = np.sqrt(p_3)*Z\n",
    "    \n",
    "    rho_with_gpauli_error = sum_element(rho, E_0)+sum_element(rho, E_1)+sum_element(rho, E_2)+sum_element(rho, E_3)\n",
    "    \n",
    "    return rho_with_gpauli_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f83194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPOLARIZING ERROR\n",
    "\n",
    "def depolar_error(num_qubits, rho, p):\n",
    "    \n",
    "    rho_with_dep_error = p*I/2 + (1-p)*rho\n",
    "\n",
    "    return rho_with_dep_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8236a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERAL AMPLITUDE DAMPING ERROR\n",
    "\n",
    "def ampl_damp_error(num_qubits, rho, p, a):\n",
    "  \n",
    "    E_0 = np.sqrt(p)*np.array([[1, 0], [0, np.sqrt(1-a)]])\n",
    "    E_1 = np.sqrt(p)*np.array([[0, np.sqrt(a)], [0, 0]])\n",
    "    E_2 = np.sqrt(1-p)*np.array([[np.sqrt(1-a), 0], [0, 1]])\n",
    "    E_3 = np.sqrt(1-p)*np.array([[0, 0], [np.sqrt(a), 0]])\n",
    "    \n",
    "    rho_with_ad_error = sum_element(rho, E_0)+sum_element(rho, E_1)+sum_element(rho, E_2)+sum_element(rho, E_3)\n",
    "\n",
    "    return rho_with_ad_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c25021",
   "metadata": {},
   "source": [
    "## Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ef1af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density matrix noise free type: complex128\n",
      "Bloch vector noise free type: float64\n"
     ]
    }
   ],
   "source": [
    "# GENERATE DATA\n",
    "data = generate_Haar_data(1, 100)\n",
    "#COMPUTE NOISE FREE DENSITY MATRIX\n",
    "density_matrix_noise_free = [*map(get_density_matrix, data)]\n",
    "#COMPUTE BLOCH VECTOR NOISE FREE\n",
    "bloch_vectors_noise_free = [*map(Bloch_vector, density_matrix_noise_free)]\n",
    "\n",
    "#PRINT THE TYPE OF THE SINGLE DENSITY MATRIX IN THE LISTS OF THE DENSITY MATRICES NOISE FREE\n",
    "print(\"Density matrix noise free type:\", density_matrix_noise_free[0].dtype)\n",
    "#PRINT THE TYPE OF THE BLOCH VECTOR IN THE LISTS OF THE BLOCH VECTORS NOISE FREE\n",
    "print(\"Bloch vector noise free type:\", bloch_vectors_noise_free[0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672aaa4b",
   "metadata": {},
   "source": [
    "## Phase Flip Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "261a32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density matrix with noise type: complex128\n",
      "Bloch vector with noise type: float64\n"
     ]
    }
   ],
   "source": [
    "#APPLY ERROR (in this case phase error with p=0.2)\n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = flip_error(1, density_matrix_noise_free[i], 'phase', 0.2)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "\n",
    "#PRINT THE TYPE OF THE SINGLE DENSITY MATRIX IN THE LISTS OF THE DENSITY MATRICES WITH NOISE\n",
    "print(\"Density matrix with noise type:\", density_matrix_with_noise[0].dtype)\n",
    "\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]\n",
    "print(\"Bloch vector with noise type:\", bloch_vectors_with_noise[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84c14861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: <dtype: 'float64'>\n",
      "Output data type: <dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:40], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:40], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "print(\"Input data type:\", x_train.dtype)\n",
    "print(\"Output data type:\", y_train.dtype)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e8193a",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff875562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd7f7a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 89ms/step - loss: 0.3484 - val_loss: 0.3340\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3168 - val_loss: 0.3068\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2891 - val_loss: 0.2801\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2627 - val_loss: 0.2542\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2369 - val_loss: 0.2289\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2111 - val_loss: 0.2040\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1863 - val_loss: 0.1799\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1618 - val_loss: 0.1560\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1379 - val_loss: 0.1329\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1147 - val_loss: 0.1109\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0930 - val_loss: 0.0909\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0731 - val_loss: 0.0727\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0556 - val_loss: 0.0562\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0407 - val_loss: 0.0425\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0291 - val_loss: 0.0309\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0200 - val_loss: 0.0219\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0093 - val_loss: 0.0104\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 8.0878e-04 - val_loss: 0.0012\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 6.7442e-04 - val_loss: 0.0011\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 5.6043e-04 - val_loss: 0.0010\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.9964e-04 - val_loss: 9.7927e-04\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.5201e-04 - val_loss: 9.5030e-04\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.1721e-04 - val_loss: 9.2402e-04\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.8571e-04 - val_loss: 8.9114e-04\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.5913e-04 - val_loss: 8.4914e-04\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.3211e-04 - val_loss: 8.0752e-04\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.1416e-04 - val_loss: 7.6473e-04\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.9517e-04 - val_loss: 7.5119e-04\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.8508e-04 - val_loss: 7.2193e-04\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.7507e-04 - val_loss: 6.9935e-04\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.5847e-04 - val_loss: 6.7739e-04\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.5258e-04 - val_loss: 6.6986e-04\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.4164e-04 - val_loss: 6.6361e-04\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.3538e-04 - val_loss: 6.4691e-04\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.2662e-04 - val_loss: 6.4343e-04\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.1475e-04 - val_loss: 6.4640e-04\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.0750e-04 - val_loss: 6.4313e-04\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.0079e-04 - val_loss: 6.3344e-04\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.9470e-04 - val_loss: 6.1783e-04\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8740e-04 - val_loss: 5.9753e-04\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8275e-04 - val_loss: 5.8537e-04\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.7591e-04 - val_loss: 5.7962e-04\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7234e-04 - val_loss: 5.7932e-04\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.6544e-04 - val_loss: 5.7557e-04\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.6202e-04 - val_loss: 5.6946e-04\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.5581e-04 - val_loss: 5.6768e-04\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.5185e-04 - val_loss: 5.6772e-04\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.4700e-04 - val_loss: 5.4754e-04\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.4177e-04 - val_loss: 5.4046e-04\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3939e-04 - val_loss: 5.4045e-04\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3424e-04 - val_loss: 5.3466e-04\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2886e-04 - val_loss: 5.3488e-04\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2655e-04 - val_loss: 5.1821e-04\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2204e-04 - val_loss: 5.1763e-04\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1785e-04 - val_loss: 5.1428e-04\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1563e-04 - val_loss: 5.0480e-04\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1295e-04 - val_loss: 5.0220e-04\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0918e-04 - val_loss: 5.0547e-04\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0627e-04 - val_loss: 5.0284e-04\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0548e-04 - val_loss: 5.0141e-04\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0209e-04 - val_loss: 4.9056e-04\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 9.9691e-05 - val_loss: 4.8115e-04\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.6388e-05 - val_loss: 4.7850e-04\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 9.3541e-05 - val_loss: 4.8101e-04\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 9.1135e-05 - val_loss: 4.8249e-04\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 9.0409e-05 - val_loss: 4.7390e-04\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 8.7838e-05 - val_loss: 4.7582e-04\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 8.3598e-05 - val_loss: 4.6792e-04\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.3457e-05 - val_loss: 4.6788e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.1997e-05 - val_loss: 4.7382e-04\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 7.8611e-05 - val_loss: 4.6170e-04\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 7.6111e-05 - val_loss: 4.4462e-04\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 7.3389e-05 - val_loss: 4.4356e-04\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 7.1238e-05 - val_loss: 4.5291e-04\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 6.9758e-05 - val_loss: 4.5286e-04\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 6.8352e-05 - val_loss: 4.4764e-04\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.5787e-05 - val_loss: 4.4264e-04\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.6545e-05 - val_loss: 4.3736e-04\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.4175e-05 - val_loss: 4.3102e-04\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 6.3327e-05 - val_loss: 4.3589e-04\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 6.0462e-05 - val_loss: 4.3831e-04\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 6.1306e-05 - val_loss: 4.3290e-04\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 6.0457e-05 - val_loss: 4.2893e-04\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 5.7471e-05 - val_loss: 4.2525e-04\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.5999e-05 - val_loss: 4.1938e-04\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.4350e-05 - val_loss: 4.1495e-04\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.3712e-05 - val_loss: 4.2354e-04\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 5.3675e-05 - val_loss: 4.2562e-04\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.1778e-05 - val_loss: 4.2054e-04\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 5.1290e-05 - val_loss: 4.1094e-04\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.9037e-05 - val_loss: 4.1319e-04\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 4.7726e-05 - val_loss: 4.1824e-04\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.7620e-05 - val_loss: 4.1102e-04\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.5772e-05 - val_loss: 3.9796e-04\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.4950e-05 - val_loss: 3.9992e-04\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.4516e-05 - val_loss: 4.0829e-04\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.4599e-05 - val_loss: 4.1018e-04\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.3376e-05 - val_loss: 4.0191e-04\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 4.1968e-05 - val_loss: 3.9332e-04\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.1816e-05 - val_loss: 4.0040e-04\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 4.0349e-05 - val_loss: 3.9617e-04\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.9862e-05 - val_loss: 3.9425e-04\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.8727e-05 - val_loss: 3.9401e-04\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.8590e-05 - val_loss: 4.0076e-04\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 3.7383e-05 - val_loss: 3.9570e-04\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.6933e-05 - val_loss: 3.8687e-04\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.6209e-05 - val_loss: 3.8270e-04\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.5164e-05 - val_loss: 3.8401e-04\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 3.5218e-05 - val_loss: 3.8630e-04\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.4296e-05 - val_loss: 3.8678e-04\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.4283e-05 - val_loss: 3.9227e-04\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 3.3842e-05 - val_loss: 3.8687e-04\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.2582e-05 - val_loss: 3.8280e-04\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.2533e-05 - val_loss: 3.7763e-04\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 3.1382e-05 - val_loss: 3.7180e-04\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.1228e-05 - val_loss: 3.7731e-04\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.0286e-05 - val_loss: 3.7720e-04\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.9949e-05 - val_loss: 3.8576e-04\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.8942e-05 - val_loss: 3.8347e-04\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.7929e-05 - val_loss: 3.7279e-04\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.7381e-05 - val_loss: 3.6733e-04\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.7437e-05 - val_loss: 3.6252e-04\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.6916e-05 - val_loss: 3.6939e-04\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.6859e-05 - val_loss: 3.7004e-04\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.5906e-05 - val_loss: 3.7005e-04\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.5229e-05 - val_loss: 3.7224e-04\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.5076e-05 - val_loss: 3.7077e-04\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.4560e-05 - val_loss: 3.5839e-04\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.4990e-05 - val_loss: 3.6455e-04\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.3540e-05 - val_loss: 3.6866e-04\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.3411e-05 - val_loss: 3.6556e-04\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.3124e-05 - val_loss: 3.6427e-04\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.2472e-05 - val_loss: 3.6328e-04\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2173e-05 - val_loss: 3.6037e-04\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.1978e-05 - val_loss: 3.6043e-04\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.1343e-05 - val_loss: 3.5887e-04\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.1309e-05 - val_loss: 3.5806e-04\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.1320e-05 - val_loss: 3.6103e-04\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0320e-05 - val_loss: 3.5685e-04\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.9904e-05 - val_loss: 3.5380e-04\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.0382e-05 - val_loss: 3.5720e-04\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.9452e-05 - val_loss: 3.5585e-04\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9961e-05 - val_loss: 3.5138e-04\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.9127e-05 - val_loss: 3.5429e-04\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.8801e-05 - val_loss: 3.5294e-04\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 27ms/step - loss: 1.8260e-05 - val_loss: 3.5297e-04\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.8259e-05 - val_loss: 3.5383e-04\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.7778e-05 - val_loss: 3.5445e-04\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.8145e-05 - val_loss: 3.4824e-04\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.7447e-05 - val_loss: 3.4961e-04\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.7250e-05 - val_loss: 3.5089e-04\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.7200e-05 - val_loss: 3.4927e-04\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.7028e-05 - val_loss: 3.4878e-04\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.6997e-05 - val_loss: 3.5200e-04\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.6643e-05 - val_loss: 3.5176e-04\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.6173e-05 - val_loss: 3.4459e-04\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.5794e-05 - val_loss: 3.4567e-04\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.5612e-05 - val_loss: 3.4531e-04\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.5289e-05 - val_loss: 3.4400e-04\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.6197e-05 - val_loss: 3.4274e-04\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.4973e-05 - val_loss: 3.4871e-04\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.5283e-05 - val_loss: 3.4718e-04\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.4607e-05 - val_loss: 3.4345e-04\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.4429e-05 - val_loss: 3.3977e-04\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.4034e-05 - val_loss: 3.4104e-04\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.4122e-05 - val_loss: 3.4126e-04\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.4659e-05 - val_loss: 3.4446e-04\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.4278e-05 - val_loss: 3.4144e-04\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.3990e-05 - val_loss: 3.4015e-04\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.3611e-05 - val_loss: 3.3663e-04\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3285e-05 - val_loss: 3.3771e-04\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.2839e-05 - val_loss: 3.4264e-04\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2912e-05 - val_loss: 3.4319e-04\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2620e-05 - val_loss: 3.3531e-04\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2546e-05 - val_loss: 3.3387e-04\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.2086e-05 - val_loss: 3.3671e-04\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2780e-05 - val_loss: 3.4168e-04\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.2475e-05 - val_loss: 3.3823e-04\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.2444e-05 - val_loss: 3.3806e-04\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1601e-05 - val_loss: 3.3342e-04\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1527e-05 - val_loss: 3.3303e-04\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1920e-05 - val_loss: 3.3362e-04\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1639e-05 - val_loss: 3.3084e-04\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.2339e-05 - val_loss: 3.3421e-04\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1141e-05 - val_loss: 3.3567e-04\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1417e-05 - val_loss: 3.3662e-04\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0742e-05 - val_loss: 3.3390e-04\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1376e-05 - val_loss: 3.2787e-04\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1351e-05 - val_loss: 3.3291e-04\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1437e-05 - val_loss: 3.3120e-04\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=loss_fn)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58d37298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.5969e-04 - 197ms/epoch - 197ms/step\n",
      "tf.Tensor((0.9969935095136057+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f7307",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b503b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5e62174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 2s 105ms/step - loss: 0.4973 - val_loss: 0.3111\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3106 - val_loss: 0.1934\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1692 - val_loss: 0.1064\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0730 - val_loss: 0.0554\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0344 - val_loss: 0.0367\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0225 - val_loss: 0.0302\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0188 - val_loss: 0.0259\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0144 - val_loss: 0.0202\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0095 - val_loss: 0.0152\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0068 - val_loss: 0.0114\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0055 - val_loss: 0.0089\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0044 - val_loss: 0.0076\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0036 - val_loss: 0.0068\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0013 - val_loss: 0.0039\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 9.7934e-04 - val_loss: 0.0033\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 9.1666e-04 - val_loss: 0.0032\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8.3608e-04 - val_loss: 0.0031\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 7.4871e-04 - val_loss: 0.0030\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.8527e-04 - val_loss: 0.0029\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.4030e-04 - val_loss: 0.0028\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.9052e-04 - val_loss: 0.0027\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 5.4638e-04 - val_loss: 0.0026\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.0790e-04 - val_loss: 0.0025\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 4.6914e-04 - val_loss: 0.0024\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.3978e-04 - val_loss: 0.0024\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.1321e-04 - val_loss: 0.0023\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.8883e-04 - val_loss: 0.0023\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.6422e-04 - val_loss: 0.0022\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.4039e-04 - val_loss: 0.0022\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.2164e-04 - val_loss: 0.0021\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.0779e-04 - val_loss: 0.0021\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.9034e-04 - val_loss: 0.0021\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.7209e-04 - val_loss: 0.0021\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.5763e-04 - val_loss: 0.0020\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.4591e-04 - val_loss: 0.0020\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2991e-04 - val_loss: 0.0020\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.1970e-04 - val_loss: 0.0020\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.0771e-04 - val_loss: 0.0020\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.9801e-04 - val_loss: 0.0019\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8760e-04 - val_loss: 0.0019\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.7660e-04 - val_loss: 0.0019\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7107e-04 - val_loss: 0.0019\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.6461e-04 - val_loss: 0.0018\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.5633e-04 - val_loss: 0.0018\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.4941e-04 - val_loss: 0.0018\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.4126e-04 - val_loss: 0.0018\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.3571e-04 - val_loss: 0.0018\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3302e-04 - val_loss: 0.0018\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.3046e-04 - val_loss: 0.0018\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2189e-04 - val_loss: 0.0018\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1566e-04 - val_loss: 0.0018\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0992e-04 - val_loss: 0.0018\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0572e-04 - val_loss: 0.0018\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0074e-04 - val_loss: 0.0018\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 9.7302e-05 - val_loss: 0.0018\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 9.2435e-05 - val_loss: 0.0017\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 9.0790e-05 - val_loss: 0.0017\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 8.7354e-05 - val_loss: 0.0017\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.2885e-05 - val_loss: 0.0017\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 7.9459e-05 - val_loss: 0.0017\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 7.5980e-05 - val_loss: 0.0017\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 7.5527e-05 - val_loss: 0.0017\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 7.1426e-05 - val_loss: 0.0017\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 6.9289e-05 - val_loss: 0.0017\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 6.6349e-05 - val_loss: 0.0017\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 6.4954e-05 - val_loss: 0.0017\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.2889e-05 - val_loss: 0.0017\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 6.0268e-05 - val_loss: 0.0017\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 5.8725e-05 - val_loss: 0.0017\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 5.7609e-05 - val_loss: 0.0017\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 5.3877e-05 - val_loss: 0.0017\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 35ms/step - loss: 5.1264e-05 - val_loss: 0.0017\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.0096e-05 - val_loss: 0.0017\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.8544e-05 - val_loss: 0.0017\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.6529e-05 - val_loss: 0.0017\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.4410e-05 - val_loss: 0.0016\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.3073e-05 - val_loss: 0.0017\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.1744e-05 - val_loss: 0.0017\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.0007e-05 - val_loss: 0.0017\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.8689e-05 - val_loss: 0.0016\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.7338e-05 - val_loss: 0.0016\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.6694e-05 - val_loss: 0.0016\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.4626e-05 - val_loss: 0.0016\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.4051e-05 - val_loss: 0.0016\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.3216e-05 - val_loss: 0.0016\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.1725e-05 - val_loss: 0.0016\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.0698e-05 - val_loss: 0.0016\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.0221e-05 - val_loss: 0.0016\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.9349e-05 - val_loss: 0.0016\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.8953e-05 - val_loss: 0.0016\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.8160e-05 - val_loss: 0.0016\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.7186e-05 - val_loss: 0.0016\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.6533e-05 - val_loss: 0.0016\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.6023e-05 - val_loss: 0.0016\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.4574e-05 - val_loss: 0.0016\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.4140e-05 - val_loss: 0.0016\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.4483e-05 - val_loss: 0.0016\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.3755e-05 - val_loss: 0.0016\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.2666e-05 - val_loss: 0.0016\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.2103e-05 - val_loss: 0.0016\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.1628e-05 - val_loss: 0.0016\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.0812e-05 - val_loss: 0.0016\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.0285e-05 - val_loss: 0.0016\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.9951e-05 - val_loss: 0.0016\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0172e-05 - val_loss: 0.0016\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.9188e-05 - val_loss: 0.0016\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.8416e-05 - val_loss: 0.0016\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.8229e-05 - val_loss: 0.0016\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.7454e-05 - val_loss: 0.0016\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.7412e-05 - val_loss: 0.0016\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.7026e-05 - val_loss: 0.0016\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.6566e-05 - val_loss: 0.0016\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.5979e-05 - val_loss: 0.0016\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.5607e-05 - val_loss: 0.0016\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.5426e-05 - val_loss: 0.0016\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.5016e-05 - val_loss: 0.0016\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.4319e-05 - val_loss: 0.0016\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3863e-05 - val_loss: 0.0016\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.4082e-05 - val_loss: 0.0016\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3418e-05 - val_loss: 0.0016\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.2989e-05 - val_loss: 0.0016\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.2924e-05 - val_loss: 0.0016\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3174e-05 - val_loss: 0.0015\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.2495e-05 - val_loss: 0.0015\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.2371e-05 - val_loss: 0.0015\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2073e-05 - val_loss: 0.0015\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1496e-05 - val_loss: 0.0015\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0973e-05 - val_loss: 0.0015\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0519e-05 - val_loss: 0.0015\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0623e-05 - val_loss: 0.0015\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0236e-05 - val_loss: 0.0015\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0151e-05 - val_loss: 0.0015\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.3326e-06 - val_loss: 0.0015\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 9.2462e-06 - val_loss: 0.0015\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.9765e-06 - val_loss: 0.0015\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.5667e-06 - val_loss: 0.0015\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.5279e-06 - val_loss: 0.0015\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 8.0168e-06 - val_loss: 0.0015\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 8.3148e-06 - val_loss: 0.0015\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 7.7754e-06 - val_loss: 0.0015\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 7.5921e-06 - val_loss: 0.0015\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 7.2196e-06 - val_loss: 0.0015\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 7.0259e-06 - val_loss: 0.0015\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 6.9708e-06 - val_loss: 0.0015\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.7309e-06 - val_loss: 0.0015\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 6.4522e-06 - val_loss: 0.0015\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.0320e-06 - val_loss: 0.0015\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 6.0797e-06 - val_loss: 0.0015\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.7593e-06 - val_loss: 0.0015\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.0886e-06 - val_loss: 0.0015\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 24ms/step - loss: 5.7399e-06 - val_loss: 0.0015\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 5.2705e-06 - val_loss: 0.0015\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 5.3823e-06 - val_loss: 0.0015\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 5.0038e-06 - val_loss: 0.0015\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.9070e-06 - val_loss: 0.0015\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 4.6864e-06 - val_loss: 0.0015\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.6149e-06 - val_loss: 0.0015\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.5046e-06 - val_loss: 0.0015\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.3839e-06 - val_loss: 0.0015\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.2409e-06 - val_loss: 0.0015\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.0859e-06 - val_loss: 0.0015\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.9250e-06 - val_loss: 0.0015\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.9324e-06 - val_loss: 0.0015\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.7193e-06 - val_loss: 0.0015\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.7119e-06 - val_loss: 0.0015\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.5062e-06 - val_loss: 0.0015\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.4735e-06 - val_loss: 0.0015\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.4094e-06 - val_loss: 0.0015\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.2648e-06 - val_loss: 0.0015\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.2037e-06 - val_loss: 0.0015\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 3.1292e-06 - val_loss: 0.0015\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.9743e-06 - val_loss: 0.0015\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.9102e-06 - val_loss: 0.0015\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.8595e-06 - val_loss: 0.0015\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.7180e-06 - val_loss: 0.0015\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.7627e-06 - val_loss: 0.0015\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.6360e-06 - val_loss: 0.0015\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.5511e-06 - val_loss: 0.0015\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.4214e-06 - val_loss: 0.0015\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.4080e-06 - val_loss: 0.0015\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.3589e-06 - val_loss: 0.0015\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 2.2531e-06 - val_loss: 0.0015\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.1920e-06 - val_loss: 0.0015\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.2739e-06 - val_loss: 0.0015\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0742e-06 - val_loss: 0.0015\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0489e-06 - val_loss: 0.0015\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.9893e-06 - val_loss: 0.0015\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.8969e-06 - val_loss: 0.0015\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.9386e-06 - val_loss: 0.0015\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.9342e-06 - val_loss: 0.0015\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.8492e-06 - val_loss: 0.0015\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7717e-06 - val_loss: 0.0015\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.7315e-06 - val_loss: 0.0015\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.7986e-06 - val_loss: 0.0015\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.5870e-06 - val_loss: 0.0015\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.6078e-06 - val_loss: 0.0015\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.5259e-06 - val_loss: 0.0015\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.5154e-06 - val_loss: 0.0015\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.4886e-06 - val_loss: 0.0015\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.4096e-06 - val_loss: 0.0015\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.4052e-06 - val_loss: 0.0015\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.3411e-06 - val_loss: 0.0015\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3217e-06 - val_loss: 0.0015\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2681e-06 - val_loss: 0.0015\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.2681e-06 - val_loss: 0.0015\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.2323e-06 - val_loss: 0.0015\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1772e-06 - val_loss: 0.0015\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1563e-06 - val_loss: 0.0014\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1250e-06 - val_loss: 0.0015\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1265e-06 - val_loss: 0.0014\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0699e-06 - val_loss: 0.0014\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0446e-06 - val_loss: 0.0014\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 9.8646e-07 - val_loss: 0.0014\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0163e-06 - val_loss: 0.0015\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.5665e-07 - val_loss: 0.0014\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.2983e-07 - val_loss: 0.0014\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.1344e-07 - val_loss: 0.0014\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8.7768e-07 - val_loss: 0.0014\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.9705e-07 - val_loss: 0.0014\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.1956e-07 - val_loss: 0.0014\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.3745e-07 - val_loss: 0.0014\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8.0317e-07 - val_loss: 0.0014\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 7.9125e-07 - val_loss: 0.0014\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 7.5549e-07 - val_loss: 0.0014\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 7.5996e-07 - val_loss: 0.0014\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 7.3165e-07 - val_loss: 0.0014\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 7.1675e-07 - val_loss: 0.0014\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.8992e-07 - val_loss: 0.0014\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 6.9290e-07 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 6.5416e-07 - val_loss: 0.0014\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.7353e-07 - val_loss: 0.0014\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 6.6608e-07 - val_loss: 0.0014\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 6.3032e-07 - val_loss: 0.0014\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 6.3181e-07 - val_loss: 0.0014\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 5.6773e-07 - val_loss: 0.0014\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.7817e-07 - val_loss: 0.0014\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.8264e-07 - val_loss: 0.0014\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.7071e-07 - val_loss: 0.0014\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.2750e-07 - val_loss: 0.0014\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 5.1111e-07 - val_loss: 0.0014\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 5.2005e-07 - val_loss: 0.0014\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 5.0068e-07 - val_loss: 0.0014\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 4.6939e-07 - val_loss: 0.0014\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.6194e-07 - val_loss: 0.0014\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.5598e-07 - val_loss: 0.0014\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.4703e-07 - val_loss: 0.0014\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.1872e-07 - val_loss: 0.0014\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 4.3213e-07 - val_loss: 0.0014\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.9786e-07 - val_loss: 0.0014\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 4.0382e-07 - val_loss: 0.0014\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.8147e-07 - val_loss: 0.0014\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.7551e-07 - val_loss: 0.0014\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 3.5912e-07 - val_loss: 0.0014\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.4869e-07 - val_loss: 0.0014\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.5316e-07 - val_loss: 0.0014\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.4273e-07 - val_loss: 0.0014\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.2932e-07 - val_loss: 0.0014\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.4422e-07 - val_loss: 0.0014\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.2485e-07 - val_loss: 0.0014\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 3.4124e-07 - val_loss: 0.0014\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.8610e-07 - val_loss: 0.0014\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.3379e-07 - val_loss: 0.0014\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.9802e-07 - val_loss: 0.0014\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.7120e-07 - val_loss: 0.0014\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.7567e-07 - val_loss: 0.0014\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.5481e-07 - val_loss: 0.0014\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.5928e-07 - val_loss: 0.0014\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.6375e-07 - val_loss: 0.0014\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.5034e-07 - val_loss: 0.0014\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2501e-07 - val_loss: 0.0014\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.3395e-07 - val_loss: 0.0014\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.2799e-07 - val_loss: 0.0014\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.2948e-07 - val_loss: 0.0014\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.4289e-07 - val_loss: 0.0014\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2352e-07 - val_loss: 0.0014\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2054e-07 - val_loss: 0.0014\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.9670e-07 - val_loss: 0.0014\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0117e-07 - val_loss: 0.0014\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.9968e-07 - val_loss: 0.0014\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.8179e-07 - val_loss: 0.0014\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.6540e-07 - val_loss: 0.0014\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.9968e-07 - val_loss: 0.0014\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.7583e-07 - val_loss: 0.0014\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6838e-07 - val_loss: 0.0014\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.7285e-07 - val_loss: 0.0014\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.6391e-07 - val_loss: 0.0014\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.5497e-07 - val_loss: 0.0014\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.5646e-07 - val_loss: 0.0014\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.4305e-07 - val_loss: 0.0014\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.4007e-07 - val_loss: 0.0014\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3411e-07 - val_loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ebf152dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 5.7588e-04 - 276ms/epoch - 276ms/step\n",
      "tf.Tensor((0.9994241234453061+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeeee8e",
   "metadata": {},
   "source": [
    "## Bit Flip Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3466d0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density matrix with noise type: complex128\n",
      "Bloch vector with noise type: float64\n"
     ]
    }
   ],
   "source": [
    "#APPLY ERROR (in this case phase error with p=0.2)\n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = flip_error(1, density_matrix_noise_free[i], 'bit', 0.2)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "\n",
    "#PRINT THE TYPE OF THE SINGLE DENSITY MATRIX IN THE LISTS OF THE DENSITY MATRICES WITH NOISE\n",
    "print(\"Density matrix with noise type:\", density_matrix_with_noise[0].dtype)\n",
    "\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]\n",
    "print(\"Bloch vector with noise type:\", bloch_vectors_with_noise[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "91f7750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: <dtype: 'float64'>\n",
      "Output data type: <dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "print(\"Input data type:\", x_train.dtype)\n",
    "print(\"Output data type:\", y_train.dtype)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b7a7b",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b77e93a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1ea7987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 70ms/step - loss: 0.3424 - val_loss: 0.3088\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2908 - val_loss: 0.2674\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2451 - val_loss: 0.2315\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2074 - val_loss: 0.2004\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1748 - val_loss: 0.1719\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1449 - val_loss: 0.1448\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1187 - val_loss: 0.1199\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0945 - val_loss: 0.0963\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0735 - val_loss: 0.0757\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0558 - val_loss: 0.0581\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0414 - val_loss: 0.0441\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0306 - val_loss: 0.0330\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0221 - val_loss: 0.0239\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0169\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7297e-04 - val_loss: 0.0015\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2693e-04 - val_loss: 0.0014\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2591e-04 - val_loss: 0.0012\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4588e-04 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.8980e-04 - val_loss: 0.0011\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4397e-04 - val_loss: 0.0010\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2916e-04 - val_loss: 9.8011e-04\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9178e-04 - val_loss: 9.2484e-04\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.6423e-04 - val_loss: 8.7942e-04\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4914e-04 - val_loss: 8.4245e-04\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2762e-04 - val_loss: 8.2576e-04\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.1029e-04 - val_loss: 7.9908e-04\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.9964e-04 - val_loss: 7.6708e-04\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8080e-04 - val_loss: 7.4498e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.6931e-04 - val_loss: 7.2840e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5948e-04 - val_loss: 7.0590e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4633e-04 - val_loss: 6.9556e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4682e-04 - val_loss: 6.8625e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3654e-04 - val_loss: 6.6231e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2244e-04 - val_loss: 6.5083e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.1364e-04 - val_loss: 6.4233e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0863e-04 - val_loss: 6.3260e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0166e-04 - val_loss: 6.4277e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9653e-04 - val_loss: 6.2001e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9093e-04 - val_loss: 5.9893e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8472e-04 - val_loss: 5.9028e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7922e-04 - val_loss: 5.8408e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7514e-04 - val_loss: 5.7620e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7348e-04 - val_loss: 5.8014e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6880e-04 - val_loss: 5.5741e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5895e-04 - val_loss: 5.4928e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5678e-04 - val_loss: 5.3991e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5323e-04 - val_loss: 5.3981e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5061e-04 - val_loss: 5.3528e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4475e-04 - val_loss: 5.2819e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4014e-04 - val_loss: 5.1938e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3748e-04 - val_loss: 5.0984e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.3526e-04 - val_loss: 5.0672e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3024e-04 - val_loss: 5.0386e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2883e-04 - val_loss: 4.9013e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.2578e-04 - val_loss: 4.8769e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2360e-04 - val_loss: 4.8959e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1920e-04 - val_loss: 4.9437e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1972e-04 - val_loss: 4.7824e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1568e-04 - val_loss: 4.7797e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1590e-04 - val_loss: 4.6661e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1180e-04 - val_loss: 4.6683e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0743e-04 - val_loss: 4.5868e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0421e-04 - val_loss: 4.5818e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0243e-04 - val_loss: 4.5694e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9870e-05 - val_loss: 4.5676e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9692e-05 - val_loss: 4.4314e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5621e-05 - val_loss: 4.4294e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5361e-05 - val_loss: 4.3756e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.3100e-05 - val_loss: 4.3475e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9988e-05 - val_loss: 4.3971e-04\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9277e-05 - val_loss: 4.3892e-04\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7548e-05 - val_loss: 4.2076e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.3576e-05 - val_loss: 4.2002e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3646e-05 - val_loss: 4.3132e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.1255e-05 - val_loss: 4.2040e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3658e-05 - val_loss: 3.9940e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.6538e-05 - val_loss: 4.1515e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8545e-05 - val_loss: 4.1724e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3285e-05 - val_loss: 4.0147e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3239e-05 - val_loss: 4.0303e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1903e-05 - val_loss: 3.9735e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8885e-05 - val_loss: 4.0357e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0550e-05 - val_loss: 4.0027e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5972e-05 - val_loss: 3.8428e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5782e-05 - val_loss: 3.8366e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5355e-05 - val_loss: 3.7646e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0759e-05 - val_loss: 3.8959e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2050e-05 - val_loss: 3.9461e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.1068e-05 - val_loss: 3.7928e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1908e-05 - val_loss: 3.7562e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0667e-05 - val_loss: 3.8974e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7802e-05 - val_loss: 3.7415e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8914e-05 - val_loss: 3.5725e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7709e-05 - val_loss: 3.7871e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4147e-05 - val_loss: 3.6635e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6491e-05 - val_loss: 3.7233e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4972e-05 - val_loss: 3.5788e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3839e-05 - val_loss: 3.5646e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0985e-05 - val_loss: 3.6790e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1908e-05 - val_loss: 3.5486e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0605e-05 - val_loss: 3.5816e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9229e-05 - val_loss: 3.5915e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1077e-05 - val_loss: 3.6156e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7815e-05 - val_loss: 3.4075e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6011e-05 - val_loss: 3.5407e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8060e-05 - val_loss: 3.5439e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5352e-05 - val_loss: 3.3451e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3547e-05 - val_loss: 3.5288e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.4342e-05 - val_loss: 3.5830e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2468e-05 - val_loss: 3.3250e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0485e-05 - val_loss: 3.4218e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1677e-05 - val_loss: 3.4731e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0439e-05 - val_loss: 3.3780e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9460e-05 - val_loss: 3.4263e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.9311e-05 - val_loss: 3.3501e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.6743e-05 - val_loss: 3.3644e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8575e-05 - val_loss: 3.3558e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6312e-05 - val_loss: 3.3149e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5284e-05 - val_loss: 3.3489e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.5258e-05 - val_loss: 3.2210e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4186e-05 - val_loss: 3.2594e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3690e-05 - val_loss: 3.3558e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.2681e-05 - val_loss: 3.2441e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.2646e-05 - val_loss: 3.2839e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.2391e-05 - val_loss: 3.2226e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.1637e-05 - val_loss: 3.2768e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2261e-05 - val_loss: 3.3330e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.0028e-05 - val_loss: 3.1105e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0641e-05 - val_loss: 3.1875e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.9720e-05 - val_loss: 3.2351e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.8966e-05 - val_loss: 3.1322e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9255e-05 - val_loss: 3.1810e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8226e-05 - val_loss: 3.1741e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8215e-05 - val_loss: 3.2100e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6363e-05 - val_loss: 3.0233e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.7393e-05 - val_loss: 3.1869e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5658e-05 - val_loss: 3.1347e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4713e-05 - val_loss: 3.1076e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5067e-05 - val_loss: 3.0854e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3897e-05 - val_loss: 3.0934e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4401e-05 - val_loss: 3.0599e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2904e-05 - val_loss: 3.0892e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2904e-05 - val_loss: 3.0958e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.2860e-05 - val_loss: 3.0885e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1927e-05 - val_loss: 2.9728e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.1748e-05 - val_loss: 3.0592e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2565e-05 - val_loss: 3.0468e-04\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2385e-05 - val_loss: 3.0110e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0944e-05 - val_loss: 3.1079e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.9784e-05 - val_loss: 3.0232e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0995e-05 - val_loss: 2.9577e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9898e-05 - val_loss: 3.0214e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9069e-05 - val_loss: 3.0335e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9090e-05 - val_loss: 2.9874e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9323e-05 - val_loss: 3.0376e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.8976e-05 - val_loss: 2.9778e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9303e-05 - val_loss: 3.0224e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.8353e-05 - val_loss: 2.9996e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7810e-05 - val_loss: 2.9500e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8150e-05 - val_loss: 3.0199e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7239e-05 - val_loss: 2.9273e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6203e-05 - val_loss: 2.9560e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6169e-05 - val_loss: 2.9514e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6490e-05 - val_loss: 2.9731e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5819e-05 - val_loss: 2.9404e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5455e-05 - val_loss: 2.8693e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5573e-05 - val_loss: 2.9855e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5046e-05 - val_loss: 2.9030e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4480e-05 - val_loss: 2.9017e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4533e-05 - val_loss: 2.8947e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.4141e-05 - val_loss: 2.9026e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4130e-05 - val_loss: 2.9268e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4161e-05 - val_loss: 2.9222e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3551e-05 - val_loss: 2.9053e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4070e-05 - val_loss: 2.8657e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.4367e-05 - val_loss: 2.9549e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.3855e-05 - val_loss: 2.8362e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2992e-05 - val_loss: 2.9176e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2699e-05 - val_loss: 2.8398e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3513e-05 - val_loss: 2.8505e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2828e-05 - val_loss: 2.9137e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2243e-05 - val_loss: 2.8529e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2263e-05 - val_loss: 2.8404e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3489e-05 - val_loss: 2.8931e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2389e-05 - val_loss: 2.7763e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2878e-05 - val_loss: 2.8878e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2589e-05 - val_loss: 2.8094e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1514e-05 - val_loss: 2.8562e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1658e-05 - val_loss: 2.8432e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1202e-05 - val_loss: 2.8503e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.1785e-05 - val_loss: 2.7439e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0964e-05 - val_loss: 2.8864e-04\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=loss_fn)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55c36efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 6.0814e-05 - 230ms/epoch - 230ms/step\n",
      "tf.Tensor((1.0000325631140117+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca934368",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec045226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ebce3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 89ms/step - loss: 0.5284 - val_loss: 0.3830\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3850 - val_loss: 0.2731\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2725 - val_loss: 0.1705\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1775 - val_loss: 0.0927\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0990 - val_loss: 0.0561\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0522 - val_loss: 0.0366\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0269 - val_loss: 0.0229\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 0.0163\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0082 - val_loss: 0.0133\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0067 - val_loss: 0.0109\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0053 - val_loss: 0.0086\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1408e-04 - val_loss: 0.0023\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8330e-04 - val_loss: 0.0021\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0220e-04 - val_loss: 0.0020\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2347e-04 - val_loss: 0.0018\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6688e-04 - val_loss: 0.0017\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.2375e-04 - val_loss: 0.0016\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.8436e-04 - val_loss: 0.0015\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4510e-04 - val_loss: 0.0015\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.1699e-04 - val_loss: 0.0014\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8724e-04 - val_loss: 0.0014\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6468e-04 - val_loss: 0.0013\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3915e-04 - val_loss: 0.0013\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1872e-04 - val_loss: 0.0013\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.9793e-04 - val_loss: 0.0012\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.8600e-04 - val_loss: 0.0012\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.6633e-04 - val_loss: 0.0011\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5234e-04 - val_loss: 0.0011\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3451e-04 - val_loss: 0.0011\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1915e-04 - val_loss: 0.0011\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1234e-04 - val_loss: 0.0011\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9631e-04 - val_loss: 0.0011\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8392e-04 - val_loss: 0.0010\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7327e-04 - val_loss: 0.0010\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6194e-04 - val_loss: 0.0010\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5065e-04 - val_loss: 9.8845e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4455e-04 - val_loss: 9.7052e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3972e-04 - val_loss: 9.5579e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2897e-04 - val_loss: 9.4910e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2304e-04 - val_loss: 9.3882e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1887e-04 - val_loss: 9.3941e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1210e-04 - val_loss: 9.1661e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0708e-04 - val_loss: 9.0961e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0293e-04 - val_loss: 9.1684e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.8783e-05 - val_loss: 8.9584e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5998e-05 - val_loss: 9.0102e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9531e-05 - val_loss: 9.0113e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7602e-05 - val_loss: 8.8758e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2396e-05 - val_loss: 8.6158e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9707e-05 - val_loss: 8.7005e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5660e-05 - val_loss: 8.7914e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5060e-05 - val_loss: 8.7210e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.1284e-05 - val_loss: 8.5887e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.7788e-05 - val_loss: 8.5959e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6710e-05 - val_loss: 8.4791e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.3063e-05 - val_loss: 8.5606e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.1269e-05 - val_loss: 8.4903e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9792e-05 - val_loss: 8.4920e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8000e-05 - val_loss: 8.4555e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6815e-05 - val_loss: 8.4544e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4289e-05 - val_loss: 8.4522e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0977e-05 - val_loss: 8.4233e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0739e-05 - val_loss: 8.3053e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8625e-05 - val_loss: 8.1866e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7435e-05 - val_loss: 8.3336e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5347e-05 - val_loss: 8.3205e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4231e-05 - val_loss: 8.2981e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3327e-05 - val_loss: 8.2326e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4408e-05 - val_loss: 8.2546e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1279e-05 - val_loss: 8.2089e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9581e-05 - val_loss: 8.1308e-04\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9312e-05 - val_loss: 8.2990e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8695e-05 - val_loss: 8.1720e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6609e-05 - val_loss: 8.1981e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.6311e-05 - val_loss: 8.0763e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.4699e-05 - val_loss: 8.0807e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3922e-05 - val_loss: 8.2304e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3770e-05 - val_loss: 8.0761e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2669e-05 - val_loss: 7.9932e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1018e-05 - val_loss: 8.0714e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.0236e-05 - val_loss: 8.0805e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.9452e-05 - val_loss: 8.0290e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8334e-05 - val_loss: 7.9919e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8135e-05 - val_loss: 8.0139e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.7280e-05 - val_loss: 7.9626e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.6339e-05 - val_loss: 7.9580e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.5914e-05 - val_loss: 7.9162e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.5527e-05 - val_loss: 7.9535e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.4163e-05 - val_loss: 7.9853e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4260e-05 - val_loss: 7.9595e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.3662e-05 - val_loss: 7.9332e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3308e-05 - val_loss: 7.9118e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1564e-05 - val_loss: 7.9260e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1822e-05 - val_loss: 7.8932e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1966e-05 - val_loss: 7.8708e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1384e-05 - val_loss: 7.9546e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0896e-05 - val_loss: 7.8694e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0480e-05 - val_loss: 7.8306e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9999e-05 - val_loss: 7.8513e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.9114e-05 - val_loss: 7.9154e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9058e-05 - val_loss: 7.9332e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8188e-05 - val_loss: 7.7795e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8258e-05 - val_loss: 7.8120e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8573e-05 - val_loss: 7.8243e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7695e-05 - val_loss: 7.9043e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6930e-05 - val_loss: 7.8185e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7806e-05 - val_loss: 7.7901e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6868e-05 - val_loss: 7.8614e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6619e-05 - val_loss: 7.8522e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6121e-05 - val_loss: 7.7900e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5899e-05 - val_loss: 7.8485e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5563e-05 - val_loss: 7.7806e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5758e-05 - val_loss: 7.6980e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5328e-05 - val_loss: 7.8652e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4652e-05 - val_loss: 7.8380e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4548e-05 - val_loss: 7.7444e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4026e-05 - val_loss: 7.7311e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.4126e-05 - val_loss: 7.7593e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4269e-05 - val_loss: 7.7553e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3164e-05 - val_loss: 7.7999e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.4399e-05 - val_loss: 7.7730e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2630e-05 - val_loss: 7.8013e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2467e-05 - val_loss: 7.8010e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2008e-05 - val_loss: 7.7918e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2252e-05 - val_loss: 7.8257e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1698e-05 - val_loss: 7.7669e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1023e-05 - val_loss: 7.6609e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2045e-05 - val_loss: 7.7022e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2349e-05 - val_loss: 7.8733e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1213e-05 - val_loss: 7.7021e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0358e-05 - val_loss: 7.7211e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0494e-05 - val_loss: 7.7902e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9635e-06 - val_loss: 7.7572e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9695e-06 - val_loss: 7.7335e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0054e-05 - val_loss: 7.8171e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0105e-05 - val_loss: 7.7212e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.4616e-06 - val_loss: 7.7219e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4116e-06 - val_loss: 7.7822e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5272e-06 - val_loss: 7.7189e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5093e-06 - val_loss: 7.7100e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.7692e-06 - val_loss: 7.8547e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.9850e-06 - val_loss: 7.6594e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6224e-06 - val_loss: 7.6893e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.4521e-06 - val_loss: 7.7187e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.3293e-06 - val_loss: 7.7202e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0067e-05 - val_loss: 7.6580e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9061e-06 - val_loss: 7.6946e-04\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5451e-06 - val_loss: 7.6935e-04\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1684e-06 - val_loss: 7.7200e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5865e-06 - val_loss: 7.6358e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2207e-06 - val_loss: 7.6253e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0645e-06 - val_loss: 7.7379e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7927e-06 - val_loss: 7.6513e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1657e-06 - val_loss: 7.6045e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4637e-06 - val_loss: 7.6707e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1418e-06 - val_loss: 7.7039e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6079e-06 - val_loss: 7.5878e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3922e-06 - val_loss: 7.7314e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3767e-06 - val_loss: 7.6007e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2253e-06 - val_loss: 7.6732e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0119e-06 - val_loss: 7.6406e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8879e-06 - val_loss: 7.5985e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.7403e-06 - val_loss: 7.5388e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3111e-06 - val_loss: 7.6881e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.2467e-06 - val_loss: 7.5989e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3908e-06 - val_loss: 7.5720e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8247e-06 - val_loss: 7.6175e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.4468e-06 - val_loss: 7.5465e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8283e-06 - val_loss: 7.4795e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.6267e-06 - val_loss: 7.5833e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0189e-06 - val_loss: 7.5979e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7673e-06 - val_loss: 7.5307e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2478e-06 - val_loss: 7.5907e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6052e-06 - val_loss: 7.5528e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8544e-06 - val_loss: 7.5506e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3169e-06 - val_loss: 7.4741e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7888e-06 - val_loss: 7.6459e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5959e-06 - val_loss: 7.4698e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3813e-06 - val_loss: 7.6207e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.6195e-06 - val_loss: 7.4981e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4252e-06 - val_loss: 7.5006e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3370e-06 - val_loss: 7.5318e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4109e-06 - val_loss: 7.4452e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3598e-06 - val_loss: 7.6001e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7437e-06 - val_loss: 7.4628e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8031e-06 - val_loss: 7.4716e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0236e-06 - val_loss: 7.4964e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5659e-06 - val_loss: 7.6118e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6791e-06 - val_loss: 7.4579e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7852e-06 - val_loss: 7.5512e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.2130e-06 - val_loss: 7.5829e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7185e-06 - val_loss: 7.3683e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9353e-06 - val_loss: 7.5473e-04\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ffe7ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 2.0944e-04 - 243ms/epoch - 243ms/step\n",
      "tf.Tensor((0.9997905494500658+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04d30c",
   "metadata": {},
   "source": [
    "## Bit-Phase Flip Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6430786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density matrix with noise type: complex128\n",
      "Bloch vector with noise type: float64\n"
     ]
    }
   ],
   "source": [
    "#APPLY ERROR (in this case phase error with p=0.2)\n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = flip_error(1, density_matrix_noise_free[i], 'bp', 0.2)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "\n",
    "#PRINT THE TYPE OF THE SINGLE DENSITY MATRIX IN THE LISTS OF THE DENSITY MATRICES WITH NOISE\n",
    "print(\"Density matrix with noise type:\", density_matrix_with_noise[0].dtype)\n",
    "\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]\n",
    "print(\"Bloch vector with noise type:\", bloch_vectors_with_noise[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e47402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: <dtype: 'float64'>\n",
      "Output data type: <dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:40], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:40], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "print(\"Input data type:\", x_train.dtype)\n",
    "print(\"Output data type:\", y_train.dtype)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d719e0e2",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a4e288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9377bf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 94ms/step - loss: 0.3371 - val_loss: 0.3161\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2990 - val_loss: 0.2856\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2652 - val_loss: 0.2577\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2350 - val_loss: 0.2309\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2052 - val_loss: 0.2052\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1764 - val_loss: 0.1802\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1500 - val_loss: 0.1561\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1237 - val_loss: 0.1328\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1004 - val_loss: 0.1112\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0795 - val_loss: 0.0919\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0615 - val_loss: 0.0754\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0475 - val_loss: 0.0615\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0367 - val_loss: 0.0496\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0284 - val_loss: 0.0397\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0218 - val_loss: 0.0313\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0171 - val_loss: 0.0241\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0130 - val_loss: 0.0181\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0094 - val_loss: 0.0133\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0068 - val_loss: 0.0097\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0051 - val_loss: 0.0071\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.7427e-04 - val_loss: 0.0022\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 8.8676e-04 - val_loss: 0.0021\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.1133e-04 - val_loss: 0.0020\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 7.5594e-04 - val_loss: 0.0019\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 7.0189e-04 - val_loss: 0.0018\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 6.5868e-04 - val_loss: 0.0018\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 6.2119e-04 - val_loss: 0.0017\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.7878e-04 - val_loss: 0.0017\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.5441e-04 - val_loss: 0.0016\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.2461e-04 - val_loss: 0.0016\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.9463e-04 - val_loss: 0.0015\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.7159e-04 - val_loss: 0.0015\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.4953e-04 - val_loss: 0.0015\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.3546e-04 - val_loss: 0.0014\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.0947e-04 - val_loss: 0.0014\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.9332e-04 - val_loss: 0.0014\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.8076e-04 - val_loss: 0.0014\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.6334e-04 - val_loss: 0.0013\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3.4686e-04 - val_loss: 0.0013\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.3149e-04 - val_loss: 0.0013\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.1571e-04 - val_loss: 0.0013\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.0726e-04 - val_loss: 0.0012\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.9170e-04 - val_loss: 0.0012\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.8597e-04 - val_loss: 0.0012\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.7214e-04 - val_loss: 0.0012\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.6307e-04 - val_loss: 0.0012\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.5397e-04 - val_loss: 0.0012\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.4419e-04 - val_loss: 0.0012\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.3280e-04 - val_loss: 0.0011\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.2639e-04 - val_loss: 0.0011\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.1820e-04 - val_loss: 0.0011\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.1096e-04 - val_loss: 0.0011\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.0040e-04 - val_loss: 0.0011\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.9586e-04 - val_loss: 0.0011\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.8898e-04 - val_loss: 0.0011\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.8007e-04 - val_loss: 0.0010\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7295e-04 - val_loss: 0.0010\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6746e-04 - val_loss: 9.9931e-04\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.6118e-04 - val_loss: 9.9416e-04\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.5566e-04 - val_loss: 9.8688e-04\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.5424e-04 - val_loss: 9.7076e-04\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.4439e-04 - val_loss: 9.7063e-04\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.4011e-04 - val_loss: 9.5682e-04\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.3456e-04 - val_loss: 9.4287e-04\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2820e-04 - val_loss: 9.3238e-04\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2673e-04 - val_loss: 9.1831e-04\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2046e-04 - val_loss: 9.1604e-04\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1969e-04 - val_loss: 9.1146e-04\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1552e-04 - val_loss: 9.0470e-04\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0951e-04 - val_loss: 8.8495e-04\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0549e-04 - val_loss: 8.8569e-04\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0327e-04 - val_loss: 8.7733e-04\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 9.8810e-05 - val_loss: 8.7540e-04\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 9.6717e-05 - val_loss: 8.6211e-04\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.2400e-05 - val_loss: 8.5970e-04\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.9686e-05 - val_loss: 8.4396e-04\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8.8282e-05 - val_loss: 8.3897e-04\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.5726e-05 - val_loss: 8.2758e-04\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.3100e-05 - val_loss: 8.3485e-04\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 7.9694e-05 - val_loss: 8.3362e-04\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 7.8443e-05 - val_loss: 8.2551e-04\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 7.5834e-05 - val_loss: 8.0904e-04\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 7.3529e-05 - val_loss: 8.0523e-04\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 7.1894e-05 - val_loss: 8.0978e-04\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 7.0652e-05 - val_loss: 7.9906e-04\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.7692e-05 - val_loss: 7.9992e-04\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.5603e-05 - val_loss: 7.9032e-04\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 6.4996e-05 - val_loss: 7.8362e-04\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 6.2942e-05 - val_loss: 7.8370e-04\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.0724e-05 - val_loss: 7.8590e-04\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 5.9216e-05 - val_loss: 7.8125e-04\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 5.8117e-05 - val_loss: 7.7318e-04\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 5.6435e-05 - val_loss: 7.6628e-04\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 5.6071e-05 - val_loss: 7.6866e-04\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 5.5172e-05 - val_loss: 7.6459e-04\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 5.3419e-05 - val_loss: 7.6345e-04\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 5.1657e-05 - val_loss: 7.4914e-04\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 5.2099e-05 - val_loss: 7.4149e-04\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 4.9450e-05 - val_loss: 7.5604e-04\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 4.8315e-05 - val_loss: 7.5754e-04\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 4.6930e-05 - val_loss: 7.3918e-04\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 4.6401e-05 - val_loss: 7.3258e-04\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.5704e-05 - val_loss: 7.4091e-04\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.3910e-05 - val_loss: 7.4005e-04\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.3246e-05 - val_loss: 7.3132e-04\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.1876e-05 - val_loss: 7.2987e-04\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.1234e-05 - val_loss: 7.2975e-04\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.0642e-05 - val_loss: 7.3072e-04\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.2294e-05 - val_loss: 7.1406e-04\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.9254e-05 - val_loss: 7.1659e-04\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.8713e-05 - val_loss: 7.2241e-04\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.7759e-05 - val_loss: 7.1529e-04\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.6489e-05 - val_loss: 7.0882e-04\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.5489e-05 - val_loss: 7.0346e-04\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.5517e-05 - val_loss: 7.1178e-04\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.4248e-05 - val_loss: 7.0088e-04\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.3661e-05 - val_loss: 7.0040e-04\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.2354e-05 - val_loss: 7.0285e-04\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.1489e-05 - val_loss: 6.9873e-04\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.1370e-05 - val_loss: 6.9489e-04\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.1359e-05 - val_loss: 6.8960e-04\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.0981e-05 - val_loss: 6.9407e-04\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.9456e-05 - val_loss: 6.8855e-04\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.9331e-05 - val_loss: 6.8391e-04\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.8451e-05 - val_loss: 6.8938e-04\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.8330e-05 - val_loss: 6.9004e-04\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.6943e-05 - val_loss: 6.8006e-04\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.7593e-05 - val_loss: 6.7590e-04\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.6128e-05 - val_loss: 6.7766e-04\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.5891e-05 - val_loss: 6.8022e-04\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.5301e-05 - val_loss: 6.7751e-04\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.5190e-05 - val_loss: 6.7736e-04\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 2.5220e-05 - val_loss: 6.6960e-04\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.4301e-05 - val_loss: 6.7535e-04\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.3791e-05 - val_loss: 6.7472e-04\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.3577e-05 - val_loss: 6.6464e-04\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.3695e-05 - val_loss: 6.6548e-04\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.2746e-05 - val_loss: 6.6548e-04\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.2204e-05 - val_loss: 6.6709e-04\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.2403e-05 - val_loss: 6.6601e-04\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.1631e-05 - val_loss: 6.6398e-04\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.1385e-05 - val_loss: 6.6019e-04\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0582e-05 - val_loss: 6.5983e-04\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0902e-05 - val_loss: 6.5975e-04\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.0476e-05 - val_loss: 6.5421e-04\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0409e-05 - val_loss: 6.5456e-04\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.9874e-05 - val_loss: 6.5570e-04\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9676e-05 - val_loss: 6.6056e-04\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9157e-05 - val_loss: 6.4933e-04\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9670e-05 - val_loss: 6.4883e-04\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9118e-05 - val_loss: 6.5419e-04\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.8702e-05 - val_loss: 6.4584e-04\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.8848e-05 - val_loss: 6.4217e-04\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.7829e-05 - val_loss: 6.5356e-04\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.7944e-05 - val_loss: 6.5153e-04\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7282e-05 - val_loss: 6.4126e-04\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.6917e-05 - val_loss: 6.3485e-04\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.7305e-05 - val_loss: 6.4370e-04\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.6782e-05 - val_loss: 6.3991e-04\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.6238e-05 - val_loss: 6.3911e-04\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.6610e-05 - val_loss: 6.4524e-04\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.6505e-05 - val_loss: 6.3826e-04\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.5555e-05 - val_loss: 6.4145e-04\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.5159e-05 - val_loss: 6.3595e-04\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.5161e-05 - val_loss: 6.2672e-04\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.4923e-05 - val_loss: 6.3312e-04\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.4349e-05 - val_loss: 6.3770e-04\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.4542e-05 - val_loss: 6.3971e-04\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.4467e-05 - val_loss: 6.2875e-04\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.4607e-05 - val_loss: 6.2757e-04\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.3672e-05 - val_loss: 6.2705e-04\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.3563e-05 - val_loss: 6.3360e-04\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3490e-05 - val_loss: 6.3196e-04\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.4181e-05 - val_loss: 6.3047e-04\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3369e-05 - val_loss: 6.1797e-04\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3921e-05 - val_loss: 6.2597e-04\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.2449e-05 - val_loss: 6.2653e-04\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2963e-05 - val_loss: 6.2574e-04\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2282e-05 - val_loss: 6.2501e-04\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.2144e-05 - val_loss: 6.2104e-04\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1989e-05 - val_loss: 6.2204e-04\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1886e-05 - val_loss: 6.2252e-04\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1574e-05 - val_loss: 6.1484e-04\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1017e-05 - val_loss: 6.1951e-04\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1247e-05 - val_loss: 6.2192e-04\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0404e-05 - val_loss: 6.1800e-04\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1471e-05 - val_loss: 6.1199e-04\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0653e-05 - val_loss: 6.2036e-04\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0708e-05 - val_loss: 6.2128e-04\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=loss_fn)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3eef2ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 8.3546e-05 - 203ms/epoch - 203ms/step\n",
      "tf.Tensor((1.0027990543824299+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeaacf2",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "170c6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d47c98eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 2s 116ms/step - loss: 0.4192 - val_loss: 0.3287\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2070 - val_loss: 0.1502\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0862 - val_loss: 0.0565\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0379 - val_loss: 0.0448\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0263 - val_loss: 0.0319\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0072 - val_loss: 0.0083\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 8.6032e-04 - val_loss: 0.0035\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 7.7919e-04 - val_loss: 0.0035\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 7.0245e-04 - val_loss: 0.0035\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 6.3892e-04 - val_loss: 0.0034\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.6782e-04 - val_loss: 0.0032\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.2013e-04 - val_loss: 0.0031\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 4.8058e-04 - val_loss: 0.0031\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.3989e-04 - val_loss: 0.0031\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 4.0457e-04 - val_loss: 0.0030\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.6215e-04 - val_loss: 0.0030\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.3960e-04 - val_loss: 0.0029\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.0683e-04 - val_loss: 0.0029\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.8624e-04 - val_loss: 0.0029\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.6376e-04 - val_loss: 0.0028\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.4574e-04 - val_loss: 0.0028\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.3210e-04 - val_loss: 0.0028\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.1570e-04 - val_loss: 0.0027\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.0902e-04 - val_loss: 0.0027\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.9385e-04 - val_loss: 0.0027\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.8194e-04 - val_loss: 0.0027\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.7081e-04 - val_loss: 0.0027\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.6125e-04 - val_loss: 0.0026\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.5422e-04 - val_loss: 0.0026\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.4625e-04 - val_loss: 0.0026\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3830e-04 - val_loss: 0.0026\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3503e-04 - val_loss: 0.0026\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2912e-04 - val_loss: 0.0026\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2300e-04 - val_loss: 0.0026\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1624e-04 - val_loss: 0.0026\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1284e-04 - val_loss: 0.0026\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0931e-04 - val_loss: 0.0025\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0323e-04 - val_loss: 0.0025\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 9.9880e-05 - val_loss: 0.0025\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 9.6433e-05 - val_loss: 0.0025\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 9.2486e-05 - val_loss: 0.0025\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 9.1706e-05 - val_loss: 0.0025\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.7422e-05 - val_loss: 0.0025\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.2415e-05 - val_loss: 0.0025\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.0864e-05 - val_loss: 0.0025\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 7.6890e-05 - val_loss: 0.0025\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 7.5412e-05 - val_loss: 0.0025\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 7.3832e-05 - val_loss: 0.0024\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 7.1427e-05 - val_loss: 0.0024\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 6.9720e-05 - val_loss: 0.0024\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.7146e-05 - val_loss: 0.0024\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.4519e-05 - val_loss: 0.0024\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.2013e-05 - val_loss: 0.0024\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.0427e-05 - val_loss: 0.0024\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.8098e-05 - val_loss: 0.0024\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 5.7532e-05 - val_loss: 0.0024\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 5.6414e-05 - val_loss: 0.0024\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.4203e-05 - val_loss: 0.0024\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.2024e-05 - val_loss: 0.0024\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.0764e-05 - val_loss: 0.0024\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 4.8073e-05 - val_loss: 0.0024\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.6846e-05 - val_loss: 0.0024\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 4.5480e-05 - val_loss: 0.0023\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.3444e-05 - val_loss: 0.0023\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.3693e-05 - val_loss: 0.0023\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.2683e-05 - val_loss: 0.0023\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 4.3978e-05 - val_loss: 0.0024\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 4.0652e-05 - val_loss: 0.0023\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.9816e-05 - val_loss: 0.0023\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.8815e-05 - val_loss: 0.0023\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 32ms/step - loss: 3.7387e-05 - val_loss: 0.0023\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.6784e-05 - val_loss: 0.0023\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.4846e-05 - val_loss: 0.0023\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 3.4055e-05 - val_loss: 0.0023\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.3486e-05 - val_loss: 0.0023\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.2550e-05 - val_loss: 0.0023\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.2187e-05 - val_loss: 0.0023\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.1243e-05 - val_loss: 0.0023\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.1807e-05 - val_loss: 0.0023\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.9768e-05 - val_loss: 0.0023\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.9038e-05 - val_loss: 0.0023\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.7165e-05 - val_loss: 0.0023\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 2.7227e-05 - val_loss: 0.0023\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.6086e-05 - val_loss: 0.0023\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.6327e-05 - val_loss: 0.0023\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.4928e-05 - val_loss: 0.0023\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.4903e-05 - val_loss: 0.0023\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.4575e-05 - val_loss: 0.0022\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.3939e-05 - val_loss: 0.0023\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.2908e-05 - val_loss: 0.0022\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2690e-05 - val_loss: 0.0022\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.1040e-05 - val_loss: 0.0022\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.1718e-05 - val_loss: 0.0022\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 2.1279e-05 - val_loss: 0.0022\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.0067e-05 - val_loss: 0.0022\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.9719e-05 - val_loss: 0.0022\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9979e-05 - val_loss: 0.0022\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.8756e-05 - val_loss: 0.0022\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.9278e-05 - val_loss: 0.0022\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.9036e-05 - val_loss: 0.0022\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.8038e-05 - val_loss: 0.0022\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.7834e-05 - val_loss: 0.0022\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.6937e-05 - val_loss: 0.0022\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.6104e-05 - val_loss: 0.0022\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6358e-05 - val_loss: 0.0022\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.5453e-05 - val_loss: 0.0022\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.5165e-05 - val_loss: 0.0022\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.5168e-05 - val_loss: 0.0022\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.4773e-05 - val_loss: 0.0022\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.4223e-05 - val_loss: 0.0022\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.3719e-05 - val_loss: 0.0022\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.3770e-05 - val_loss: 0.0022\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.3115e-05 - val_loss: 0.0022\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3243e-05 - val_loss: 0.0022\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.2864e-05 - val_loss: 0.0022\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.2346e-05 - val_loss: 0.0022\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1890e-05 - val_loss: 0.0022\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1753e-05 - val_loss: 0.0022\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.1855e-05 - val_loss: 0.0022\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1225e-05 - val_loss: 0.0022\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.1197e-05 - val_loss: 0.0022\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0650e-05 - val_loss: 0.0022\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1604e-05 - val_loss: 0.0022\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0927e-05 - val_loss: 0.0022\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0401e-05 - val_loss: 0.0022\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0632e-05 - val_loss: 0.0022\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0285e-05 - val_loss: 0.0022\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 9.4026e-06 - val_loss: 0.0022\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0014e-05 - val_loss: 0.0022\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.6276e-06 - val_loss: 0.0022\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.8304e-06 - val_loss: 0.0022\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 9.1895e-06 - val_loss: 0.0022\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 9.0390e-06 - val_loss: 0.0022\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.4996e-06 - val_loss: 0.0022\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 8.2359e-06 - val_loss: 0.0022\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 8.1003e-06 - val_loss: 0.0022\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 7.8246e-06 - val_loss: 0.0022\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 8.5399e-06 - val_loss: 0.0022\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.0749e-06 - val_loss: 0.0022\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 7.9066e-06 - val_loss: 0.0022\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 7.7635e-06 - val_loss: 0.0022\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 7.3880e-06 - val_loss: 0.0022\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 7.6100e-06 - val_loss: 0.0022\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 6.9812e-06 - val_loss: 0.0022\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 7.3448e-06 - val_loss: 0.0022\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 6.7815e-06 - val_loss: 0.0022\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 6.5863e-06 - val_loss: 0.0022\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 6.6534e-06 - val_loss: 0.0022\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.3896e-06 - val_loss: 0.0021\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 27ms/step - loss: 6.4731e-06 - val_loss: 0.0021\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.3762e-06 - val_loss: 0.0022\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 5.9411e-06 - val_loss: 0.0022\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 6.0990e-06 - val_loss: 0.0021\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 6.1244e-06 - val_loss: 0.0022\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 6.2883e-06 - val_loss: 0.0022\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 5.8562e-06 - val_loss: 0.0021\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.8606e-06 - val_loss: 0.0021\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 5.3629e-06 - val_loss: 0.0022\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 5.5760e-06 - val_loss: 0.0022\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.6669e-06 - val_loss: 0.0021\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.3331e-06 - val_loss: 0.0021\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 5.2363e-06 - val_loss: 0.0021\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 5.5403e-06 - val_loss: 0.0022\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 5.0962e-06 - val_loss: 0.0021\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 4.9770e-06 - val_loss: 0.0021\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 4.9591e-06 - val_loss: 0.0021\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.7773e-06 - val_loss: 0.0021\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 5.0351e-06 - val_loss: 0.0021\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 5.0172e-06 - val_loss: 0.0021\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 4.6819e-06 - val_loss: 0.0021\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 4.7565e-06 - val_loss: 0.0021\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 4.7177e-06 - val_loss: 0.0021\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 4.4718e-06 - val_loss: 0.0021\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 4.2841e-06 - val_loss: 0.0021\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.2871e-06 - val_loss: 0.0021\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 4.0725e-06 - val_loss: 0.0021\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.3064e-06 - val_loss: 0.0021\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.9712e-06 - val_loss: 0.0021\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.8505e-06 - val_loss: 0.0021\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 3.8698e-06 - val_loss: 0.0021\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.6225e-06 - val_loss: 0.0021\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 3.7342e-06 - val_loss: 0.0021\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.6612e-06 - val_loss: 0.0021\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.6255e-06 - val_loss: 0.0021\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 3.5256e-06 - val_loss: 0.0021\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.7268e-06 - val_loss: 0.0021\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.5331e-06 - val_loss: 0.0021\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.7327e-06 - val_loss: 0.0021\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 3.9220e-06 - val_loss: 0.0021\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 3.3781e-06 - val_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9973dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0016 - 237ms/epoch - 237ms/step\n",
      "tf.Tensor((0.9984285433625457+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c177d047",
   "metadata": {},
   "source": [
    "## General Pauli Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "05f010ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY ERROR \n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = g_pauli_error(1, density_matrix_noise_free[i], 0.7, 0.1, 0.1, 0.1)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "064627c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1db0f6",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8da6d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "69a68fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 65ms/step - loss: 0.3373 - val_loss: 0.3135\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2960 - val_loss: 0.2792\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2603 - val_loss: 0.2469\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2279 - val_loss: 0.2180\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1977 - val_loss: 0.1906\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1680 - val_loss: 0.1631\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1396 - val_loss: 0.1362\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1115 - val_loss: 0.1103\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0862 - val_loss: 0.0866\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0638 - val_loss: 0.0653\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0449 - val_loss: 0.0468\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0304 - val_loss: 0.0315\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0192 - val_loss: 0.0196\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0569e-04 - val_loss: 0.0014\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5406e-04 - val_loss: 0.0014\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5640e-04 - val_loss: 0.0014\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0181e-04 - val_loss: 0.0014\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6696e-04 - val_loss: 0.0013\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3741e-04 - val_loss: 0.0013\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1622e-04 - val_loss: 0.0012\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8379e-04 - val_loss: 0.0012\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5635e-04 - val_loss: 0.0011\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.4070e-04 - val_loss: 0.0011\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2257e-04 - val_loss: 0.0010\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.0845e-04 - val_loss: 0.0010\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8968e-04 - val_loss: 0.0010\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7864e-04 - val_loss: 9.8487e-04\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7117e-04 - val_loss: 9.4562e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2.5898e-04 - val_loss: 9.3022e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.4570e-04 - val_loss: 9.2763e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 2.3607e-04 - val_loss: 9.3169e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3176e-04 - val_loss: 8.9831e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.1730e-04 - val_loss: 8.6721e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1263e-04 - val_loss: 8.4702e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0369e-04 - val_loss: 8.3291e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9748e-04 - val_loss: 8.1246e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9160e-04 - val_loss: 8.1102e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.8535e-04 - val_loss: 7.9305e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7971e-04 - val_loss: 7.8994e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7269e-04 - val_loss: 7.7663e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6519e-04 - val_loss: 7.5456e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6094e-04 - val_loss: 7.3768e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5770e-04 - val_loss: 7.3805e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5362e-04 - val_loss: 7.1229e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4734e-04 - val_loss: 7.1487e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4697e-04 - val_loss: 7.1100e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4034e-04 - val_loss: 6.9415e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3631e-04 - val_loss: 6.7528e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3279e-04 - val_loss: 6.6570e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2800e-04 - val_loss: 6.4940e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2385e-04 - val_loss: 6.5391e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1983e-04 - val_loss: 6.4380e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.1633e-04 - val_loss: 6.3348e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1359e-04 - val_loss: 6.2286e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0911e-04 - val_loss: 6.1667e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0932e-04 - val_loss: 6.1427e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0501e-04 - val_loss: 6.0660e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0301e-04 - val_loss: 5.9749e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0035e-04 - val_loss: 6.0188e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0022e-04 - val_loss: 5.9624e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9299e-05 - val_loss: 5.8199e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3546e-05 - val_loss: 5.7662e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1626e-05 - val_loss: 5.7371e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9429e-05 - val_loss: 5.6254e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.8745e-05 - val_loss: 5.6500e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5699e-05 - val_loss: 5.7003e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5648e-05 - val_loss: 5.5994e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2207e-05 - val_loss: 5.5190e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0105e-05 - val_loss: 5.4959e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9385e-05 - val_loss: 5.4760e-04\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 26ms/step - loss: 7.8097e-05 - val_loss: 5.3950e-04\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5725e-05 - val_loss: 5.3981e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3810e-05 - val_loss: 5.3494e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2142e-05 - val_loss: 5.3533e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9063e-05 - val_loss: 5.3663e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7601e-05 - val_loss: 5.3031e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7430e-05 - val_loss: 5.2584e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7182e-05 - val_loss: 5.1949e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4013e-05 - val_loss: 5.2428e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3149e-05 - val_loss: 5.1692e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2215e-05 - val_loss: 5.1553e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1338e-05 - val_loss: 5.1112e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0465e-05 - val_loss: 5.1871e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9433e-05 - val_loss: 5.0193e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7903e-05 - val_loss: 4.9893e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.7161e-05 - val_loss: 5.0179e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.4800e-05 - val_loss: 4.9995e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.6193e-05 - val_loss: 4.9953e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.3548e-05 - val_loss: 4.9836e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3430e-05 - val_loss: 4.9039e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1711e-05 - val_loss: 4.8428e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1922e-05 - val_loss: 4.8793e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9654e-05 - val_loss: 4.8489e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0290e-05 - val_loss: 4.8541e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.8475e-05 - val_loss: 4.7461e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7932e-05 - val_loss: 4.7805e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6513e-05 - val_loss: 4.8011e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6223e-05 - val_loss: 4.6989e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4673e-05 - val_loss: 4.7183e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4422e-05 - val_loss: 4.6902e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4917e-05 - val_loss: 4.6438e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.3377e-05 - val_loss: 4.6684e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2702e-05 - val_loss: 4.6415e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.3049e-05 - val_loss: 4.6193e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.1003e-05 - val_loss: 4.6245e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1070e-05 - val_loss: 4.5812e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.9612e-05 - val_loss: 4.5642e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9277e-05 - val_loss: 4.5008e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8032e-05 - val_loss: 4.5326e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8786e-05 - val_loss: 4.5667e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6785e-05 - val_loss: 4.5057e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9280e-05 - val_loss: 4.4248e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5474e-05 - val_loss: 4.5528e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5673e-05 - val_loss: 4.4889e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.5737e-05 - val_loss: 4.4686e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3538e-05 - val_loss: 4.4568e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.3762e-05 - val_loss: 4.3791e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3275e-05 - val_loss: 4.3679e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.2590e-05 - val_loss: 4.4640e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2561e-05 - val_loss: 4.3565e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.0605e-05 - val_loss: 4.3235e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.1130e-05 - val_loss: 4.3615e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0550e-05 - val_loss: 4.3702e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.1116e-05 - val_loss: 4.3477e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.9315e-05 - val_loss: 4.2896e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0325e-05 - val_loss: 4.2732e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9401e-05 - val_loss: 4.2552e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8353e-05 - val_loss: 4.2806e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.8299e-05 - val_loss: 4.2209e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6925e-05 - val_loss: 4.1730e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7499e-05 - val_loss: 4.2163e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.6683e-05 - val_loss: 4.2294e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.6079e-05 - val_loss: 4.2195e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.5551e-05 - val_loss: 4.2313e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.6424e-05 - val_loss: 4.1449e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5022e-05 - val_loss: 4.1277e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5311e-05 - val_loss: 4.1609e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.5373e-05 - val_loss: 4.2173e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.4533e-05 - val_loss: 4.1772e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.4318e-05 - val_loss: 4.1035e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2848e-05 - val_loss: 4.0854e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2679e-05 - val_loss: 4.0678e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2704e-05 - val_loss: 4.0992e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2911e-05 - val_loss: 4.1383e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2255e-05 - val_loss: 4.0664e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1544e-05 - val_loss: 4.0657e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1710e-05 - val_loss: 4.0290e-04\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1422e-05 - val_loss: 4.0060e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1158e-05 - val_loss: 4.0272e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0857e-05 - val_loss: 4.0221e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0734e-05 - val_loss: 3.9679e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0117e-05 - val_loss: 3.9679e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0829e-05 - val_loss: 4.0410e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9668e-05 - val_loss: 3.9766e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9701e-05 - val_loss: 3.9876e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9712e-05 - val_loss: 3.9241e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9956e-05 - val_loss: 3.9216e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.9849e-05 - val_loss: 3.9311e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9513e-05 - val_loss: 4.0014e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7985e-05 - val_loss: 3.8928e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9325e-05 - val_loss: 3.8691e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.7728e-05 - val_loss: 3.8719e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8043e-05 - val_loss: 3.8922e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7504e-05 - val_loss: 3.8751e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8328e-05 - val_loss: 3.8611e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.8269e-05 - val_loss: 3.8301e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6699e-05 - val_loss: 3.8193e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.8145e-05 - val_loss: 3.7844e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6912e-05 - val_loss: 3.8099e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6778e-05 - val_loss: 3.8434e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5984e-05 - val_loss: 3.7742e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6218e-05 - val_loss: 3.7951e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6113e-05 - val_loss: 3.7992e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5605e-05 - val_loss: 3.7773e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5885e-05 - val_loss: 3.7454e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5616e-05 - val_loss: 3.7655e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6199e-05 - val_loss: 3.7484e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5780e-05 - val_loss: 3.7846e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4903e-05 - val_loss: 3.7295e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4546e-05 - val_loss: 3.7222e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4495e-05 - val_loss: 3.6979e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4588e-05 - val_loss: 3.6822e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4733e-05 - val_loss: 3.7101e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5186e-05 - val_loss: 3.6811e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3437e-05 - val_loss: 3.7029e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3779e-05 - val_loss: 3.6439e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4385e-05 - val_loss: 3.6391e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.3407e-05 - val_loss: 3.6502e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2918e-05 - val_loss: 3.6432e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3913e-05 - val_loss: 3.6980e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3503e-05 - val_loss: 3.5998e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3235e-05 - val_loss: 3.5682e-04\n"
     ]
    }
   ],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=loss_fn)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ad16a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.8501e-04 - 193ms/epoch - 193ms/step\n",
      "tf.Tensor((0.998422795183377+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23515161",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b78bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b028e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 89ms/step - loss: 0.2614 - val_loss: 0.1932\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1053 - val_loss: 0.0749\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0348 - val_loss: 0.0379\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0196 - val_loss: 0.0233\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0075 - val_loss: 0.0086\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0051 - val_loss: 0.0069\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5374e-04 - val_loss: 0.0019\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.1760e-04 - val_loss: 0.0017\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8956e-04 - val_loss: 0.0016\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1599e-04 - val_loss: 0.0015\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.3157e-04 - val_loss: 0.0015\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.6444e-04 - val_loss: 0.0014\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.0550e-04 - val_loss: 0.0013\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.7067e-04 - val_loss: 0.0012\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4604e-04 - val_loss: 0.0012\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8903e-04 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.7322e-04 - val_loss: 0.0012\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4508e-04 - val_loss: 0.0011\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.1872e-04 - val_loss: 0.0011\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0113e-04 - val_loss: 0.0011\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.8699e-04 - val_loss: 0.0011\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7403e-04 - val_loss: 0.0011\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5960e-04 - val_loss: 0.0011\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5230e-04 - val_loss: 0.0011\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4562e-04 - val_loss: 0.0010\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3572e-04 - val_loss: 0.0010\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3238e-04 - val_loss: 0.0010\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2815e-04 - val_loss: 0.0010\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1955e-04 - val_loss: 0.0010\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.1496e-04 - val_loss: 0.0010\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0877e-04 - val_loss: 0.0010\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0098e-04 - val_loss: 9.9250e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6549e-05 - val_loss: 9.8409e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.2149e-05 - val_loss: 9.7877e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9608e-05 - val_loss: 9.7363e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6130e-05 - val_loss: 9.6819e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2802e-05 - val_loss: 9.7377e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0124e-05 - val_loss: 9.5026e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.7543e-05 - val_loss: 9.4449e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.6529e-05 - val_loss: 9.8025e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1756e-05 - val_loss: 9.5182e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9566e-05 - val_loss: 9.3271e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4317e-05 - val_loss: 9.3645e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3002e-05 - val_loss: 9.4076e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0104e-05 - val_loss: 9.3106e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9298e-05 - val_loss: 9.2340e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8856e-05 - val_loss: 9.2427e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5488e-05 - val_loss: 9.2759e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6238e-05 - val_loss: 9.2128e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0988e-05 - val_loss: 9.1898e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9174e-05 - val_loss: 8.9841e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0303e-05 - val_loss: 8.9372e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5927e-05 - val_loss: 8.9592e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5911e-05 - val_loss: 9.1817e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4246e-05 - val_loss: 8.9553e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.4290e-05 - val_loss: 8.7943e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0730e-05 - val_loss: 8.8906e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2647e-05 - val_loss: 9.0495e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7967e-05 - val_loss: 8.8502e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9110e-05 - val_loss: 8.7992e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4934e-05 - val_loss: 8.7546e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5490e-05 - val_loss: 8.8128e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.8562e-05 - val_loss: 8.8427e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.2803e-05 - val_loss: 8.5952e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3190e-05 - val_loss: 8.5784e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.1792e-05 - val_loss: 8.8597e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1930e-05 - val_loss: 8.8159e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.1294e-05 - val_loss: 8.5334e-04\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.9290e-05 - val_loss: 8.6210e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8939e-05 - val_loss: 8.6880e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.6475e-05 - val_loss: 8.6611e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.6577e-05 - val_loss: 8.6052e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.5494e-05 - val_loss: 8.4603e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4980e-05 - val_loss: 8.6161e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.4319e-05 - val_loss: 8.5469e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.3416e-05 - val_loss: 8.5253e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.3993e-05 - val_loss: 8.5657e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.5094e-05 - val_loss: 8.5710e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3804e-05 - val_loss: 8.3461e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1507e-05 - val_loss: 8.5450e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1245e-05 - val_loss: 8.4517e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.1685e-05 - val_loss: 8.4483e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9425e-05 - val_loss: 8.3626e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9420e-05 - val_loss: 8.4761e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8615e-05 - val_loss: 8.4345e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0021e-05 - val_loss: 8.3630e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6834e-05 - val_loss: 8.2647e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0709e-05 - val_loss: 8.4544e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8413e-05 - val_loss: 8.5388e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7346e-05 - val_loss: 8.2234e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5572e-05 - val_loss: 8.4990e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7135e-05 - val_loss: 8.3916e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5335e-05 - val_loss: 8.1160e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5237e-05 - val_loss: 8.4481e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.4974e-05 - val_loss: 8.3322e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4176e-05 - val_loss: 8.2150e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4545e-05 - val_loss: 8.3860e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.4017e-05 - val_loss: 8.4685e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4344e-05 - val_loss: 8.1370e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2763e-05 - val_loss: 8.4183e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2791e-05 - val_loss: 8.2822e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3283e-05 - val_loss: 8.3448e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1908e-05 - val_loss: 8.4289e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3368e-05 - val_loss: 8.1788e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2374e-05 - val_loss: 8.2589e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.3051e-05 - val_loss: 8.2838e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0480e-05 - val_loss: 8.1606e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.1322e-05 - val_loss: 8.2984e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0488e-05 - val_loss: 8.2559e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0481e-05 - val_loss: 8.2200e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0376e-05 - val_loss: 8.1330e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1009e-05 - val_loss: 8.3452e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0448e-05 - val_loss: 8.2504e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6393e-06 - val_loss: 8.1698e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.2243e-05 - val_loss: 8.2449e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1107e-05 - val_loss: 8.1553e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.1956e-06 - val_loss: 8.3400e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9002e-06 - val_loss: 8.1458e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1801e-06 - val_loss: 8.1458e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8642e-06 - val_loss: 8.2365e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7105e-06 - val_loss: 8.1362e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9167e-06 - val_loss: 8.1208e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5531e-06 - val_loss: 8.3113e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2205e-06 - val_loss: 8.0810e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7856e-06 - val_loss: 8.1712e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0226e-06 - val_loss: 8.2741e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0524e-06 - val_loss: 8.1122e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3646e-06 - val_loss: 8.1703e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8510e-06 - val_loss: 8.1911e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3312e-06 - val_loss: 8.1314e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0000e-06 - val_loss: 8.1764e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0630e-06 - val_loss: 8.0849e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0439e-06 - val_loss: 8.2090e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9462e-06 - val_loss: 8.1155e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.6219e-06 - val_loss: 8.0696e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8150e-06 - val_loss: 8.2056e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5611e-06 - val_loss: 8.0851e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.0426e-06 - val_loss: 8.1898e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.9233e-06 - val_loss: 8.0699e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.9269e-06 - val_loss: 8.1658e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5633e-06 - val_loss: 8.1015e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9961e-06 - val_loss: 8.0974e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.5729e-06 - val_loss: 8.0969e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.5896e-06 - val_loss: 8.1821e-04\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5705e-06 - val_loss: 7.9962e-04\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3988e-06 - val_loss: 8.1232e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3011e-06 - val_loss: 8.0965e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9411e-06 - val_loss: 8.0774e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1473e-06 - val_loss: 8.0569e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6967e-06 - val_loss: 8.1325e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9673e-06 - val_loss: 8.0434e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6788e-06 - val_loss: 8.1064e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.7503e-06 - val_loss: 8.1342e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.9577e-06 - val_loss: 7.9748e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.6871e-06 - val_loss: 8.1200e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6074e-06 - val_loss: 8.0919e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.7050e-06 - val_loss: 8.0300e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9101e-06 - val_loss: 8.0837e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0008e-06 - val_loss: 8.0369e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6001e-06 - val_loss: 8.1554e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.5954e-06 - val_loss: 7.9351e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.4249e-06 - val_loss: 8.0736e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0267e-06 - val_loss: 8.0064e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5608e-06 - val_loss: 8.1383e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5048e-06 - val_loss: 7.9867e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2997e-06 - val_loss: 8.0422e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0565e-06 - val_loss: 8.0847e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4094e-06 - val_loss: 8.1014e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8145e-06 - val_loss: 8.0173e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.7645e-06 - val_loss: 7.9594e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.7394e-06 - val_loss: 8.1327e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.7764e-06 - val_loss: 7.9449e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.8896e-06 - val_loss: 8.0493e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.6643e-06 - val_loss: 8.0408e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.9147e-06 - val_loss: 7.9712e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.4988e-06 - val_loss: 8.0091e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.6476e-06 - val_loss: 7.9987e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.7001e-06 - val_loss: 8.1275e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4748e-06 - val_loss: 7.9119e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4152e-06 - val_loss: 8.0710e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.9135e-06 - val_loss: 7.9677e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.4176e-06 - val_loss: 8.0183e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6834e-06 - val_loss: 7.9583e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1887e-06 - val_loss: 8.0897e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3091e-06 - val_loss: 7.9472e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.5952e-06 - val_loss: 8.0005e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9670e-06 - val_loss: 8.0173e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1601e-06 - val_loss: 8.0065e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.9455e-06 - val_loss: 7.9540e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.9944e-06 - val_loss: 7.9664e-04\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b1b248b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 5.4007e-04 - 256ms/epoch - 256ms/step\n",
      "tf.Tensor((0.9994599367812246+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa17001",
   "metadata": {},
   "source": [
    "## Amplitude Damping Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98175936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY ERROR \n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = ampl_damp_error(1, density_matrix_noise_free[i], 0.5, 0.3)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6174896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4111ddde",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e0d4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),  \n",
    "  tf.keras.layers.Dense(64, activation='relu'),                                  \n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f549360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt,\n",
    "              loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa696782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 69ms/step - loss: 0.3438 - val_loss: 0.3112\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2880 - val_loss: 0.2647\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2401 - val_loss: 0.2229\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1980 - val_loss: 0.1859\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1600 - val_loss: 0.1528\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1266 - val_loss: 0.1227\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0976 - val_loss: 0.0962\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0724 - val_loss: 0.0727\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0513 - val_loss: 0.0532\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0351 - val_loss: 0.0373\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0227 - val_loss: 0.0253\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0171\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0097 - val_loss: 0.0120\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0070 - val_loss: 0.0092\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9921e-04 - val_loss: 0.0021\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4957e-04 - val_loss: 0.0019\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1925e-04 - val_loss: 0.0017\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1949e-04 - val_loss: 0.0015\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4257e-04 - val_loss: 0.0014\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8936e-04 - val_loss: 0.0013\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4548e-04 - val_loss: 0.0013\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1045e-04 - val_loss: 0.0012\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.7321e-04 - val_loss: 0.0012\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5201e-04 - val_loss: 0.0011\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3045e-04 - val_loss: 0.0011\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.0991e-04 - val_loss: 0.0010\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9923e-04 - val_loss: 0.0010\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8700e-04 - val_loss: 9.8416e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7538e-04 - val_loss: 9.8580e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.6486e-04 - val_loss: 9.5980e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5086e-04 - val_loss: 9.3441e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.4783e-04 - val_loss: 9.2983e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4299e-04 - val_loss: 9.2463e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.2858e-04 - val_loss: 8.9670e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2038e-04 - val_loss: 8.7927e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1073e-04 - val_loss: 8.6340e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0643e-04 - val_loss: 8.6336e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0047e-04 - val_loss: 8.6241e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9199e-04 - val_loss: 8.5197e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.8715e-04 - val_loss: 8.3024e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8047e-04 - val_loss: 8.1400e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7600e-04 - val_loss: 8.1425e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7444e-04 - val_loss: 8.1519e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6683e-04 - val_loss: 8.1442e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6019e-04 - val_loss: 7.9604e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5831e-04 - val_loss: 7.8213e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5298e-04 - val_loss: 7.8804e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4872e-04 - val_loss: 7.8098e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4400e-04 - val_loss: 7.6523e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3939e-04 - val_loss: 7.5394e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3765e-04 - val_loss: 7.6375e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3424e-04 - val_loss: 7.5297e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3115e-04 - val_loss: 7.4735e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2839e-04 - val_loss: 7.3731e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2313e-04 - val_loss: 7.1715e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2255e-04 - val_loss: 7.1625e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1687e-04 - val_loss: 7.2567e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1580e-04 - val_loss: 7.2176e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1672e-04 - val_loss: 7.2026e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1131e-04 - val_loss: 7.1486e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0843e-04 - val_loss: 6.8963e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0898e-04 - val_loss: 6.7769e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0654e-04 - val_loss: 6.7554e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0297e-04 - val_loss: 6.8433e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0155e-04 - val_loss: 6.8018e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.8438e-05 - val_loss: 6.6980e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9656e-05 - val_loss: 6.8351e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.8096e-05 - val_loss: 6.6961e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1342e-05 - val_loss: 6.5943e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9196e-05 - val_loss: 6.5301e-04\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7373e-05 - val_loss: 6.4545e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5996e-05 - val_loss: 6.4531e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3370e-05 - val_loss: 6.3930e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0857e-05 - val_loss: 6.4307e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0033e-05 - val_loss: 6.4448e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1206e-05 - val_loss: 6.3777e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8943e-05 - val_loss: 6.2718e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7014e-05 - val_loss: 6.2832e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2998e-05 - val_loss: 6.2025e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5034e-05 - val_loss: 6.0144e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3333e-05 - val_loss: 6.2153e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.0391e-05 - val_loss: 6.0823e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8472e-05 - val_loss: 6.0944e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7442e-05 - val_loss: 6.0201e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.6509e-05 - val_loss: 5.9701e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8180e-05 - val_loss: 6.0262e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3879e-05 - val_loss: 6.1298e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4534e-05 - val_loss: 5.9138e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0628e-05 - val_loss: 5.8603e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1075e-05 - val_loss: 5.8376e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8379e-05 - val_loss: 5.8818e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9209e-05 - val_loss: 5.7964e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9466e-05 - val_loss: 5.7665e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5883e-05 - val_loss: 5.6646e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7329e-05 - val_loss: 5.7391e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4127e-05 - val_loss: 5.7815e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5033e-05 - val_loss: 5.7702e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4121e-05 - val_loss: 5.5396e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0451e-05 - val_loss: 5.5223e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.0936e-05 - val_loss: 5.5498e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.0894e-05 - val_loss: 5.6029e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9454e-05 - val_loss: 5.6854e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8359e-05 - val_loss: 5.5377e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.8084e-05 - val_loss: 5.4629e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5193e-05 - val_loss: 5.5883e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6278e-05 - val_loss: 5.4394e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.4841e-05 - val_loss: 5.3367e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3316e-05 - val_loss: 5.4362e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5241e-05 - val_loss: 5.4826e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4844e-05 - val_loss: 5.3112e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2887e-05 - val_loss: 5.4164e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1022e-05 - val_loss: 5.3346e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.1112e-05 - val_loss: 5.3557e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0518e-05 - val_loss: 5.3659e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8589e-05 - val_loss: 5.2002e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8617e-05 - val_loss: 5.2495e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8181e-05 - val_loss: 5.2424e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8480e-05 - val_loss: 5.3078e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.7442e-05 - val_loss: 5.2695e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.6064e-05 - val_loss: 5.1523e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4965e-05 - val_loss: 5.1669e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6239e-05 - val_loss: 5.1883e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5202e-05 - val_loss: 5.1356e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6274e-05 - val_loss: 5.2026e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2909e-05 - val_loss: 5.1537e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.4544e-05 - val_loss: 5.1193e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3058e-05 - val_loss: 5.0814e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.2455e-05 - val_loss: 5.1179e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2697e-05 - val_loss: 5.0858e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.1268e-05 - val_loss: 4.9792e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0908e-05 - val_loss: 5.0010e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2821e-05 - val_loss: 5.1823e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2725e-05 - val_loss: 4.9980e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.9308e-05 - val_loss: 5.0685e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9970e-05 - val_loss: 5.0189e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9281e-05 - val_loss: 4.9085e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7950e-05 - val_loss: 4.9845e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.7444e-05 - val_loss: 5.0195e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.7947e-05 - val_loss: 4.9617e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6694e-05 - val_loss: 4.9682e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7209e-05 - val_loss: 4.9359e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7131e-05 - val_loss: 4.9183e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.5890e-05 - val_loss: 4.9731e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6232e-05 - val_loss: 4.9832e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.6459e-05 - val_loss: 4.8567e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.5448e-05 - val_loss: 4.9867e-04\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.5002e-05 - val_loss: 4.8622e-04\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 26ms/step - loss: 2.6931e-05 - val_loss: 4.8200e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.5278e-05 - val_loss: 4.9928e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.4084e-05 - val_loss: 4.8646e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5674e-05 - val_loss: 4.8431e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.2595e-05 - val_loss: 4.8528e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3735e-05 - val_loss: 4.8532e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3329e-05 - val_loss: 4.8252e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3111e-05 - val_loss: 4.8912e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2826e-05 - val_loss: 4.7459e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2834e-05 - val_loss: 4.8483e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2815e-05 - val_loss: 4.8343e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.1708e-05 - val_loss: 4.7917e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.2458e-05 - val_loss: 4.8022e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3879e-05 - val_loss: 4.8137e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2761e-05 - val_loss: 4.7368e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.3059e-05 - val_loss: 4.8425e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1385e-05 - val_loss: 4.8091e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.9933e-05 - val_loss: 4.7367e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.0205e-05 - val_loss: 4.7731e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.9722e-05 - val_loss: 4.7999e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9803e-05 - val_loss: 4.7224e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8640e-05 - val_loss: 4.6994e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8177e-05 - val_loss: 4.7713e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.8179e-05 - val_loss: 4.7134e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7563e-05 - val_loss: 4.7321e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7309e-05 - val_loss: 4.7349e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7082e-05 - val_loss: 4.7507e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7186e-05 - val_loss: 4.6375e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6935e-05 - val_loss: 4.7630e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6960e-05 - val_loss: 4.6672e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6223e-05 - val_loss: 4.6854e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6697e-05 - val_loss: 4.7059e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6657e-05 - val_loss: 4.6530e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6041e-05 - val_loss: 4.7445e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6176e-05 - val_loss: 4.6113e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6511e-05 - val_loss: 4.6628e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6040e-05 - val_loss: 4.6649e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5800e-05 - val_loss: 4.6199e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4888e-05 - val_loss: 4.6466e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5045e-05 - val_loss: 4.6597e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.3808e-05 - val_loss: 4.6440e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4462e-05 - val_loss: 4.6311e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3646e-05 - val_loss: 4.5870e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4311e-05 - val_loss: 4.5667e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2694e-05 - val_loss: 4.6070e-04\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val,y_val),batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09ce5432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.4444e-04 - 217ms/epoch - 217ms/step\n",
      "tf.Tensor((0.9994821667701119+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4a9ee",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2b3bd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "15dede24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 94ms/step - loss: 0.2476 - val_loss: 0.1519\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1033 - val_loss: 0.0519\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0409 - val_loss: 0.0232\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0260 - val_loss: 0.0179\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0107\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2583e-04 - val_loss: 0.0013\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8697e-04 - val_loss: 0.0011\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7646e-04 - val_loss: 0.0010\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9247e-04 - val_loss: 8.7002e-04\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2985e-04 - val_loss: 7.7479e-04\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.7162e-04 - val_loss: 7.2684e-04\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3410e-04 - val_loss: 6.9486e-04\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0187e-04 - val_loss: 6.8570e-04\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.6940e-04 - val_loss: 6.7627e-04\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4578e-04 - val_loss: 6.5697e-04\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.3077e-04 - val_loss: 6.4153e-04\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.1040e-04 - val_loss: 6.3823e-04\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9253e-04 - val_loss: 6.2257e-04\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8285e-04 - val_loss: 6.1435e-04\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6681e-04 - val_loss: 6.0536e-04\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5823e-04 - val_loss: 5.9486e-04\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4734e-04 - val_loss: 5.9572e-04\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3756e-04 - val_loss: 5.9219e-04\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3040e-04 - val_loss: 5.8749e-04\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2202e-04 - val_loss: 5.7381e-04\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1671e-04 - val_loss: 5.7281e-04\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1093e-04 - val_loss: 5.6829e-04\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0244e-04 - val_loss: 5.6195e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5924e-05 - val_loss: 5.5294e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1178e-05 - val_loss: 5.5389e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7624e-05 - val_loss: 5.5804e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.2518e-05 - val_loss: 5.4590e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9752e-05 - val_loss: 5.4152e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3380e-05 - val_loss: 5.3675e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.1356e-05 - val_loss: 5.3195e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8632e-05 - val_loss: 5.2848e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6785e-05 - val_loss: 5.2798e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2369e-05 - val_loss: 5.1949e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0461e-05 - val_loss: 5.1570e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9373e-05 - val_loss: 5.2273e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5245e-05 - val_loss: 5.1001e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1852e-05 - val_loss: 5.0763e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9876e-05 - val_loss: 5.1609e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.8549e-05 - val_loss: 5.1088e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6045e-05 - val_loss: 5.0503e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4518e-05 - val_loss: 4.9169e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2976e-05 - val_loss: 5.0054e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1965e-05 - val_loss: 4.9636e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0005e-05 - val_loss: 5.0093e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9480e-05 - val_loss: 4.9795e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7856e-05 - val_loss: 4.9033e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6423e-05 - val_loss: 4.8376e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5019e-05 - val_loss: 4.9266e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.3674e-05 - val_loss: 4.8326e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.2555e-05 - val_loss: 4.9078e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.1620e-05 - val_loss: 4.8717e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.9622e-05 - val_loss: 4.8295e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.9559e-05 - val_loss: 4.8286e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7611e-05 - val_loss: 4.8033e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.6783e-05 - val_loss: 4.7787e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.5963e-05 - val_loss: 4.7436e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.4908e-05 - val_loss: 4.7479e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3880e-05 - val_loss: 4.7439e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.3597e-05 - val_loss: 4.7399e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2572e-05 - val_loss: 4.7278e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.2767e-05 - val_loss: 4.7193e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1181e-05 - val_loss: 4.7108e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1741e-05 - val_loss: 4.6693e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.0089e-05 - val_loss: 4.7279e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9062e-05 - val_loss: 4.6442e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9443e-05 - val_loss: 4.6022e-04\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8431e-05 - val_loss: 4.6814e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8625e-05 - val_loss: 4.5809e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6893e-05 - val_loss: 4.6495e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6376e-05 - val_loss: 4.6616e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6605e-05 - val_loss: 4.5626e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5475e-05 - val_loss: 4.5783e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5235e-05 - val_loss: 4.6536e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4232e-05 - val_loss: 4.5873e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4387e-05 - val_loss: 4.5248e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4179e-05 - val_loss: 4.5812e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3236e-05 - val_loss: 4.5393e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2736e-05 - val_loss: 4.5040e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.2633e-05 - val_loss: 4.5703e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2648e-05 - val_loss: 4.5089e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.1520e-05 - val_loss: 4.5716e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.1126e-05 - val_loss: 4.5508e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0941e-05 - val_loss: 4.4985e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0631e-05 - val_loss: 4.4815e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0371e-05 - val_loss: 4.5342e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0099e-05 - val_loss: 4.4847e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5153e-06 - val_loss: 4.4993e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7823e-06 - val_loss: 4.5403e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4855e-06 - val_loss: 4.4677e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0790e-06 - val_loss: 4.4663e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.9133e-06 - val_loss: 4.5451e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6987e-06 - val_loss: 4.4859e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5068e-06 - val_loss: 4.4544e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3005e-06 - val_loss: 4.4942e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8452e-06 - val_loss: 4.4463e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8046e-06 - val_loss: 4.4668e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4244e-06 - val_loss: 4.4346e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8356e-06 - val_loss: 4.4522e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0012e-06 - val_loss: 4.4691e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0894e-06 - val_loss: 4.4100e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1037e-06 - val_loss: 4.4427e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8140e-06 - val_loss: 4.4585e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7711e-06 - val_loss: 4.4009e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2418e-06 - val_loss: 4.4676e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5076e-06 - val_loss: 4.4355e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0427e-06 - val_loss: 4.4176e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3229e-06 - val_loss: 4.4035e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9843e-06 - val_loss: 4.4585e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2752e-06 - val_loss: 4.3895e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5742e-06 - val_loss: 4.4755e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9271e-06 - val_loss: 4.3998e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7137e-06 - val_loss: 4.4082e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7745e-06 - val_loss: 4.4622e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2464e-06 - val_loss: 4.3843e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2893e-06 - val_loss: 4.4511e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0867e-06 - val_loss: 4.4389e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7052e-06 - val_loss: 4.3930e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9770e-06 - val_loss: 4.4013e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7290e-06 - val_loss: 4.4597e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6933e-06 - val_loss: 4.4050e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6122e-06 - val_loss: 4.4170e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3440e-06 - val_loss: 4.4249e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2045e-06 - val_loss: 4.4111e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2522e-06 - val_loss: 4.4107e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1068e-06 - val_loss: 4.4252e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9947e-06 - val_loss: 4.3820e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1127e-06 - val_loss: 4.4024e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5562e-06 - val_loss: 4.4444e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7777e-06 - val_loss: 4.3919e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9637e-06 - val_loss: 4.4220e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8075e-06 - val_loss: 4.4186e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9566e-06 - val_loss: 4.4002e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.4606e-06 - val_loss: 4.4239e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6168e-06 - val_loss: 4.4224e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5274e-06 - val_loss: 4.3932e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3128e-06 - val_loss: 4.4077e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5822e-06 - val_loss: 4.3921e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4690e-06 - val_loss: 4.3965e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4487e-06 - val_loss: 4.4238e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.1638e-06 - val_loss: 4.3716e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0625e-06 - val_loss: 4.3881e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0458e-06 - val_loss: 4.4082e-04\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8837e-06 - val_loss: 4.3987e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.9290e-06 - val_loss: 4.4086e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.0744e-06 - val_loss: 4.3855e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2616e-06 - val_loss: 4.3779e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7871e-06 - val_loss: 4.3926e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.7001e-06 - val_loss: 4.3930e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8992e-06 - val_loss: 4.4083e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8586e-06 - val_loss: 4.3745e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2473e-06 - val_loss: 4.4049e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5880e-06 - val_loss: 4.3824e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5833e-06 - val_loss: 4.3947e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5749e-06 - val_loss: 4.4037e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7442e-06 - val_loss: 4.3949e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8801e-06 - val_loss: 4.3838e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.4474e-06 - val_loss: 4.3991e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3162e-06 - val_loss: 4.3748e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.3437e-06 - val_loss: 4.3863e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.2471e-06 - val_loss: 4.3501e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2745e-06 - val_loss: 4.3738e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.4068e-06 - val_loss: 4.3744e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.0802e-06 - val_loss: 4.3757e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1780e-06 - val_loss: 4.3692e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.0897e-06 - val_loss: 4.3717e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1493e-06 - val_loss: 4.3706e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0969e-06 - val_loss: 4.3751e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.2352e-06 - val_loss: 4.3713e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9741e-06 - val_loss: 4.3900e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9169e-06 - val_loss: 4.3600e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9181e-06 - val_loss: 4.3738e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9610e-06 - val_loss: 4.3526e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.9991e-06 - val_loss: 4.3714e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8716e-06 - val_loss: 4.3759e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8275e-06 - val_loss: 4.3388e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8573e-06 - val_loss: 4.3639e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.8024e-06 - val_loss: 4.3648e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7881e-06 - val_loss: 4.3516e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7095e-06 - val_loss: 4.3859e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7655e-06 - val_loss: 4.3715e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7238e-06 - val_loss: 4.3777e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8704e-06 - val_loss: 4.3803e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7893e-06 - val_loss: 4.3639e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6940e-06 - val_loss: 4.3878e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6975e-06 - val_loss: 4.3690e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5080e-06 - val_loss: 4.3773e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7095e-06 - val_loss: 4.3562e-04\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2521dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 2.9617e-04 - 258ms/epoch - 258ms/step\n",
      "tf.Tensor((0.9997038259280812+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535347a5",
   "metadata": {},
   "source": [
    "## Depolarizing Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0d9bdb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY ERROR \n",
    "density_matrix_with_noise = []\n",
    "for i in range(len(data)):\n",
    "    single_data_with_noise = depolar_error(1, density_matrix_noise_free[i], 0.3)\n",
    "    density_matrix_with_noise.append(single_data_with_noise)\n",
    "#COMPUTE_BLOCH VECTOR WITH NOISE\n",
    "bloch_vectors_with_noise = [*map(Bloch_vector, density_matrix_with_noise)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "549f545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the training, validation and test set \n",
    "\n",
    "x_train_list, x_val_list, x_test_list = bloch_vectors_with_noise[:50], bloch_vectors_with_noise[50:90], bloch_vectors_with_noise[90:]\n",
    "y_train_list, y_val_list, y_test_list = bloch_vectors_noise_free[:50], bloch_vectors_noise_free[50:90], bloch_vectors_noise_free[90:]\n",
    "\n",
    "#Convert to tensors\n",
    "x_train = tf.convert_to_tensor(x_train_list)\n",
    "y_train = tf.convert_to_tensor(y_train_list)\n",
    "\n",
    "x_val = tf.convert_to_tensor(x_val_list)\n",
    "y_val = tf.convert_to_tensor(y_val_list)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test_list)\n",
    "y_test = tf.convert_to_tensor(y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ace025",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "361b4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),  \n",
    "  tf.keras.layers.Dense(64, activation='relu'),                                  \n",
    "  tf.keras.layers.Dense(3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b9792d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "loss_fn = tf.keras.losses.mse\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt,\n",
    "              loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "882d7fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 94ms/step - loss: 0.3186 - val_loss: 0.2986\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2720 - val_loss: 0.2576\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2315 - val_loss: 0.2189\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1948 - val_loss: 0.1846\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1607 - val_loss: 0.1540\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1298 - val_loss: 0.1264\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.1020 - val_loss: 0.1030\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0792 - val_loss: 0.0827\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0603 - val_loss: 0.0656\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0462 - val_loss: 0.0507\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0343 - val_loss: 0.0386\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0255 - val_loss: 0.0287\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0127 - val_loss: 0.0135\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7373e-04 - val_loss: 0.0018\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5867e-04 - val_loss: 0.0016\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3273e-04 - val_loss: 0.0015\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1027e-04 - val_loss: 0.0014\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4750e-04 - val_loss: 0.0013\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8738e-04 - val_loss: 0.0013\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5629e-04 - val_loss: 0.0012\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.2767e-04 - val_loss: 0.0012\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9725e-04 - val_loss: 0.0012\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7657e-04 - val_loss: 0.0011\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4939e-04 - val_loss: 0.0010\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2651e-04 - val_loss: 0.0010\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.1486e-04 - val_loss: 0.0010\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.9675e-04 - val_loss: 9.4998e-04\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8107e-04 - val_loss: 9.3583e-04\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.6931e-04 - val_loss: 9.1723e-04\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.5772e-04 - val_loss: 9.2769e-04\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.4415e-04 - val_loss: 8.8995e-04\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3479e-04 - val_loss: 8.7527e-04\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2748e-04 - val_loss: 8.7338e-04\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1482e-04 - val_loss: 8.5483e-04\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0798e-04 - val_loss: 8.2554e-04\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0038e-04 - val_loss: 8.3368e-04\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9331e-04 - val_loss: 8.0221e-04\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8362e-04 - val_loss: 8.0156e-04\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7788e-04 - val_loss: 7.8763e-04\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.7327e-04 - val_loss: 7.9013e-04\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6913e-04 - val_loss: 7.6170e-04\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6046e-04 - val_loss: 7.3869e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5331e-04 - val_loss: 7.4411e-04\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5199e-04 - val_loss: 7.3580e-04\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4707e-04 - val_loss: 7.2098e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4132e-04 - val_loss: 7.1902e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3924e-04 - val_loss: 6.9354e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3195e-04 - val_loss: 7.0124e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2854e-04 - val_loss: 6.8877e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2388e-04 - val_loss: 6.7320e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2118e-04 - val_loss: 6.6737e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1827e-04 - val_loss: 6.8284e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1567e-04 - val_loss: 6.6588e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1203e-04 - val_loss: 6.3886e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1101e-04 - val_loss: 6.4457e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0516e-04 - val_loss: 6.3800e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0251e-04 - val_loss: 6.1974e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0171e-04 - val_loss: 6.3641e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.6949e-05 - val_loss: 6.2456e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5121e-05 - val_loss: 6.0403e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5452e-05 - val_loss: 6.1403e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1961e-05 - val_loss: 6.1717e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1421e-05 - val_loss: 5.8223e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3530e-05 - val_loss: 5.9141e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1356e-05 - val_loss: 5.9146e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8482e-05 - val_loss: 5.7775e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7640e-05 - val_loss: 5.6882e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6232e-05 - val_loss: 5.6990e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3892e-05 - val_loss: 5.6960e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5004e-05 - val_loss: 5.5264e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9379e-05 - val_loss: 5.6117e-04\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1375e-05 - val_loss: 5.6551e-04\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6086e-05 - val_loss: 5.3854e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6842e-05 - val_loss: 5.3641e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4586e-05 - val_loss: 5.3959e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1893e-05 - val_loss: 5.3919e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0486e-05 - val_loss: 5.2225e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9154e-05 - val_loss: 5.3456e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8191e-05 - val_loss: 5.2070e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5262e-05 - val_loss: 5.1912e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5351e-05 - val_loss: 5.1720e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4118e-05 - val_loss: 5.1078e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1237e-05 - val_loss: 5.1942e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2160e-05 - val_loss: 5.1212e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9900e-05 - val_loss: 4.8820e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9273e-05 - val_loss: 5.0090e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7659e-05 - val_loss: 4.9929e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5897e-05 - val_loss: 4.8495e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5728e-05 - val_loss: 4.8752e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4850e-05 - val_loss: 4.8518e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3589e-05 - val_loss: 4.7745e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3846e-05 - val_loss: 4.6908e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5513e-05 - val_loss: 4.8871e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2344e-05 - val_loss: 4.6682e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2044e-05 - val_loss: 4.6643e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.9117e-05 - val_loss: 4.7846e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9735e-05 - val_loss: 4.5779e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9278e-05 - val_loss: 4.5272e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.6910e-05 - val_loss: 4.6290e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.6674e-05 - val_loss: 4.4246e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6322e-05 - val_loss: 4.4571e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3787e-05 - val_loss: 4.4957e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3572e-05 - val_loss: 4.3627e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2810e-05 - val_loss: 4.4292e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.1025e-05 - val_loss: 4.3353e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.0602e-05 - val_loss: 4.2299e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.0606e-05 - val_loss: 4.3104e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9661e-05 - val_loss: 4.2314e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2.8766e-05 - val_loss: 4.2405e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8865e-05 - val_loss: 4.1497e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 2.6647e-05 - val_loss: 4.1965e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7059e-05 - val_loss: 4.1544e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.7413e-05 - val_loss: 4.0837e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2.7384e-05 - val_loss: 4.1061e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5026e-05 - val_loss: 4.0264e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5359e-05 - val_loss: 4.0326e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5316e-05 - val_loss: 4.0532e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.4756e-05 - val_loss: 3.9339e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.5820e-05 - val_loss: 3.9891e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.4711e-05 - val_loss: 4.0008e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.3374e-05 - val_loss: 3.8562e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2955e-05 - val_loss: 3.9155e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2388e-05 - val_loss: 3.8853e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2548e-05 - val_loss: 3.8548e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.1663e-05 - val_loss: 3.8878e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.0951e-05 - val_loss: 3.8041e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0082e-05 - val_loss: 3.7579e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9830e-05 - val_loss: 3.7972e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.0091e-05 - val_loss: 3.9138e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8794e-05 - val_loss: 3.7223e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.9025e-05 - val_loss: 3.6986e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8350e-05 - val_loss: 3.7211e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8490e-05 - val_loss: 3.6751e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8164e-05 - val_loss: 3.6191e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8213e-05 - val_loss: 3.7327e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7925e-05 - val_loss: 3.5746e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6886e-05 - val_loss: 3.7155e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7121e-05 - val_loss: 3.6113e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7310e-05 - val_loss: 3.5659e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6255e-05 - val_loss: 3.6421e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6361e-05 - val_loss: 3.5625e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5713e-05 - val_loss: 3.5610e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5769e-05 - val_loss: 3.5981e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5498e-05 - val_loss: 3.4662e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5430e-05 - val_loss: 3.5651e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6522e-05 - val_loss: 3.4994e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4579e-05 - val_loss: 3.4409e-04\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4353e-05 - val_loss: 3.5353e-04\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4560e-05 - val_loss: 3.4481e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4067e-05 - val_loss: 3.4369e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5380e-05 - val_loss: 3.5716e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5411e-05 - val_loss: 3.3915e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4250e-05 - val_loss: 3.4840e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.4493e-05 - val_loss: 3.4080e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3926e-05 - val_loss: 3.3521e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3042e-05 - val_loss: 3.4511e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.3478e-05 - val_loss: 3.3503e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3080e-05 - val_loss: 3.3695e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.2305e-05 - val_loss: 3.4122e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2009e-05 - val_loss: 3.3341e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3593e-05 - val_loss: 3.3815e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2806e-05 - val_loss: 3.3990e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2681e-05 - val_loss: 3.2386e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2302e-05 - val_loss: 3.3243e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1625e-05 - val_loss: 3.3326e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1668e-05 - val_loss: 3.3199e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1322e-05 - val_loss: 3.2820e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2227e-05 - val_loss: 3.2923e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3240e-05 - val_loss: 3.2738e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1260e-05 - val_loss: 3.2886e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1958e-05 - val_loss: 3.2507e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0910e-05 - val_loss: 3.2645e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0820e-05 - val_loss: 3.2305e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0257e-05 - val_loss: 3.2375e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0475e-05 - val_loss: 3.2133e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1068e-05 - val_loss: 3.1828e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0182e-05 - val_loss: 3.2093e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.0610e-05 - val_loss: 3.1652e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0552e-05 - val_loss: 3.2703e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7574e-06 - val_loss: 3.1370e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9977e-06 - val_loss: 3.1506e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8752e-06 - val_loss: 3.1906e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0276e-05 - val_loss: 3.1050e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4965e-06 - val_loss: 3.1628e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.8807e-06 - val_loss: 3.1100e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3854e-06 - val_loss: 3.1368e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5418e-06 - val_loss: 3.0865e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2124e-06 - val_loss: 3.1290e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9049e-06 - val_loss: 3.0738e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6510e-06 - val_loss: 3.0906e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9358e-06 - val_loss: 3.0958e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3043e-06 - val_loss: 3.0601e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6440e-06 - val_loss: 3.0851e-04\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val,y_val),batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e381f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 7.5641e-05 - 191ms/epoch - 191ms/step\n",
      "tf.Tensor((0.9987502039157767+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7e038",
   "metadata": {},
   "source": [
    "### INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08af1f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(3,)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(3),\n",
    "  tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4adaa54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 79ms/step - loss: 0.4646 - val_loss: 0.4060\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2293 - val_loss: 0.2055\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1051 - val_loss: 0.0756\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0364 - val_loss: 0.0448\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0252 - val_loss: 0.0300\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0173 - val_loss: 0.0173\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.3626e-04 - val_loss: 0.0021\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6735e-04 - val_loss: 0.0020\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0713e-04 - val_loss: 0.0018\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.3329e-04 - val_loss: 0.0017\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9394e-04 - val_loss: 0.0017\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4765e-04 - val_loss: 0.0016\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0795e-04 - val_loss: 0.0016\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7502e-04 - val_loss: 0.0015\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4267e-04 - val_loss: 0.0015\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1202e-04 - val_loss: 0.0014\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8616e-04 - val_loss: 0.0014\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7152e-04 - val_loss: 0.0013\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4155e-04 - val_loss: 0.0013\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2192e-04 - val_loss: 0.0013\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0178e-04 - val_loss: 0.0012\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8613e-04 - val_loss: 0.0012\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.6647e-04 - val_loss: 0.0012\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.5583e-04 - val_loss: 0.0012\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4078e-04 - val_loss: 0.0012\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2825e-04 - val_loss: 0.0012\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1369e-04 - val_loss: 0.0011\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0053e-04 - val_loss: 0.0012\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9328e-04 - val_loss: 0.0012\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.7904e-04 - val_loss: 0.0011\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.6634e-04 - val_loss: 0.0011\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.5502e-04 - val_loss: 0.0011\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.4778e-04 - val_loss: 0.0011\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.4007e-04 - val_loss: 0.0011\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.3105e-04 - val_loss: 0.0011\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2390e-04 - val_loss: 0.0010\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1628e-04 - val_loss: 0.0010\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0856e-04 - val_loss: 9.9558e-04\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0052e-04 - val_loss: 0.0010\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9285e-04 - val_loss: 0.0010\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8807e-04 - val_loss: 9.9442e-04\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8343e-04 - val_loss: 9.8915e-04\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8191e-04 - val_loss: 9.9200e-04\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7019e-04 - val_loss: 9.6422e-04\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6442e-04 - val_loss: 9.4707e-04\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5930e-04 - val_loss: 9.3735e-04\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5133e-04 - val_loss: 9.4604e-04\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4725e-04 - val_loss: 9.3991e-04\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4199e-04 - val_loss: 9.0567e-04\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3673e-04 - val_loss: 8.9793e-04\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3049e-04 - val_loss: 9.0283e-04\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2611e-04 - val_loss: 9.1219e-04\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2066e-04 - val_loss: 8.9064e-04\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1692e-04 - val_loss: 8.6825e-04\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1156e-04 - val_loss: 8.6984e-04\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0859e-04 - val_loss: 8.7952e-04\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0490e-04 - val_loss: 8.5954e-04\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0169e-04 - val_loss: 8.4880e-04\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6382e-05 - val_loss: 8.3619e-04\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2785e-05 - val_loss: 8.3441e-04\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9458e-05 - val_loss: 8.4215e-04\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6356e-05 - val_loss: 8.2673e-04\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3733e-05 - val_loss: 8.2125e-04\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1354e-05 - val_loss: 8.2683e-04\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8114e-05 - val_loss: 8.2117e-04\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.5921e-05 - val_loss: 8.2234e-04\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4418e-05 - val_loss: 8.1467e-04\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1108e-05 - val_loss: 8.0441e-04\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9366e-05 - val_loss: 8.0452e-04\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7120e-05 - val_loss: 8.0562e-04\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6237e-05 - val_loss: 8.1353e-04\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4479e-05 - val_loss: 8.0082e-04\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7682e-05 - val_loss: 7.8919e-04\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0543e-05 - val_loss: 7.8160e-04\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9496e-05 - val_loss: 7.8699e-04\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7752e-05 - val_loss: 8.0383e-04\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8345e-05 - val_loss: 7.9879e-04\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6323e-05 - val_loss: 7.7074e-04\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3289e-05 - val_loss: 7.7764e-04\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3105e-05 - val_loss: 7.9641e-04\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.0381e-05 - val_loss: 7.8352e-04\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.8249e-05 - val_loss: 7.7100e-04\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.8075e-05 - val_loss: 7.6544e-04\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6369e-05 - val_loss: 7.7092e-04\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5775e-05 - val_loss: 7.7535e-04\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6345e-05 - val_loss: 7.6694e-04\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3241e-05 - val_loss: 7.6592e-04\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1771e-05 - val_loss: 7.6686e-04\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1074e-05 - val_loss: 7.6210e-04\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0946e-05 - val_loss: 7.5528e-04\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9259e-05 - val_loss: 7.5374e-04\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.7456e-05 - val_loss: 7.5703e-04\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.7924e-05 - val_loss: 7.6759e-04\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5646e-05 - val_loss: 7.5920e-04\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6178e-05 - val_loss: 7.4800e-04\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4230e-05 - val_loss: 7.3864e-04\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.3573e-05 - val_loss: 7.4547e-04\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2943e-05 - val_loss: 7.5230e-04\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1084e-05 - val_loss: 7.4470e-04\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1327e-05 - val_loss: 7.4812e-04\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.9620e-05 - val_loss: 7.4994e-04\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.9889e-05 - val_loss: 7.3583e-04\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0077e-05 - val_loss: 7.3871e-04\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.8017e-05 - val_loss: 7.4475e-04\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8067e-05 - val_loss: 7.4384e-04\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7215e-05 - val_loss: 7.3384e-04\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.6723e-05 - val_loss: 7.3306e-04\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.5427e-05 - val_loss: 7.3409e-04\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.5835e-05 - val_loss: 7.3227e-04\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4456e-05 - val_loss: 7.4756e-04\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.4595e-05 - val_loss: 7.4333e-04\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.3907e-05 - val_loss: 7.3408e-04\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.3824e-05 - val_loss: 7.2461e-04\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2938e-05 - val_loss: 7.3289e-04\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2790e-05 - val_loss: 7.3089e-04\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.2560e-05 - val_loss: 7.2780e-04\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1797e-05 - val_loss: 7.3241e-04\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1285e-05 - val_loss: 7.2925e-04\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0727e-05 - val_loss: 7.2127e-04\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0748e-05 - val_loss: 7.2211e-04\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0361e-05 - val_loss: 7.3320e-04\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9907e-05 - val_loss: 7.2923e-04\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.9461e-05 - val_loss: 7.1928e-04\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.9264e-05 - val_loss: 7.1889e-04\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9033e-05 - val_loss: 7.3112e-04\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.8157e-05 - val_loss: 7.2075e-04\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7823e-05 - val_loss: 7.1666e-04\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8840e-05 - val_loss: 7.2742e-04\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.8857e-05 - val_loss: 7.1776e-04\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7126e-05 - val_loss: 7.2018e-04\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6757e-05 - val_loss: 7.2524e-04\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6601e-05 - val_loss: 7.1583e-04\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6878e-05 - val_loss: 7.1744e-04\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6228e-05 - val_loss: 7.1700e-04\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.6333e-05 - val_loss: 7.1523e-04\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5540e-05 - val_loss: 7.2464e-04\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4781e-05 - val_loss: 7.1786e-04\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5043e-05 - val_loss: 7.1006e-04\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4774e-05 - val_loss: 7.1055e-04\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4201e-05 - val_loss: 7.1647e-04\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.4130e-05 - val_loss: 7.1811e-04\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3975e-05 - val_loss: 7.1665e-04\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3593e-05 - val_loss: 7.0527e-04\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3280e-05 - val_loss: 7.1463e-04\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2746e-05 - val_loss: 7.1886e-04\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.2732e-05 - val_loss: 7.1062e-04\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.2368e-05 - val_loss: 7.1734e-04\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.2380e-05 - val_loss: 7.1234e-04\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.1793e-05 - val_loss: 7.0487e-04\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1674e-05 - val_loss: 7.1256e-04\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1437e-05 - val_loss: 7.1244e-04\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1330e-05 - val_loss: 7.0617e-04\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1412e-05 - val_loss: 7.0941e-04\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1210e-05 - val_loss: 7.1756e-04\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0741e-05 - val_loss: 7.0378e-04\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0369e-05 - val_loss: 7.0804e-04\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0588e-05 - val_loss: 7.1910e-04\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0151e-05 - val_loss: 7.0408e-04\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5046e-06 - val_loss: 7.0283e-04\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3639e-06 - val_loss: 7.1487e-04\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5224e-06 - val_loss: 7.0986e-04\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3114e-06 - val_loss: 7.1055e-04\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4986e-06 - val_loss: 7.0353e-04\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9324e-06 - val_loss: 7.0924e-04\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6713e-06 - val_loss: 7.0843e-04\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5735e-06 - val_loss: 7.0476e-04\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1825e-06 - val_loss: 7.1217e-04\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.2088e-06 - val_loss: 7.0689e-04\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.2302e-06 - val_loss: 7.0343e-04\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2827e-06 - val_loss: 7.0345e-04\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7534e-06 - val_loss: 7.0390e-04\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5030e-06 - val_loss: 7.0706e-04\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2384e-06 - val_loss: 7.0542e-04\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2610e-06 - val_loss: 7.0196e-04\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0941e-06 - val_loss: 7.0687e-04\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1275e-06 - val_loss: 7.0214e-04\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0763e-06 - val_loss: 7.0794e-04\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4838e-06 - val_loss: 7.0359e-04\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4969e-06 - val_loss: 7.0132e-04\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1013e-06 - val_loss: 7.0463e-04\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5696e-06 - val_loss: 7.0070e-04\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0333e-06 - val_loss: 7.0327e-04\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2621e-06 - val_loss: 7.0871e-04\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.2501e-06 - val_loss: 6.9568e-04\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9032e-06 - val_loss: 6.9987e-04\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7268e-06 - val_loss: 7.0496e-04\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5814e-06 - val_loss: 7.0640e-04\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.4049e-06 - val_loss: 6.9997e-04\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.5027e-06 - val_loss: 6.9545e-04\n"
     ]
    }
   ],
   "source": [
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "# Compile model\n",
    "model.compile(optimizer=adam_opt, \n",
    "              loss=infidelity)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "72998d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 6.1127e-04 - 274ms/epoch - 274ms/step\n",
      "tf.Tensor((0.9993887449341811+0j), shape=(), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "#save the model predictions in a tensor\n",
    "y_prediction = model(x_test)\n",
    "\n",
    "#CHANGE TYPE OF PREDICTION IN COMPLEX ONE\n",
    "y_prediction = tf.cast(y_prediction, tf.complex128)\n",
    "\n",
    "#CHANGE TYPE OF IDEAL CASE IN COMPLEX ONE\n",
    "y_test = tf.cast(y_test, tf.complex128)\n",
    "\n",
    "fidelities = []\n",
    "\n",
    "for i in range(len(y_prediction)):\n",
    "  den_mat = density_matrix_from_bloch_vector(y_prediction[i])\n",
    "  den_mat = np.asarray(den_mat)\n",
    "\n",
    "\n",
    "  den_mat_id = density_matrix_from_bloch_vector(y_test[i])\n",
    "  den_mat_id = np.asarray(den_mat_id)\n",
    "\n",
    "\n",
    "  fidelity = fidelity_function(den_mat_id, den_mat)\n",
    "  fidelities.append(fidelity)\n",
    "\n",
    "print(tf.math.reduce_mean(fidelities))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
